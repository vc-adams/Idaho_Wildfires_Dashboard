{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ---------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# ---------------------------------------------------------\n",
    "from splinter import Browser\n",
    "# ---------------------------------------------------------\n",
    "from bs4 import BeautifulSoup as BS\n",
    "# ---------------------------------------------------------\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "# ---------------------------------------------------------\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "# ---------------------------------------------------------\n",
    "from itertools import dropwhile\n",
    "# ---------------------------------------------------------\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# import pymongo\n",
    "# import requests\n",
    "# import datefinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs for the Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USGS_WaterWatch_url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 00 - Scrape the Tables from USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Using Pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This did not work b/c the table is created with JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Websites\n",
    "# River_Stream_7Day_Flow_Conditions_Tables = pd.read_html(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(River_Stream_7Day_Flow_Conditions_Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# River_Stream_7Day_Flow_Conditions_Tables[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Scraping the Website with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' WaterWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identify location of chromedriver and store it as a variable\n",
    "# chromedriver = !which chromedriver\n",
    "# print(type(chromedriver))\n",
    "# chromedriver[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve page with the requests module\n",
    "# executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# # OR\n",
    "# # executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# # I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# # executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "# browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URL of page to be scraped\n",
    "# url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# browser.visit(url)\n",
    "# # window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = browser.html\n",
    "# soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the html code of the NASA's Mars website\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Click FULL IMAGE to see a large thumbnail of the featured image \n",
    "# browser.click_link_by_id('st')\n",
    "# # browser.fill('st', \"Idaho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "# for option in soup.find_all('option'):\n",
    "#     print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from selenium import webdriver\n",
    "# # from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get(USGS_WaterWatch_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "# select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# # Select by visible text\n",
    "# select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill in Input Fills\n",
    "# #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# # Clear the Input Field\n",
    "# #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "# element = driver.find_element_by_name(\"bdt\")\n",
    "# element.clear()\n",
    "# element.send_keys(\"1990-01-01\")\n",
    "\n",
    "# element = driver.find_element_by_name(\"edt\")\n",
    "# element.clear()\n",
    "# element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Press/Click a Button Without an ID\n",
    "# #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "# button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "# button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# # test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# # test\n",
    "\n",
    "# # https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "# soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Grab All Page Source on the Page\n",
    "# soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# # Find All the Tables on the Page\n",
    "# tables = soup_lxml.find_all(\"table\")\n",
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the Tables with Pandas\n",
    "# dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the Table\n",
    "# print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "# print(\"*********************************************************************************************************\")\n",
    "# print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "# print(\"*********************************************************************************************************\")\n",
    "# print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "# dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, json\n",
    "# text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "# data = json.loads(text)\n",
    "# print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tr in soup.find_all('tr')[2:]:\n",
    "#     tds = tr.find_all('td')\n",
    "#     print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "# #           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scrape a Table of All the Streamflow Stations In Idaho by County, Save a CSV File with Daily Streamflow Data for Each Station, and Scrape a Table with Extended Streamflow Statistics for Each Streamflow Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create the Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Current Streamflow')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('group_table_by'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('county_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "sbmt_bttn = '//input[@type=\"submit\" and @value=\"go\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find All the Station Numbers Scrap the table with all the stations and use that table to loop \n",
    "# through and click each station's link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "crrnt_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tables on the current page: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationNumber</th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)3/6</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)3/6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13206000</td>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13206305</td>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13206400</td>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>13011500</td>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>13011900</td>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>13013650</td>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>13015000</td>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>13018750</td>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StationNumber                                    Station name  \\\n",
       "0        Ada County                                      Ada County   \n",
       "1          13206000      BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2          13206305           BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3          13206400                        EAGLE DRAIN AT EAGLE, ID   \n",
       "4    Bannock County                                  Bannock County   \n",
       "..              ...                                             ...   \n",
       "271        13011500                      PACIFIC CREEK AT MORAN, WY   \n",
       "272        13011900          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273        13013650                        SNAKE RIVER AT MOOSE, WY   \n",
       "274        13015000                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275        13018750  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)3/6 Dailymeanstream- flow (ft3/s)3/6  \n",
       "0                    Ada County                       Ada County  \n",
       "1                           NaN                              290  \n",
       "2                           NaN                              251  \n",
       "3                           NaN                             6.70  \n",
       "4                Bannock County                   Bannock County  \n",
       "..                          ...                              ...  \n",
       "271                         NaN                               --  \n",
       "272                         NaN                               --  \n",
       "273                         NaN                              989  \n",
       "274                         NaN                               --  \n",
       "275                         NaN                             1390  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "statn_table = pd.read_html(crrnt_url)\n",
    "print(f\"Number of Tables on the current page: {len(statn_table)}\")\n",
    "statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(statn_table[1].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df = statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)3/6</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)3/6</th>\n",
       "      <th>numbers</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td></td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290</td>\n",
       "      <td>13206000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>13206305</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.70</td>\n",
       "      <td>13206400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td></td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011500</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011900</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>989</td>\n",
       "      <td>13013650</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13015000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1390</td>\n",
       "      <td>13018750</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Station name  \\\n",
       "0                                        Ada County   \n",
       "1        BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2             BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3                          EAGLE DRAIN AT EAGLE, ID   \n",
       "4                                    Bannock County   \n",
       "..                                              ...   \n",
       "271                      PACIFIC CREEK AT MORAN, WY   \n",
       "272          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273                        SNAKE RIVER AT MOOSE, WY   \n",
       "274                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)3/6 Dailymeanstream- flow (ft3/s)3/6   numbers  \\\n",
       "0                    Ada County                       Ada County             \n",
       "1                           NaN                              290  13206000   \n",
       "2                           NaN                              251  13206305   \n",
       "3                           NaN                             6.70  13206400   \n",
       "4                Bannock County                   Bannock County             \n",
       "..                          ...                              ...       ...   \n",
       "271                         NaN                               --  13011500   \n",
       "272                         NaN                               --  13011900   \n",
       "273                         NaN                              989  13013650   \n",
       "274                         NaN                               --  13015000   \n",
       "275                         NaN                             1390  13018750   \n",
       "\n",
       "               text  \n",
       "0        Ada County  \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4    Bannock County  \n",
       "..              ...  \n",
       "271                  \n",
       "272                  \n",
       "273                  \n",
       "274                  \n",
       "275                  \n",
       "\n",
       "[276 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the text from the digits in the \"StationNumber\" column.\n",
    "# https://stackoverflow.com/questions/56851679/how-to-separate-pandas-column-that-contains-values-stored-as-text-and-numbers-in\n",
    "\n",
    "statn_table_df_splt_StatnNmbr = statn_table_df.join(statn_table_df.pop('StationNumber').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n",
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW CELL\n",
    "\n",
    "# if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "#     print(\"No County\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the \"numbers\" column from the \"statn_table_df_splt\" Dataframe\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn = pd.DataFrame(statn_table_df_splt_StatnNmbr[\"numbers\"])\n",
    "\n",
    "# Replace the Empty Rows with \"NaN\"\n",
    "# https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "\n",
    "nan_value = float(\"NaN\")\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.replace(\"\", nan_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the Number of Null Values in the Dataframe\n",
    "# # https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Values: numbers    0\n",
      "dtype: int64\n",
      "*********************************************************************************************************\n",
      "numbers    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove the \"NaN\" Null Values\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls = statn_table_df_splt_StatnNmbr_nmbrs_clmn.dropna()\n",
    "print(f\"Number of Null Values: {statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.isna().sum()}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Convert the \"numbers\" column to an Interger Data Type\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"] = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"].astype(int)\n",
    "\n",
    "# print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgn_date = \"1990-01-01\"\n",
    "end_date = \"1990-01-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13206000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 1\n",
      "********************************************************************************\n",
      "Station Number: 13206305\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 2\n",
      "********************************************************************************\n",
      "Station Number: 13206400\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 3\n",
      "********************************************************************************\n",
      "Station Number: 13073000\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(),'13075000')]\"}\n  (Session info: chrome=88.0.4324.192)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-1685085edeb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//*[contains(text(),'\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstatn_nmbr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"')]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(),'13075000')]\"}\n  (Session info: chrome=88.0.4324.192)\n"
     ]
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.index:\n",
    "    \n",
    "    # Find the Hyper Link for One Station\n",
    "    statn_nmbr = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"][row]\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\n",
    "    # driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\n",
    "    driver.find_element_by_xpath(\"//*[contains(text(),'\" +statn_nmbr+\"')]\").click()\n",
    "\n",
    "\n",
    "    # Select the Tab-separated Output format\n",
    "    lst_all_statns = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "    lst_all_statns_button = driver.find_element_by_xpath(lst_all_statns)\n",
    "    lst_all_statns_button.click()\n",
    "\n",
    "\n",
    "    # Enter Values for the Begin Date and End Date\n",
    "    # Fill in Input Fills\n",
    "    #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "    # Clear the Input Field\n",
    "    #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "    element = driver.find_element_by_name(\"begin_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(bgn_date)\n",
    "\n",
    "    element = driver.find_element_by_name(\"end_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(end_date)\n",
    "\n",
    "    # Press/Click a Button Without an ID\n",
    "    #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "    #     - https://stackoverflow.com/questions/21322116/using-selenium-in-python-to-click-select-a-radio-button/21322160\n",
    "\n",
    "    sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
    "\n",
    "    sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "    sbmt_bttn_button.click()\n",
    "\n",
    "\n",
    "#     from selenium.webdriver import ActionChains\n",
    "\n",
    "    actionChains = ActionChains(driver)\n",
    "\n",
    "\n",
    "    # Save the data file to This Computer\n",
    "\n",
    "    # How to Open and Write to a File on This Computer\n",
    "    #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "    # How to Change the Location of the File\n",
    "    #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "#     import urllib.request, urllib.error, urllib.parse\n",
    "#     import os\n",
    "\n",
    "\n",
    "    response = urllib.request.urlopen(driver.current_url)\n",
    "    webContent = response.read()\n",
    "\n",
    "    fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "    f = open(fle_nm, 'wb')\n",
    "    f.write(webContent)\n",
    "    f.close\n",
    "\n",
    "# Go back to the original URL for the station\n",
    "    driver.back()\n",
    "    \n",
    "# Select the \"Time-series: Current/Historical Observations\" from the dropdown list, this will \n",
    "# create page which includes a table with extended streamflow statistics.\n",
    "\n",
    "    crrnt_hstrcl_obsrvtns = '//input[@value=\"uv\"]'\n",
    "    \n",
    "    select = Select(driver.find_element_by_id(\"select_data_1\"))\n",
    "    select.select_by_visible_text(\"Time-series:   Current/Historical Observations\")\n",
    "    \n",
    "# Get the extended year streamflow min, max, median, mean, 25th percentile, and 75th percentile\n",
    "    # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "    \n",
    "    crrnt_hstrcl_obsrvtns_url = driver.current_url\n",
    "    crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
    "    print(f'Station Number: {statn_nmbr}')\n",
    "    print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
    "#     print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
    "    \n",
    "    if len(crrnt_hstrcl_obsrvtns_html) == 2:\n",
    "        \n",
    "#         print(crrnt_hstrcl_obsrvtns_html[1])\n",
    "\n",
    "        extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
    "\n",
    "\n",
    "        # Reference: \n",
    "    #     - Find column whose name contains a specific string:\n",
    "    #         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
    "\n",
    "    # print(extndd_yrs_sttstcs.columns)\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
    "        min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'Min Flow: {min_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
    "        max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'Max Flow: {max_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
    "        _25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'25th_prcntle: {_25th_prcntle_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
    "        _75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'75th_prcntle: {_75th_prcntle_strmflw}')\n",
    "\n",
    "\n",
    "\n",
    "            # References:\n",
    "        #     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
    "        #         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
    "        #     - Pandas update a cell:\n",
    "        #         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
    "\n",
    "\n",
    "        # Find the Index for the Station  \n",
    "        indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
    "        print(f'Index No: {indx_lbl[0]}')\n",
    "\n",
    "        # Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
    "        # Dataframe\n",
    "    # #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]\n",
    "    \n",
    "    elif len(crrnt_hstrcl_obsrvtns_html) < 2:\n",
    "        print(\"No Extened Water Statistics\")\n",
    "    \n",
    "    print(\"********************************************************************************\")\n",
    "    \n",
    "# Go back to the URL with the list of Stations and Counties\n",
    "    driver.back()\n",
    "    driver.back()\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)3/6</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)3/6</th>\n",
       "      <th>numbers</th>\n",
       "      <th>text</th>\n",
       "      <th>extndd_yrs_min</th>\n",
       "      <th>extndd_yrs_max</th>\n",
       "      <th>extndd_yrs_median</th>\n",
       "      <th>extndd_yrs_mean</th>\n",
       "      <th>25th_prcntle</th>\n",
       "      <th>75th_prcntle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td></td>\n",
       "      <td>Ada County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290</td>\n",
       "      <td>13206000</td>\n",
       "      <td></td>\n",
       "      <td>111.00</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>13206305</td>\n",
       "      <td></td>\n",
       "      <td>108.00</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.70</td>\n",
       "      <td>13206400</td>\n",
       "      <td></td>\n",
       "      <td>5.62</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td></td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PORTNEUF RIVER AT TOPAZ ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>13073000</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARSH CREEK NR MCCAMMON ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13075000</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Station name Dailymeangage height(ft)3/6  \\\n",
       "0                                  Ada County                  Ada County   \n",
       "1  BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID                         NaN   \n",
       "2       BOISE RIVER SOUTH CHANNEL AT EAGLE ID                         NaN   \n",
       "3                    EAGLE DRAIN AT EAGLE, ID                         NaN   \n",
       "4                              Bannock County              Bannock County   \n",
       "5                  PORTNEUF RIVER AT TOPAZ ID                         NaN   \n",
       "6                  MARSH CREEK NR MCCAMMON ID                         NaN   \n",
       "\n",
       "  Dailymeanstream- flow (ft3/s)3/6   numbers            text  extndd_yrs_min  \\\n",
       "0                       Ada County                Ada County             NaN   \n",
       "1                              290  13206000                          111.00   \n",
       "2                              251  13206305                          108.00   \n",
       "3                             6.70  13206400                            5.62   \n",
       "4                   Bannock County            Bannock County             NaN   \n",
       "5                              120  13073000                             NaN   \n",
       "6                             58.9  13075000                             NaN   \n",
       "\n",
       "   extndd_yrs_max  extndd_yrs_median  extndd_yrs_mean  25th_prcntle  \\\n",
       "0             NaN                NaN              NaN           NaN   \n",
       "1          7020.0              279.0           1420.0         213.0   \n",
       "2          2870.0              226.0            444.0         165.0   \n",
       "3            11.6                7.8              8.3           6.3   \n",
       "4             NaN                NaN              NaN           NaN   \n",
       "5             NaN                NaN              NaN           NaN   \n",
       "6             NaN                NaN              NaN           NaN   \n",
       "\n",
       "   75th_prcntle  \n",
       "0           NaN  \n",
       "1        1420.0  \n",
       "2         252.0  \n",
       "3          11.0  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr_test.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver import ActionChains\n",
    "\n",
    "# actionChains = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data file to This Computer\n",
    "\n",
    "# # How to Open and Write to a File on This Computer\n",
    "# #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "# # How to Change the Location of the File\n",
    "# #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "# import urllib.request, urllib.error, urllib.parse\n",
    "# import os\n",
    "\n",
    "# # url='https://waterdata.usgs.gov/id/nwis/dv?cb_00060=on&format=rdb&site_no=13206000&referred_module=sw&period=&begin_date=1990-01-01&end_date=1990-12-31'\n",
    "\n",
    "# response = urllib.request.urlopen(driver.current_url)\n",
    "# webContent = response.read()\n",
    "\n",
    "# output_fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "# f = open(output_fle_nm, 'wb')\n",
    "# f.write(webContent)\n",
    "# f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.back()\n",
    "# driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crrnt_hstrcl_obsrvtns_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
    "# print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
    "# print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
    "\n",
    "# extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
    "# extndd_yrs_sttstcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reference: \n",
    "# #     - Find column whose name contains a specific string:\n",
    "# #         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
    "\n",
    "# print(extndd_yrs_sttstcs.columns)\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
    "# min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
    "# max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
    "# _25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
    "# _75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the Median because I was the most drastic/losest streamflow\n",
    "# extndd_yrs_sttstcs[\"Median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # References:\n",
    "# #     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
    "# #         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
    "# #     - Pandas update a cell:\n",
    "# #         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
    "\n",
    "# statn_nmbr = \"13206305\"\n",
    "\n",
    "# # Find the Index for the Station  \n",
    "# indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
    "# print(indx_lbl[0])\n",
    "\n",
    "# # Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
    "# # Dataframe\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_test.head(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Create a Dataframe for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to Skip All of the Commented Lines in the File\n",
    "#     https://cmdlinetips.com/2018/01/3-ways-to-read-a-file-and-skip-initial-comments-in-python/\n",
    "\n",
    "def is_comment(s):\n",
    "    \"\"\" function to check if a line\n",
    "         starts with some character.\n",
    "         Here # for comment\n",
    "    \"\"\"\n",
    "    # return true if a line starts with #\n",
    "    return s.startswith('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names for the Dataframe\n",
    "clmn_nms = [\"agency\", \n",
    "            \"site_nmbr\", \n",
    "            \"date\", \n",
    "            \"streamflow_rate\", \n",
    "            \"approved/pending\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path for the Streamflow Data\n",
    "input_fle_path = os.path.join(\"Data\", \"Idaho_Streamflow_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Data Types to Change in the Dataframe\n",
    "convert_dict = {\n",
    "                \"streamflow_rate\": float\n",
    "               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10039500.txt', '13075500.txt', '12415070.txt', '.DS_Store', '13073000.txt', '12414900.txt', '13075000.txt', '10068500.txt', '13206305.txt', '13206400.txt', '12415135.txt', '13075910.txt', '13206000.txt']\n"
     ]
    }
   ],
   "source": [
    "# List of Files in a Directory\n",
    "#     - https://careerkarma.com/blog/python-list-files-in-directory/\n",
    "\n",
    "input_fle_lst = os.listdir(input_fle_path)\n",
    "print(input_fle_lst)\n",
    "# input_fle_nm = input_fle_lst[0]\n",
    "# print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# Create a Dictionary of List from the Files in the Directory\n",
    "input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": []}\n",
    "\n",
    "for input_fle_nm in input_fle_lst:\n",
    "#     Skipping the Files that Start With \".\"\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "\n",
    "# Append to the Station Numbers and File Names and create and append the Dataframe Name to the \n",
    "# Directory\n",
    "        input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "        input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "        input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr.head()\n",
    "\n",
    "# The Last Index Value in the \"text\" Column\n",
    "lst_row_text_clmn = statn_table_df_splt_StatnNmbr[\"text\"].last_valid_index()\n",
    "lst_row_text_clmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_1 = 0\n",
    "\n",
    "# for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "# #     print(row)\n",
    "    \n",
    "#     if row != \"\":\n",
    "# #         print(row)\n",
    "#         count_1 = count_1 + 1\n",
    "# #         cnty_lst.append(row)\n",
    "        \n",
    "# print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnty_lst = [{}for x in range(51)]\n",
    "# # cnty_lst[2].append(2050)\n",
    "# # cnty_lst[1]\n",
    "# cnty_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of list\n",
    "# #     - https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "\n",
    "\n",
    "# cnty_lst = [[]for x in range(51)]\n",
    "\n",
    "# count_1 = 0\n",
    "# count_2 = 0\n",
    "# count_3 = 0\n",
    "\n",
    "# statn_lst = []\n",
    "# # cnty_lst = [[] * 154]\n",
    "# new_dict = {}\n",
    "\n",
    "\n",
    "# for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "# #     print(row)\n",
    " \n",
    "# # *********************************************************************************************\n",
    "# #                               Step 1: If the row is Not Empty\n",
    "# # *********************************************************************************************\n",
    "#     if row != \"\":\n",
    "#         print(row)\n",
    "# #         count_1 = count_1\n",
    "#         cnty_lst[count_2].append(row)\n",
    "#         cnty_lst[count_2].append([])\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# #                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# # *********************************************************************************************\n",
    "\n",
    "#     elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "# #         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # # #         count_3 = count_1\n",
    "# # # #         print (count_3)\n",
    "# # #         count_1 = 0\n",
    "\n",
    "\n",
    "#         new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "#                                   \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "#                                   \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "#                                   \"Data\": \"\", \n",
    "#                                   \"Avg_Streamflow\": \"\",\n",
    "#                                   \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "#         cnty_lst[count_2][1].append(dict(new_dict))\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# #                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# # *********************************************************************************************\n",
    "#     elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "# #         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "#         new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "#                                   \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "#                                   \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "#                                   \"Data\": \"\", \n",
    "#                                   \"Avg_Streamflow\": \"\",\n",
    "#                                   \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "#         cnty_lst[count_2][1].append(dict(new_dict))\n",
    "        \n",
    "#         count_2 = count_2 + 1\n",
    "# # *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# # *********************************************************************************************\n",
    "# #                               Step 4: Add 1 to the Count\n",
    "# # *********************************************************************************************    \n",
    "#     count_1 = count_1 + 1\n",
    "# # *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # statn_lst\n",
    "\n",
    "# # cnty_lst[0][0].append(input_fle_dict)\n",
    "# # cnty_lst[0][1].append(\"test\")\n",
    "# # print(cnty_lst)\n",
    "# print(cnty_lst[0])\n",
    "# print(\"********************************************************************\")\n",
    "# print(cnty_lst[0][1])\n",
    "# print(\"********************************************************************\")\n",
    "# print(cnty_lst[0][1][0])\n",
    "# print(\"********************************************************************\")\n",
    "# print(cnty_lst[0][1][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    }
   ],
   "source": [
    "# Create a List of the Counties\n",
    "cnty_lst = []\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "# Create a List of the Stations\n",
    "# statn_lst = []\n",
    "# cnty_lst = [[] * 154]\n",
    "new_dict = {}\n",
    "\n",
    "# The \"text\" Column is the County Name\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    " \n",
    "#     If this count is <= the Last Row in the \"text\" Column\n",
    "    if count_1 + 1 < 276:\n",
    "# *********************************************************************************************\n",
    "#                               Step 1: If the row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        if row != \"\":\n",
    "            # Create a List of the Stations\n",
    "            statn_lst = []  # This will be a list of dictionaries\n",
    "            cnty_nm = row\n",
    "#         print(row)\n",
    "# #         count_1 = count_1\n",
    "#         cnty_lst[count_2].append(row)\n",
    "#         cnty_lst[count_2].append([])\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# *********************************************************************************************\n",
    "\n",
    "        elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # #         count_3 = count_1\n",
    "# # #         print (count_3)\n",
    "# #         count_1 = 0\n",
    "\n",
    "\n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        elif row == \"\": #and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "        \n",
    "#         count_2 = count_2 + 1\n",
    "        \n",
    "            cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "        \n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************  \n",
    "    if count_1 + 1 > 275 and row == \"\":\n",
    "        print (count_1)\n",
    "\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        \n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                    \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                    \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                    \"Data\": \"\", \n",
    "                    \"Avg_Streamflow\": \"\",\n",
    "                    \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "        statn_lst.append(dict(new_dict))\n",
    "\n",
    "        cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "# *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                               Step 4: Add 1 to the Count\n",
    "# *********************************************************************************************    \n",
    "    count_1 = count_1 + 1\n",
    "# *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Ada County': [{'Avg_Streamflow': '',\n",
      "                  'Data': '',\n",
      "                  'File_Name': '13206000.txt',\n",
      "                  'Prcnt_Below_Avg': '',\n",
      "                  'Station_Nmbr': '13206000',\n",
      "                  'df_Name': '13206000_df'},\n",
      "                 {'Avg_Streamflow': '',\n",
      "                  'Data': '',\n",
      "                  'File_Name': '13206305.txt',\n",
      "                  'Prcnt_Below_Avg': '',\n",
      "                  'Station_Nmbr': '13206305',\n",
      "                  'df_Name': '13206305_df'},\n",
      "                 {'Avg_Streamflow': '',\n",
      "                  'Data': '',\n",
      "                  'File_Name': '13206400.txt',\n",
      "                  'Prcnt_Below_Avg': '',\n",
      "                  'Station_Nmbr': '13206400',\n",
      "                  'df_Name': '13206400_df'}]},\n",
      " {'Bannock County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13073000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13073000',\n",
      "                      'df_Name': '13073000_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13075000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13075000',\n",
      "                      'df_Name': '13075000_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13075500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13075500',\n",
      "                      'df_Name': '13075500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13075910.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13075910',\n",
      "                      'df_Name': '13075910_df'}]},\n",
      " {'Bear Lake County': [{'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '10039500.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '10039500',\n",
      "                        'df_Name': '10039500_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '10068500.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '10068500',\n",
      "                        'df_Name': '10068500_df'}]},\n",
      " {'Benewah County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '12414900.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '12414900',\n",
      "                      'df_Name': '12414900_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '12415070.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '12415070',\n",
      "                      'df_Name': '12415070_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '12415135.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '12415135',\n",
      "                      'df_Name': '12415135_df'}]},\n",
      " {'Bingham County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13060000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13060000',\n",
      "                      'df_Name': '13060000_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13062500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13062500',\n",
      "                      'df_Name': '13062500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13065500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13065500',\n",
      "                      'df_Name': '13065500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13066000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13066000',\n",
      "                      'df_Name': '13066000_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13068300.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13068300',\n",
      "                      'df_Name': '13068300_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13068495.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13068495',\n",
      "                      'df_Name': '13068495_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13068500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13068500',\n",
      "                      'df_Name': '13068500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13069500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13069500',\n",
      "                      'df_Name': '13069500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13075983.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13075983',\n",
      "                      'df_Name': '13075983_df'}]},\n",
      " {'Blaine County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13135500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13135500',\n",
      "                     'df_Name': '13135500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13135520.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13135520',\n",
      "                     'df_Name': '13135520_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13136550.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13136550',\n",
      "                     'df_Name': '13136550_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13137000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13137000',\n",
      "                     'df_Name': '13137000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13137500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13137500',\n",
      "                     'df_Name': '13137500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13138000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13138000',\n",
      "                     'df_Name': '13138000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13139510.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13139510',\n",
      "                     'df_Name': '13139510_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13140335.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13140335',\n",
      "                     'df_Name': '13140335_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13140800.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13140800',\n",
      "                     'df_Name': '13140800_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13142500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13142500',\n",
      "                     'df_Name': '13142500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13147900.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13147900',\n",
      "                     'df_Name': '13147900_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13148500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13148500',\n",
      "                     'df_Name': '13148500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13150430.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13150430',\n",
      "                     'df_Name': '13150430_df'}]},\n",
      " {'Boise County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13185000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13185000',\n",
      "                    'df_Name': '13185000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13200000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13200000',\n",
      "                    'df_Name': '13200000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13235000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13235000',\n",
      "                    'df_Name': '13235000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13237920.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13237920',\n",
      "                    'df_Name': '13237920_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13246000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13246000',\n",
      "                    'df_Name': '13246000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13247500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13247500',\n",
      "                    'df_Name': '13247500_df'}]},\n",
      " {'Bonner County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '12391950.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '12391950',\n",
      "                     'df_Name': '12391950_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '12392155.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '12392155',\n",
      "                     'df_Name': '12392155_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '12392300.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '12392300',\n",
      "                     'df_Name': '12392300_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '12393501.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '12393501',\n",
      "                     'df_Name': '12393501_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '12395000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '12395000',\n",
      "                     'df_Name': '12395000_df'}]},\n",
      " {'Bonneville County': [{'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13032500.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13032500',\n",
      "                         'df_Name': '13032500_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13037500.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13037500',\n",
      "                         'df_Name': '13037500_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13057132.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13057132',\n",
      "                         'df_Name': '13057132_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13057155.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13057155',\n",
      "                         'df_Name': '13057155_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13057500.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13057500',\n",
      "                         'df_Name': '13057500_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13057940.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13057940',\n",
      "                         'df_Name': '13057940_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13058000.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13058000',\n",
      "                         'df_Name': '13058000_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13058510.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13058510',\n",
      "                         'df_Name': '13058510_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13058520.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13058520',\n",
      "                         'df_Name': '13058520_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13058529.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13058529',\n",
      "                         'df_Name': '13058529_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13058530.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13058530',\n",
      "                         'df_Name': '13058530_df'}]},\n",
      " {'Boundary County': [{'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12306500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12306500',\n",
      "                       'df_Name': '12306500_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12308000.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12308000',\n",
      "                       'df_Name': '12308000_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12308500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12308500',\n",
      "                       'df_Name': '12308500_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12309500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12309500',\n",
      "                       'df_Name': '12309500_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12310100.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12310100',\n",
      "                       'df_Name': '12310100_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12318500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12318500',\n",
      "                       'df_Name': '12318500_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12321500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12321500',\n",
      "                       'df_Name': '12321500_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12322000.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12322000',\n",
      "                       'df_Name': '12322000_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12322001.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12322001',\n",
      "                       'df_Name': '12322001_df'}]},\n",
      " {'Butte County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13118700.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13118700',\n",
      "                    'df_Name': '13118700_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13118975.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13118975',\n",
      "                    'df_Name': '13118975_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13119000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13119000',\n",
      "                    'df_Name': '13119000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132100.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132100',\n",
      "                    'df_Name': '13132100_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132373.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132373',\n",
      "                    'df_Name': '13132373_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132500',\n",
      "                    'df_Name': '13132500_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132513.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132513',\n",
      "                    'df_Name': '13132513_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132520.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132520',\n",
      "                    'df_Name': '13132520_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132535.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132535',\n",
      "                    'df_Name': '13132535_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13132565.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13132565',\n",
      "                    'df_Name': '13132565_df'}]},\n",
      " {'Camas County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13141500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13141500',\n",
      "                    'df_Name': '13141500_df'}]},\n",
      " {'Canyon County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13210810.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13210810',\n",
      "                     'df_Name': '13210810_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13210824.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13210824',\n",
      "                     'df_Name': '13210824_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13210831.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13210831',\n",
      "                     'df_Name': '13210831_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13210980.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13210980',\n",
      "                     'df_Name': '13210980_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13210986.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13210986',\n",
      "                     'df_Name': '13210986_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '132109867.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '132109867',\n",
      "                     'df_Name': '132109867_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13211205.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13211205',\n",
      "                     'df_Name': '13211205_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13212549.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13212549',\n",
      "                     'df_Name': '13212549_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13213000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13213000',\n",
      "                     'df_Name': '13213000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13213100.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13213100',\n",
      "                     'df_Name': '13213100_df'}]},\n",
      " {'Caribou County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13057300.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13057300',\n",
      "                      'df_Name': '13057300_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13063000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13063000',\n",
      "                      'df_Name': '13063000_df'}]},\n",
      " {'Cassia County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13078000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13078000',\n",
      "                     'df_Name': '13078000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13079300.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13079300',\n",
      "                     'df_Name': '13079300_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13082500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13082500',\n",
      "                     'df_Name': '13082500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13083000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13083000',\n",
      "                     'df_Name': '13083000_df'}]},\n",
      " {'Clark County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13116500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13116500',\n",
      "                    'df_Name': '13116500_df'}]},\n",
      " {'Clearwater County': [{'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13340000.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13340000',\n",
      "                         'df_Name': '13340000_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13340600.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13340600',\n",
      "                         'df_Name': '13340600_df'}]},\n",
      " {'Custer County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13120000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13120000',\n",
      "                     'df_Name': '13120000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13120500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13120500',\n",
      "                     'df_Name': '13120500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13122000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13122000',\n",
      "                     'df_Name': '13122000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13124265.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13124265',\n",
      "                     'df_Name': '13124265_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13127000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13127000',\n",
      "                     'df_Name': '13127000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13128900.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13128900',\n",
      "                     'df_Name': '13128900_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13295000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13295000',\n",
      "                     'df_Name': '13295000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13296000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13296000',\n",
      "                     'df_Name': '13296000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13296500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13296500',\n",
      "                     'df_Name': '13296500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13297330.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13297330',\n",
      "                     'df_Name': '13297330_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13297355.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13297355',\n",
      "                     'df_Name': '13297355_df'}]},\n",
      " {'Elmore County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13154500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13154500',\n",
      "                     'df_Name': '13154500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13159800.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13159800',\n",
      "                     'df_Name': '13159800_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13186000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13186000',\n",
      "                     'df_Name': '13186000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13190500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13190500',\n",
      "                     'df_Name': '13190500_df'}]},\n",
      " {'Franklin County': [{'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '10092700.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '10092700',\n",
      "                       'df_Name': '10092700_df'}]},\n",
      " {'Fremont County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13039500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13039500',\n",
      "                      'df_Name': '13039500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13042500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13042500',\n",
      "                      'df_Name': '13042500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13046000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13046000',\n",
      "                      'df_Name': '13046000_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13046995.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13046995',\n",
      "                      'df_Name': '13046995_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13047500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13047500',\n",
      "                      'df_Name': '13047500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13047600.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13047600',\n",
      "                      'df_Name': '13047600_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13049500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13049500',\n",
      "                      'df_Name': '13049500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13050500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13050500',\n",
      "                      'df_Name': '13050500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13055000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13055000',\n",
      "                      'df_Name': '13055000_df'}]},\n",
      " {'Gem County': [{'Avg_Streamflow': '',\n",
      "                  'Data': '',\n",
      "                  'File_Name': '13249500.txt',\n",
      "                  'Prcnt_Below_Avg': '',\n",
      "                  'Station_Nmbr': '13249500',\n",
      "                  'df_Name': '13249500_df'},\n",
      "                 {'Avg_Streamflow': '',\n",
      "                  'Data': '',\n",
      "                  'File_Name': '13250000.txt',\n",
      "                  'Prcnt_Below_Avg': '',\n",
      "                  'Station_Nmbr': '13250000',\n",
      "                  'df_Name': '13250000_df'}]},\n",
      " {'Gooding County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13095175.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13095175',\n",
      "                      'df_Name': '13095175_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13095500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13095500',\n",
      "                      'df_Name': '13095500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13152500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13152500',\n",
      "                      'df_Name': '13152500_df'}]},\n",
      " {'Idaho County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13316500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13316500',\n",
      "                    'df_Name': '13316500_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13317000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13317000',\n",
      "                    'df_Name': '13317000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13336500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13336500',\n",
      "                    'df_Name': '13336500_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13337000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13337000',\n",
      "                    'df_Name': '13337000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13337500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13337500',\n",
      "                    'df_Name': '13337500_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13338500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13338500',\n",
      "                    'df_Name': '13338500_df'}]},\n",
      " {'Jefferson County': [{'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13038000.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13038000',\n",
      "                        'df_Name': '13038000_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13038500.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13038500',\n",
      "                        'df_Name': '13038500_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13112000.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13112000',\n",
      "                        'df_Name': '13112000_df'}]},\n",
      " {'Jerome County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13089500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13089500',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     'df_Name': '13089500_df'}]},\n",
      " {'Kootenai County': [{'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413500',\n",
      "                       'df_Name': '12413500_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413860.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413860',\n",
      "                       'df_Name': '12413860_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12417650.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12417650',\n",
      "                       'df_Name': '12417650_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12419000.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12419000',\n",
      "                       'df_Name': '12419000_df'}]},\n",
      " {'Latah County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13345000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13345000',\n",
      "                    'df_Name': '13345000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13346800.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13346800',\n",
      "                    'df_Name': '13346800_df'}]},\n",
      " {'Lemhi County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13302005.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13302005',\n",
      "                    'df_Name': '13302005_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13302500.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13302500',\n",
      "                    'df_Name': '13302500_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13305000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13305000',\n",
      "                    'df_Name': '13305000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13305310.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13305310',\n",
      "                    'df_Name': '13305310_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13306370.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13306370',\n",
      "                    'df_Name': '13306370_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13306385.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13306385',\n",
      "                    'df_Name': '13306385_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13307000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13307000',\n",
      "                    'df_Name': '13307000_df'},\n",
      "                   {'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13310199.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13310199',\n",
      "                    'df_Name': '13310199_df'}]},\n",
      " {'Lewis County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13338950.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13338950',\n",
      "                    'df_Name': '13338950_df'}]},\n",
      " {'Madison County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13055250.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13055250',\n",
      "                      'df_Name': '13055250_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13055340.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13055340',\n",
      "                      'df_Name': '13055340_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13056500.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13056500',\n",
      "                      'df_Name': '13056500_df'},\n",
      "                     {'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13057000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13057000',\n",
      "                      'df_Name': '13057000_df'}]},\n",
      " {'Minidoka County': [{'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '13081500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '13081500',\n",
      "                       'df_Name': '13081500_df'}]},\n",
      " {'Nez Perce County': [{'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13317660.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13317660',\n",
      "                        'df_Name': '13317660_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13341050.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13341050',\n",
      "                        'df_Name': '13341050_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13341140.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13341140',\n",
      "                        'df_Name': '13341140_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13341570.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13341570',\n",
      "                        'df_Name': '13341570_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13342450.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13342450',\n",
      "                        'df_Name': '13342450_df'},\n",
      "                       {'Avg_Streamflow': '',\n",
      "                        'Data': '',\n",
      "                        'File_Name': '13342500.txt',\n",
      "                        'Prcnt_Below_Avg': '',\n",
      "                        'Station_Nmbr': '13342500',\n",
      "                        'df_Name': '13342500_df'}]},\n",
      " {'Owyhee County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13168500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13168500',\n",
      "                     'df_Name': '13168500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13176400.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13176400',\n",
      "                     'df_Name': '13176400_df'}]},\n",
      " {'Payette County': [{'Avg_Streamflow': '',\n",
      "                      'Data': '',\n",
      "                      'File_Name': '13251000.txt',\n",
      "                      'Prcnt_Below_Avg': '',\n",
      "                      'Station_Nmbr': '13251000',\n",
      "                      'df_Name': '13251000_df'}]},\n",
      " {'Power County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13077000.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13077000',\n",
      "                    'df_Name': '13077000_df'}]},\n",
      " {'Shoshone County': [{'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12411000.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12411000',\n",
      "                       'df_Name': '12411000_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413000.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413000',\n",
      "                       'df_Name': '12413000_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413125.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413125',\n",
      "                       'df_Name': '12413125_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413130.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413130',\n",
      "                       'df_Name': '12413130_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413131.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413131',\n",
      "                       'df_Name': '12413131_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413210.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413210',\n",
      "                       'df_Name': '12413210_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413355.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413355',\n",
      "                       'df_Name': '12413355_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12413875.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12413875',\n",
      "                       'df_Name': '12413875_df'},\n",
      "                      {'Avg_Streamflow': '',\n",
      "                       'Data': '',\n",
      "                       'File_Name': '12414500.txt',\n",
      "                       'Prcnt_Below_Avg': '',\n",
      "                       'Station_Nmbr': '12414500',\n",
      "                       'df_Name': '12414500_df'}]},\n",
      " {'Teton County': [{'Avg_Streamflow': '',\n",
      "                    'Data': '',\n",
      "                    'File_Name': '13052200.txt',\n",
      "                    'Prcnt_Below_Avg': '',\n",
      "                    'Station_Nmbr': '13052200',\n",
      "                    'df_Name': '13052200_df'}]},\n",
      " {'Twin Falls County': [{'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13087505.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13087505',\n",
      "                         'df_Name': '13087505_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '',\n",
      "                         'df_Name': '_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13087995.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13087995',\n",
      "                         'df_Name': '13087995_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13090500.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13090500',\n",
      "                         'df_Name': '13090500_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13092747.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13092747',\n",
      "                         'df_Name': '13092747_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13094000.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13094000',\n",
      "                         'df_Name': '13094000_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13108150.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13108150',\n",
      "                         'df_Name': '13108150_df'}]},\n",
      " {'Valley County': [{'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13236500.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13236500',\n",
      "                     'df_Name': '13236500_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13239000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13239000',\n",
      "                     'df_Name': '13239000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13240000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13240000',\n",
      "                     'df_Name': '13240000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13309220.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13309220',\n",
      "                     'df_Name': '13309220_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13310700.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13310700',\n",
      "                     'df_Name': '13310700_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13310800.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13310800',\n",
      "                     'df_Name': '13310800_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13310850.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13310850',\n",
      "                     'df_Name': '13310850_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13311000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13311000',\n",
      "                     'df_Name': '13311000_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13311250.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13311250',\n",
      "                     'df_Name': '13311250_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13311450.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13311450',\n",
      "                     'df_Name': '13311450_df'},\n",
      "                    {'Avg_Streamflow': '',\n",
      "                     'Data': '',\n",
      "                     'File_Name': '13313000.txt',\n",
      "                     'Prcnt_Below_Avg': '',\n",
      "                     'Station_Nmbr': '13313000',\n",
      "                     'df_Name': '13313000_df'}]},\n",
      " {'Washington County': [{'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13258500.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13258500',\n",
      "                         'df_Name': '13258500_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13265500.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13265500',\n",
      "                         'df_Name': '13265500_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13266000.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13266000',\n",
      "                         'df_Name': '13266000_df'},\n",
      "                        {'Avg_Streamflow': '',\n",
      "                         'Data': '',\n",
      "                         'File_Name': '13269000.txt',\n",
      "                         'Prcnt_Below_Avg': '',\n",
      "                         'Station_Nmbr': '13269000',\n",
      "                         'df_Name': '13269000_df'}]},\n",
      " {'Flathead County, Montana': [{'Avg_Streamflow': '',\n",
      "                                'Data': '',\n",
      "                                'File_Name': '12355347.txt',\n",
      "                                'Prcnt_Below_Avg': '',\n",
      "                                'Station_Nmbr': '12355347',\n",
      "                                'df_Name': '12355347_df'}]},\n",
      " {'Lincoln County, Montana': [{'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12301250.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12301250',\n",
      "                               'df_Name': '12301250_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12301933.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12301933',\n",
      "                               'df_Name': '12301933_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12302055.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12302055',\n",
      "                               'df_Name': '12302055_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12304500.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12304500',\n",
      "                               'df_Name': '12304500_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12305000.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12305000',\n",
      "                               'df_Name': '12305000_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '480608115242901.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '480608115242901',\n",
      "                               'df_Name': '480608115242901_df'}]},\n",
      " {'Sanders County, Montana': [{'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12389500.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12389500',\n",
      "                               'df_Name': '12389500_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '12390700.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '12390700',\n",
      "                               'df_Name': '12390700_df'}]},\n",
      " {'Elko County, Nevada': [{'Avg_Streamflow': '',\n",
      "                           'Data': '',\n",
      "                           'File_Name': '13105000.txt',\n",
      "                           'Prcnt_Below_Avg': '',\n",
      "                           'Station_Nmbr': '13105000',\n",
      "                           'df_Name': '13105000_df'},\n",
      "                          {'Avg_Streamflow': '',\n",
      "                           'Data': '',\n",
      "                           'File_Name': '13161500.txt',\n",
      "                           'Prcnt_Below_Avg': '',\n",
      "                           'Station_Nmbr': '13161500',\n",
      "                           'df_Name': '13161500_df'},\n",
      "                          {'Avg_Streamflow': '',\n",
      "                           'Data': '',\n",
      "                           'File_Name': '13162225.txt',\n",
      "                           'Prcnt_Below_Avg': '',\n",
      "                           'Station_Nmbr': '13162225',\n",
      "                           'df_Name': '13162225_df'}]},\n",
      " {'Harney County, Oregon': [{'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '10396000.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '10396000',\n",
      "                             'df_Name': '10396000_df'}]},\n",
      " {'Malheur County, Oregon': [{'Avg_Streamflow': '',\n",
      "                              'Data': '',\n",
      "                              'File_Name': '13181000.txt',\n",
      "                              'Prcnt_Below_Avg': '',\n",
      "                              'Station_Nmbr': '13181000',\n",
      "                              'df_Name': '13181000_df'},\n",
      "                             {'Avg_Streamflow': '',\n",
      "                              'Data': '',\n",
      "                              'File_Name': '13183000.txt',\n",
      "                              'Prcnt_Below_Avg': '',\n",
      "                              'Station_Nmbr': '13183000',\n",
      "                              'df_Name': '13183000_df'},\n",
      "                             {'Avg_Streamflow': '',\n",
      "                              'Data': '',\n",
      "                              'File_Name': '13233300.txt',\n",
      "                              'Prcnt_Below_Avg': '',\n",
      "                              'Station_Nmbr': '13233300',\n",
      "                              'df_Name': '13233300_df'}]},\n",
      " {'Wallowa County, Oregon': [{'Avg_Streamflow': '',\n",
      "                              'Data': '',\n",
      "                              'File_Name': '13333000.txt',\n",
      "                              'Prcnt_Below_Avg': '',\n",
      "                              'Station_Nmbr': '13333000',\n",
      "                              'df_Name': '13333000_df'}]},\n",
      " {'Asotin County, Washington': [{'Avg_Streamflow': '',\n",
      "                                 'Data': '',\n",
      "                                 'File_Name': '13334300.txt',\n",
      "                                 'Prcnt_Below_Avg': '',\n",
      "                                 'Station_Nmbr': '13334300',\n",
      "                                 'df_Name': '13334300_df'}]},\n",
      " {'Lincoln County, Wyoming': [{'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '13022500.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '13022500',\n",
      "                               'df_Name': '13022500_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '13023000.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '13023000',\n",
      "                               'df_Name': '13023000_df'},\n",
      "                              {'Avg_Streamflow': '',\n",
      "                               'Data': '',\n",
      "                               'File_Name': '13027500.txt',\n",
      "                               'Prcnt_Below_Avg': '',\n",
      "                               'Station_Nmbr': '13027500',\n",
      "                               'df_Name': '13027500_df'}]},\n",
      " {'Teton County, Wyoming': [{'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13010065.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13010065',\n",
      "                             'df_Name': '13010065_df'},\n",
      "                            {'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13011000.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13011000',\n",
      "                             'df_Name': '13011000_df'},\n",
      "                            {'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13011500.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13011500',\n",
      "                             'df_Name': '13011500_df'},\n",
      "                            {'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13011900.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13011900',\n",
      "                             'df_Name': '13011900_df'},\n",
      "                            {'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13013650.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13013650',\n",
      "                             'df_Name': '13013650_df'},\n",
      "                            {'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13015000.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13015000',\n",
      "                             'df_Name': '13015000_df'},\n",
      "                            {'Avg_Streamflow': '',\n",
      "                             'Data': '',\n",
      "                             'File_Name': '13018750.txt',\n",
      "                             'Prcnt_Below_Avg': '',\n",
      "                             'Station_Nmbr': '13018750',\n",
      "                             'df_Name': '13018750_df'}]}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(cnty_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statn_lst\n",
    "# cnty_lst = {cnty_nm: statn_lst}\n",
    "# cnty_lst[0][0].append(input_fle_dict)\n",
    "# cnty_lst[0][1].append(\"test\")\n",
    "# pprint.pprint(cnty_lst)\n",
    "# print(\"********************************************************************\")\n",
    "# print(new_dict)\n",
    "# print(statn_lst)\n",
    "pprint.pprint(cnty_lst[0])\n",
    "# pprint.pprint(cnty_lst[50])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"][0])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Station_Nmbr\"])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Data\"][\"date\"])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
    "\n",
    "print(cnty_lst[0].keys())\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][\"Ada County\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_path_fr_lp = input_fle_path + \"/\" + cnty_lst[0][key_list[0]][0][\"File_Name\"]\n",
    "# # input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I DON'T THINK I NEED THIS!!!\n",
    "\n",
    "# key_list = list(cnty_lst[0].keys())\n",
    "# val_list = list(cnty_lst[0].values())\n",
    "# key_list[0]\n",
    "# print(cnty_lst[0][key_list[0]][0][\"File_Name\"])\n",
    "\n",
    "# input_fle_path + \"/\" + cnty_lst[0][key_list[0]][0][\"File_Name\"]\n",
    "# # val_list\n",
    "\n",
    "# # position = val_list.index(1)\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # *********************************************************************************************\n",
    "# #     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "# df = pd.DataFrame(columns = clmn_nms)\n",
    "# #     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# #                           Step 2 Create a Dataframe for the Streamflow\n",
    "# # *********************************************************************************************\n",
    "# # Loop Through the .txt File and Store the Data into a Dataframe\n",
    "# with open(input_fle_path_fr_lp,'r') as fh:\n",
    "#     for curline in dropwhile(is_comment, fh):\n",
    "#     #         print(f\"Index Number: {count} {curline}\")\n",
    "#     #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "#     # Split a String\n",
    "#     #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "#     # Pandas Series\n",
    "#     #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "#         to_append = curline[:-1].split(\"\\t\")\n",
    "#         a_series = pd.Series(to_append, index = clmn_nms)\n",
    "\n",
    "#     #             Dataframe\n",
    "#     #             Dataframe Name\n",
    "#         statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "#     #             Append Data to the Dataframe\n",
    "#         df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# #     print(input_fle_nm)\n",
    "# # Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "# df = df.drop(index = [0, 1])\n",
    "# # Reset the Index so that it Starts with 0\n",
    "# df = df.reset_index(drop = True)\n",
    "# # Change the Data Types of Each Column\n",
    "# df = df.astype(convert_dict) \n",
    "# # Change the Date Column to a datetime Data Type\n",
    "# df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "# avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "# print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "# #     print(df[\"streamflow_rate\"])\n",
    "# #     print(\"********************************************************************\")\n",
    "# print (df)\n",
    "    \n",
    "# count = 0\n",
    "# print(len(df))\n",
    "\n",
    "# for i_df in range(len(df)):\n",
    "# #         print (df[\"streamflow_rate\"][2])\n",
    "#     print (df[\"streamflow_rate\"][i_df])\n",
    "# #         print (df_row)\n",
    "#     if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "#         count = count + 1\n",
    "\n",
    "#         print (\"True\")\n",
    "#     elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "#         print (\"False\")\n",
    "#     print(\"********************************************************************\")\n",
    "\n",
    "# pct_blw_avg = (count / len(df) * 100)\n",
    "# print (pct_blw_avg)\n",
    "# # Add a value into an empty dictionay element\n",
    "# #     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "# statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "# statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "# statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "# #     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "# # df_nm = df_nm.drop(index = [0, 1])\n",
    "# # \"_\" + statn_nm + \"_df\" = df\n",
    "# # df_nm\n",
    "# # df\n",
    "# # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def find(name, path):\n",
    "for root, dirs, files in os.walk(input_fle_path):\n",
    "    if \"13073000.txt\" in files:\n",
    "        print (os.path.join(root, \"13073000.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(\"13073000.txt\", input_fle_path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(input_fle_path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # Create a List of the Files in the Directory\n",
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# Create a List to Store/Save the Streamflow Data, Data will be Saved as a List of Dictionaries\n",
    "statn_data_lst_of_dicts = []\n",
    "input_fle_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# Put the Station in a list by County Name\n",
    "# First Find the station in the county  \n",
    "\n",
    "if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "    print(\"No County\")\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "# Skip the Hidden Files in the Directory\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "# # *********************************************************************************************\n",
    "# #         Append to the File Names to the Directory\n",
    "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "# #         print(input_fle_nm)\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "        input_fle_dict = {\"Station_Nmbr\": input_fle_nm[:-4], \n",
    "                          \"File_Name\": input_fle_nm, \n",
    "                          \"df_Name\": \"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                          \"Data\": \"\", \n",
    "                          \"Avg_Streamflow\": \"\",\n",
    "                          \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "# Append to the File Names to the Directory\n",
    "    statn_data_lst_of_dicts.append(dict(input_fle_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "statn_data_lst_of_dicts\n",
    "# del statn_data_lst_of_dicts[0]\n",
    "# statn_data_lst_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[1]['Station_Nmbr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, station in enumerate(dict_nm[key]):\n",
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "    print(statn_data_lst_of_dicts[i]['File_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = list(a_dict.keys())\n",
    "type(county)\n",
    "county[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_series = pd.Series(data = [0,1,2,3,4], index = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"])\n",
    "a_series\n",
    "statn_data_lst_of_dicts\n",
    "a_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index No: 0\n",
      "County: Ada County\n",
      "Stations:13206000.txt\n",
      "Average Streamflow: 175.51612903225808\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  13206000 1990-01-01            183.0                A\n",
      "1    USGS  13206000 1990-01-02            185.0                A\n",
      "2    USGS  13206000 1990-01-03            184.0                A\n",
      "3    USGS  13206000 1990-01-04            189.0                A\n",
      "4    USGS  13206000 1990-01-05            182.0                A\n",
      "5    USGS  13206000 1990-01-06            182.0                A\n",
      "6    USGS  13206000 1990-01-07            209.0                A\n",
      "7    USGS  13206000 1990-01-08            201.0                A\n",
      "8    USGS  13206000 1990-01-09            189.0                A\n",
      "9    USGS  13206000 1990-01-10            186.0                A\n",
      "10   USGS  13206000 1990-01-11            176.0                A\n",
      "11   USGS  13206000 1990-01-12            170.0                A\n",
      "12   USGS  13206000 1990-01-13            169.0                A\n",
      "13   USGS  13206000 1990-01-14            169.0                A\n",
      "14   USGS  13206000 1990-01-15            165.0                A\n",
      "15   USGS  13206000 1990-01-16            167.0                A\n",
      "16   USGS  13206000 1990-01-17            166.0                A\n",
      "17   USGS  13206000 1990-01-18            169.0                A\n",
      "18   USGS  13206000 1990-01-19            168.0                A\n",
      "19   USGS  13206000 1990-01-20            168.0                A\n",
      "20   USGS  13206000 1990-01-21            167.0                A\n",
      "21   USGS  13206000 1990-01-22            168.0                A\n",
      "22   USGS  13206000 1990-01-23            167.0                A\n",
      "23   USGS  13206000 1990-01-24            164.0                A\n",
      "24   USGS  13206000 1990-01-25            166.0                A\n",
      "25   USGS  13206000 1990-01-26            166.0                A\n",
      "26   USGS  13206000 1990-01-27            172.0                A\n",
      "27   USGS  13206000 1990-01-28            174.0                A\n",
      "28   USGS  13206000 1990-01-29            172.0                A\n",
      "29   USGS  13206000 1990-01-30            176.0                A\n",
      "30   USGS  13206000 1990-01-31            172.0                A\n",
      "----------------------------------------------------\n",
      "Stations:13206305.txt\n",
      "Stations:13206400.txt\n",
      "********************************************************************\n",
      "Index No: 1\n",
      "County: Bannock County\n",
      "Stations:13073000.txt\n",
      "Average Streamflow: 138.38709677419354\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  13073000 1990-01-01            133.0                A\n",
      "1    USGS  13073000 1990-01-02            136.0                A\n",
      "2    USGS  13073000 1990-01-03            133.0                A\n",
      "3    USGS  13073000 1990-01-04            135.0                A\n",
      "4    USGS  13073000 1990-01-05            134.0                A\n",
      "5    USGS  13073000 1990-01-06            134.0                A\n",
      "6    USGS  13073000 1990-01-07            132.0                A\n",
      "7    USGS  13073000 1990-01-08            164.0                A\n",
      "8    USGS  13073000 1990-01-09            146.0                A\n",
      "9    USGS  13073000 1990-01-10            144.0                A\n",
      "10   USGS  13073000 1990-01-11            143.0                A\n",
      "11   USGS  13073000 1990-01-12            143.0                A\n",
      "12   USGS  13073000 1990-01-13            143.0                A\n",
      "13   USGS  13073000 1990-01-14            147.0                A\n",
      "14   USGS  13073000 1990-01-15            146.0                A\n",
      "15   USGS  13073000 1990-01-16            144.0                A\n",
      "16   USGS  13073000 1990-01-17            142.0                A\n",
      "17   USGS  13073000 1990-01-18            137.0                A\n",
      "18   USGS  13073000 1990-01-19            134.0                A\n",
      "19   USGS  13073000 1990-01-20            134.0                A\n",
      "20   USGS  13073000 1990-01-21            134.0                A\n",
      "21   USGS  13073000 1990-01-22            134.0                A\n",
      "22   USGS  13073000 1990-01-23            135.0                A\n",
      "23   USGS  13073000 1990-01-24            135.0                A\n",
      "24   USGS  13073000 1990-01-25            134.0                A\n",
      "25   USGS  13073000 1990-01-26            135.0                A\n",
      "26   USGS  13073000 1990-01-27            135.0                A\n",
      "27   USGS  13073000 1990-01-28            135.0                A\n",
      "28   USGS  13073000 1990-01-29            136.0                A\n",
      "29   USGS  13073000 1990-01-30            137.0                A\n",
      "30   USGS  13073000 1990-01-31            136.0                A\n",
      "----------------------------------------------------\n",
      "Stations:13075000.txt\n",
      "Average Streamflow: 78.38709677419355\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  13075000 1990-01-01             68.0                A\n",
      "1    USGS  13075000 1990-01-02             70.0                A\n",
      "2    USGS  13075000 1990-01-03             66.0                A\n",
      "3    USGS  13075000 1990-01-04             72.0                A\n",
      "4    USGS  13075000 1990-01-05             71.0                A\n",
      "5    USGS  13075000 1990-01-06             71.0                A\n",
      "6    USGS  13075000 1990-01-07             69.0                A\n",
      "7    USGS  13075000 1990-01-08            121.0                A\n",
      "8    USGS  13075000 1990-01-09            107.0                A\n",
      "9    USGS  13075000 1990-01-10             89.0                A\n",
      "10   USGS  13075000 1990-01-11             87.0                A\n",
      "11   USGS  13075000 1990-01-12             82.0                A\n",
      "12   USGS  13075000 1990-01-13             81.0                A\n",
      "13   USGS  13075000 1990-01-14             88.0                A\n",
      "14   USGS  13075000 1990-01-15             92.0                A\n",
      "15   USGS  13075000 1990-01-16             88.0                A\n",
      "16   USGS  13075000 1990-01-17             85.0                A\n",
      "17   USGS  13075000 1990-01-18             81.0                A\n",
      "18   USGS  13075000 1990-01-19             78.0                A\n",
      "19   USGS  13075000 1990-01-20             76.0                A\n",
      "20   USGS  13075000 1990-01-21             73.0                A\n",
      "21   USGS  13075000 1990-01-22             73.0                A\n",
      "22   USGS  13075000 1990-01-23             73.0                A\n",
      "23   USGS  13075000 1990-01-24             68.0                A\n",
      "24   USGS  13075000 1990-01-25             74.0                A\n",
      "25   USGS  13075000 1990-01-26             72.0                A\n",
      "26   USGS  13075000 1990-01-27             65.0                A\n",
      "27   USGS  13075000 1990-01-28             74.0                A\n",
      "28   USGS  13075000 1990-01-29             72.0                A\n",
      "29   USGS  13075000 1990-01-30             72.0                A\n",
      "30   USGS  13075000 1990-01-31             72.0                A\n",
      "----------------------------------------------------\n",
      "Stations:13075500.txt\n",
      "Average Streamflow: 241.03225806451613\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  13075500 1990-01-01            221.0                A\n",
      "1    USGS  13075500 1990-01-02            225.0                A\n",
      "2    USGS  13075500 1990-01-03            226.0                A\n",
      "3    USGS  13075500 1990-01-04            221.0                A\n",
      "4    USGS  13075500 1990-01-05            225.0                A\n",
      "5    USGS  13075500 1990-01-06            223.0                A\n",
      "6    USGS  13075500 1990-01-07            223.0                A\n",
      "7    USGS  13075500 1990-01-08            245.0                A\n",
      "8    USGS  13075500 1990-01-09            343.0                A\n",
      "9    USGS  13075500 1990-01-10            291.0                A\n",
      "10   USGS  13075500 1990-01-11            263.0                A\n",
      "11   USGS  13075500 1990-01-12            257.0                A\n",
      "12   USGS  13075500 1990-01-13            249.0                A\n",
      "13   USGS  13075500 1990-01-14            256.0                A\n",
      "14   USGS  13075500 1990-01-15            270.0                A\n",
      "15   USGS  13075500 1990-01-16            262.0                A\n",
      "16   USGS  13075500 1990-01-17            253.0                A\n",
      "17   USGS  13075500 1990-01-18            244.0                A\n",
      "18   USGS  13075500 1990-01-19            234.0                A\n",
      "19   USGS  13075500 1990-01-20            230.0                A\n",
      "20   USGS  13075500 1990-01-21            229.0                A\n",
      "21   USGS  13075500 1990-01-22            230.0                A\n",
      "22   USGS  13075500 1990-01-23            230.0                A\n",
      "23   USGS  13075500 1990-01-24            230.0                A\n",
      "24   USGS  13075500 1990-01-25            225.0                A\n",
      "25   USGS  13075500 1990-01-26            229.0                A\n",
      "26   USGS  13075500 1990-01-27            227.0                A\n",
      "27   USGS  13075500 1990-01-28            220.0              A:e\n",
      "28   USGS  13075500 1990-01-29            225.0              A:e\n",
      "29   USGS  13075500 1990-01-30            232.0                A\n",
      "30   USGS  13075500 1990-01-31            234.0                A\n",
      "----------------------------------------------------\n",
      "Stations:13075910.txt\n",
      "Average Streamflow: 492.5483870967742\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  13075910 1990-01-01            470.0              A:e\n",
      "1    USGS  13075910 1990-01-02            470.0              A:e\n",
      "2    USGS  13075910 1990-01-03            475.0              A:e\n",
      "3    USGS  13075910 1990-01-04            470.0              A:e\n",
      "4    USGS  13075910 1990-01-05            465.0              A:e\n",
      "5    USGS  13075910 1990-01-06            465.0              A:e\n",
      "6    USGS  13075910 1990-01-07            470.0              A:e\n",
      "7    USGS  13075910 1990-01-08            500.0              A:e\n",
      "8    USGS  13075910 1990-01-09            590.0              A:e\n",
      "9    USGS  13075910 1990-01-10            550.0              A:e\n",
      "10   USGS  13075910 1990-01-11            520.0              A:e\n",
      "11   USGS  13075910 1990-01-12            515.0              A:e\n",
      "12   USGS  13075910 1990-01-13            520.0              A:e\n",
      "13   USGS  13075910 1990-01-14            525.0              A:e\n",
      "14   USGS  13075910 1990-01-15            535.0              A:e\n",
      "15   USGS  13075910 1990-01-16            525.0              A:e\n",
      "16   USGS  13075910 1990-01-17            515.0              A:e\n",
      "17   USGS  13075910 1990-01-18            500.0              A:e\n",
      "18   USGS  13075910 1990-01-19            480.0              A:e\n",
      "19   USGS  13075910 1990-01-20            475.0              A:e\n",
      "20   USGS  13075910 1990-01-21            470.0              A:e\n",
      "21   USGS  13075910 1990-01-22            470.0              A:e\n",
      "22   USGS  13075910 1990-01-23            470.0              A:e\n",
      "23   USGS  13075910 1990-01-24            470.0              A:e\n",
      "24   USGS  13075910 1990-01-25            483.0                A\n",
      "25   USGS  13075910 1990-01-26            486.0                A\n",
      "26   USGS  13075910 1990-01-27            483.0                A\n",
      "27   USGS  13075910 1990-01-28            480.0                A\n",
      "28   USGS  13075910 1990-01-29            476.0                A\n",
      "29   USGS  13075910 1990-01-30            473.0                A\n",
      "30   USGS  13075910 1990-01-31            473.0                A\n",
      "----------------------------------------------------\n",
      "********************************************************************\n",
      "Index No: 2\n",
      "County: Bear Lake County\n",
      "Stations:10039500.txt\n",
      "Average Streamflow: 142.16129032258064\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  10039500 1990-01-01            143.0              A:e\n",
      "1    USGS  10039500 1990-01-02            147.0              A:e\n",
      "2    USGS  10039500 1990-01-03            141.0              A:e\n",
      "3    USGS  10039500 1990-01-04            140.0              A:e\n",
      "4    USGS  10039500 1990-01-05            143.0              A:e\n",
      "5    USGS  10039500 1990-01-06            140.0              A:e\n",
      "6    USGS  10039500 1990-01-07            138.0              A:e\n",
      "7    USGS  10039500 1990-01-08            141.0              A:e\n",
      "8    USGS  10039500 1990-01-09            139.0              A:e\n",
      "9    USGS  10039500 1990-01-10            140.0              A:e\n",
      "10   USGS  10039500 1990-01-11            142.0              A:e\n",
      "11   USGS  10039500 1990-01-12            150.0              A:e\n",
      "12   USGS  10039500 1990-01-13            158.0              A:e\n",
      "13   USGS  10039500 1990-01-14            160.0              A:e\n",
      "14   USGS  10039500 1990-01-15            154.0              A:e\n",
      "15   USGS  10039500 1990-01-16            154.0              A:e\n",
      "16   USGS  10039500 1990-01-17            150.0              A:e\n",
      "17   USGS  10039500 1990-01-18            141.0              A:e\n",
      "18   USGS  10039500 1990-01-19            134.0              A:e\n",
      "19   USGS  10039500 1990-01-20            141.0              A:e\n",
      "20   USGS  10039500 1990-01-21            150.0              A:e\n",
      "21   USGS  10039500 1990-01-22            141.0              A:e\n",
      "22   USGS  10039500 1990-01-23            132.0              A:e\n",
      "23   USGS  10039500 1990-01-24            141.0              A:e\n",
      "24   USGS  10039500 1990-01-25            132.0              A:e\n",
      "25   USGS  10039500 1990-01-26            141.0              A:e\n",
      "26   USGS  10039500 1990-01-27            148.0              A:e\n",
      "27   USGS  10039500 1990-01-28            137.0              A:e\n",
      "28   USGS  10039500 1990-01-29            138.0              A:e\n",
      "29   USGS  10039500 1990-01-30            126.0              A:e\n",
      "30   USGS  10039500 1990-01-31            125.0              A:e\n",
      "----------------------------------------------------\n",
      "Stations:10068500.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Streamflow: 82.3225806451613\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  10068500 1990-01-01             88.0              A:e\n",
      "1    USGS  10068500 1990-01-02             86.0              A:e\n",
      "2    USGS  10068500 1990-01-03             86.0              A:e\n",
      "3    USGS  10068500 1990-01-04             85.0              A:e\n",
      "4    USGS  10068500 1990-01-05             85.0              A:e\n",
      "5    USGS  10068500 1990-01-06             86.0              A:e\n",
      "6    USGS  10068500 1990-01-07             88.0              A:e\n",
      "7    USGS  10068500 1990-01-08             88.0              A:e\n",
      "8    USGS  10068500 1990-01-09             90.0              A:e\n",
      "9    USGS  10068500 1990-01-10             87.0              A:e\n",
      "10   USGS  10068500 1990-01-11             86.0              A:e\n",
      "11   USGS  10068500 1990-01-12             84.0              A:e\n",
      "12   USGS  10068500 1990-01-13             84.0              A:e\n",
      "13   USGS  10068500 1990-01-14             82.0              A:e\n",
      "14   USGS  10068500 1990-01-15             82.0              A:e\n",
      "15   USGS  10068500 1990-01-16             80.0              A:e\n",
      "16   USGS  10068500 1990-01-17             82.0              A:e\n",
      "17   USGS  10068500 1990-01-18             79.0              A:e\n",
      "18   USGS  10068500 1990-01-19             78.0              A:e\n",
      "19   USGS  10068500 1990-01-20             75.0              A:e\n",
      "20   USGS  10068500 1990-01-21             78.0              A:e\n",
      "21   USGS  10068500 1990-01-22             81.0              A:e\n",
      "22   USGS  10068500 1990-01-23             78.0              A:e\n",
      "23   USGS  10068500 1990-01-24             81.0              A:e\n",
      "24   USGS  10068500 1990-01-25             78.0              A:e\n",
      "25   USGS  10068500 1990-01-26             78.0              A:e\n",
      "26   USGS  10068500 1990-01-27             80.0              A:e\n",
      "27   USGS  10068500 1990-01-28             80.0              A:e\n",
      "28   USGS  10068500 1990-01-29             78.0              A:e\n",
      "29   USGS  10068500 1990-01-30             81.0              A:e\n",
      "30   USGS  10068500 1990-01-31             78.0              A:e\n",
      "----------------------------------------------------\n",
      "********************************************************************\n",
      "Index No: 3\n",
      "County: Benewah County\n",
      "Stations:12414900.txt\n",
      "Average Streamflow: 489.4516129032258\n",
      "Data:   agency site_nmbr       date  streamflow_rate approved/pending\n",
      "0    USGS  12414900 1990-01-01             74.0              A:e\n",
      "1    USGS  12414900 1990-01-02             74.0              A:e\n",
      "2    USGS  12414900 1990-01-03             68.0                A\n",
      "3    USGS  12414900 1990-01-04             95.0                A\n",
      "4    USGS  12414900 1990-01-05            102.0                A\n",
      "5    USGS  12414900 1990-01-06            211.0                A\n",
      "6    USGS  12414900 1990-01-07           1250.0                A\n",
      "7    USGS  12414900 1990-01-08           2520.0                A\n",
      "8    USGS  12414900 1990-01-09           1560.0                A\n",
      "9    USGS  12414900 1990-01-10           2100.0                A\n",
      "10   USGS  12414900 1990-01-11           1020.0                A\n",
      "11   USGS  12414900 1990-01-12            672.0                A\n",
      "12   USGS  12414900 1990-01-13            515.0                A\n",
      "13   USGS  12414900 1990-01-14            567.0                A\n",
      "14   USGS  12414900 1990-01-15            543.0                A\n",
      "15   USGS  12414900 1990-01-16            453.0                A\n",
      "16   USGS  12414900 1990-01-17            391.0                A\n",
      "17   USGS  12414900 1990-01-18            333.0                A\n",
      "18   USGS  12414900 1990-01-19            260.0                A\n",
      "19   USGS  12414900 1990-01-20            240.0              A:e\n",
      "20   USGS  12414900 1990-01-21            230.0              A:e\n",
      "21   USGS  12414900 1990-01-22            238.0                A\n",
      "22   USGS  12414900 1990-01-23            221.0                A\n",
      "23   USGS  12414900 1990-01-24            199.0                A\n",
      "24   USGS  12414900 1990-01-25            187.0                A\n",
      "25   USGS  12414900 1990-01-26            196.0                A\n",
      "26   USGS  12414900 1990-01-27            172.0                A\n",
      "27   USGS  12414900 1990-01-28            172.0                A\n",
      "28   USGS  12414900 1990-01-29            171.0                A\n",
      "29   USGS  12414900 1990-01-30            173.0                A\n",
      "30   USGS  12414900 1990-01-31            166.0                A\n",
      "----------------------------------------------------\n",
      "Stations:12415070.txt\n",
      "Stations:12415135.txt\n",
      "********************************************************************\n",
      "Index No: 4\n",
      "County: Bingham County\n",
      "Stations:13060000.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Idaho_Streamflow_Data/13060000.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b36ec9664a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# *********************************************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Loop Through the .txt File and Store the Data into a Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fle_path_fr_lp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m#             print(fh)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#             print(\"----------------------------------------------------\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Idaho_Streamflow_Data/13060000.txt'"
     ]
    }
   ],
   "source": [
    "# References:\n",
    "#     - Break a Loop:\n",
    "#         - https://www.programiz.com/python-programming/break-continue\n",
    "\n",
    "# for i, station in enumerate(dict_nm[key]):\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 1 Loop Through Each County \n",
    "# *********************************************************************************************\n",
    "\n",
    "statns_wth_no_strmflw_data = []\n",
    "\n",
    "for i, county_dict in enumerate(cnty_lst):\n",
    "    print(f\"Index No: {i}\")\n",
    "# Get dictionary keys as a list\n",
    "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
    "    county_lst = list(county_dict.keys())\n",
    "    county = county_lst[0]\n",
    "    print(f\"County: {county}\")\n",
    "#     print(f\"Stations:\")\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each Station Within a County\n",
    "# *********************************************************************************************\n",
    "# \n",
    "    for station_dict in county_dict[county]:\n",
    "        station_lst_keys = list(station_dict.keys())\n",
    "        station_lst_File_Name = station_lst_keys[1]\n",
    "        station_lst_data = station_lst_keys[3]\n",
    "#         print(station_lst_keys)\n",
    "#         print(station_lst_File_Name)\n",
    "#         print(station_lst)\n",
    "        print(f\"Stations:{station_dict[station_lst_File_Name]}\")\n",
    "#     pprint.pprint(a_dict[county])\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3 - Create the File Path for the Stream Data\n",
    "# *********************************************************************************************\n",
    "\n",
    "# Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
    "        input_fle_path_fr_lp = input_fle_path + \"/\" + station_dict[station_lst_File_Name]\n",
    "#         print(f\"File Path: {input_fle_path_fr_lp}\")\n",
    "#         print(\"----------------------------------------------------\")\n",
    "        \n",
    "# Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "        df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "# *********************************************************************************************\n",
    "#             Step 4 - Loop Through the .txt File and Store the Data into a Dataframe\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "        with open(input_fle_path_fr_lp,'r') as fh:\n",
    "#             print(fh)\n",
    "#             print(\"----------------------------------------------------\")\n",
    "            for curline in dropwhile(is_comment, fh):\n",
    "#                 print(f\"Curline:\")\n",
    "#                 print(type(curline))\n",
    "#                 print(\"----------------------------------------------------\")\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "                to_append = curline[:-1].split(\"\\t\")\n",
    "#                 print(f\"To Append:\")\n",
    "#                 print(to_append)\n",
    "# #                 print(to_append[4])\n",
    "#                 print(\"----------------------------------------------------\")\n",
    "                \n",
    "                if len(to_append) == 5:\n",
    "#                     print(\"True\")\n",
    "            \n",
    "                    a_series = pd.Series(data = to_append, index = clmn_nms)\n",
    "#                     print(clmn_nms)\n",
    "#                     print(\"Series:\")\n",
    "#                     print(a_series)\n",
    "#                     print(\"----------------------------------------------------\")\n",
    "                    \n",
    "                        #             Dataframe\n",
    "    #             Dataframe Name\n",
    "#                     statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "                    df= df.append(a_series, ignore_index=True)\n",
    "\n",
    "                    \n",
    "            \n",
    "                elif len(to_append) < 5:\n",
    "                    statns_wth_no_strmflw_data.append(station_dict[station_lst_File_Name])\n",
    "                    break\n",
    "#                     print(f\"Station {station_dict[station_lst_File_Name]} Does not \")\n",
    "                    \n",
    "#     #             Dataframe\n",
    "#     #             Dataframe Name\n",
    "#                 statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "        if len(df) != 0:\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "            df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "            df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "            df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "            df['date']= pd.to_datetime(df['date'])\n",
    "\n",
    "# Calculate the Averge Streamflow Rate for the Station\n",
    "            avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "#     avg_strmflw = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_mean\"]\n",
    "            print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "    \n",
    "#     #             Append Data to the Dataframe           \n",
    "#             print(df)\n",
    "            station_dict[station_lst_data] = df\n",
    "            print(f\"Data:{station_dict[station_lst_data]}\")\n",
    "            print(\"----------------------------------------------------\")\n",
    "            \n",
    "    print(\"********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statns_wth_no_strmflw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cnty_lst[0][\"Ada County\"][1][\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations:13206000\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 183.0\n",
      "----------------------------------------------------\n",
      "1    279.0\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: 279.0\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "279.0 > 183.0\n",
      "Stations:13206305\n",
      "Stations:13206400\n",
      "Stations:13073000\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 133.0\n",
      "----------------------------------------------------\n",
      "5   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:13075000\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 68.0\n",
      "----------------------------------------------------\n",
      "6   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:13075500\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 221.0\n",
      "----------------------------------------------------\n",
      "7   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:13075910\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 470.0\n",
      "----------------------------------------------------\n",
      "8   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:10039500\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 143.0\n",
      "----------------------------------------------------\n",
      "10   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:10068500\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 88.0\n",
      "----------------------------------------------------\n",
      "11   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:12414900\n",
      "Date: 0   1990-01-01\n",
      "Name: date, dtype: datetime64[ns]\n",
      "Daily Streamflow Average: 74.0\n",
      "----------------------------------------------------\n",
      "13   NaN\n",
      "Name: extndd_yrs_median, dtype: float64\n",
      "Extended Years Median: nan\n",
      "<class 'numpy.float64'>\n",
      "----------------------------------------------------\n",
      "Stations:12415070\n",
      "Stations:12415135\n",
      "Stations:13060000\n",
      "Stations:13062500\n",
      "Stations:13065500\n",
      "Stations:13066000\n",
      "Stations:13068300\n",
      "Stations:13068495\n",
      "Stations:13068500\n",
      "Stations:13069500\n",
      "Stations:13075983\n",
      "Stations:13135500\n",
      "Stations:13135520\n",
      "Stations:13136550\n",
      "Stations:13137000\n",
      "Stations:13137500\n",
      "Stations:13138000\n",
      "Stations:13139510\n",
      "Stations:13140335\n",
      "Stations:13140800\n",
      "Stations:13142500\n",
      "Stations:13147900\n",
      "Stations:13148500\n",
      "Stations:13150430\n",
      "Stations:13185000\n",
      "Stations:13200000\n",
      "Stations:13235000\n",
      "Stations:13237920\n",
      "Stations:13246000\n",
      "Stations:13247500\n",
      "Stations:12391950\n",
      "Stations:12392155\n",
      "Stations:12392300\n",
      "Stations:12393501\n",
      "Stations:12395000\n",
      "Stations:13032500\n",
      "Stations:13037500\n",
      "Stations:13057132\n",
      "Stations:13057155\n",
      "Stations:13057500\n",
      "Stations:13057940\n",
      "Stations:13058000\n",
      "Stations:13058510\n",
      "Stations:13058520\n",
      "Stations:13058529\n",
      "Stations:13058530\n",
      "Stations:12306500\n",
      "Stations:12308000\n",
      "Stations:12308500\n",
      "Stations:12309500\n",
      "Stations:12310100\n",
      "Stations:12318500\n",
      "Stations:12321500\n",
      "Stations:12322000\n",
      "Stations:12322001\n",
      "Stations:13118700\n",
      "Stations:13118975\n",
      "Stations:13119000\n",
      "Stations:13132100\n",
      "Stations:13132373\n",
      "Stations:13132500\n",
      "Stations:13132513\n",
      "Stations:13132520\n",
      "Stations:13132535\n",
      "Stations:13132565\n",
      "Stations:13141500\n",
      "Stations:13210810\n",
      "Stations:13210824\n",
      "Stations:13210831\n",
      "Stations:13210980\n",
      "Stations:13210986\n",
      "Stations:132109867\n",
      "Stations:13211205\n",
      "Stations:13212549\n",
      "Stations:13213000\n",
      "Stations:13213100\n",
      "Stations:13057300\n",
      "Stations:13063000\n",
      "Stations:13078000\n",
      "Stations:13079300\n",
      "Stations:13082500\n",
      "Stations:13083000\n",
      "Stations:13116500\n",
      "Stations:13340000\n",
      "Stations:13340600\n",
      "Stations:13120000\n",
      "Stations:13120500\n",
      "Stations:13122000\n",
      "Stations:13124265\n",
      "Stations:13127000\n",
      "Stations:13128900\n",
      "Stations:13295000\n",
      "Stations:13296000\n",
      "Stations:13296500\n",
      "Stations:13297330\n",
      "Stations:13297355\n",
      "Stations:13154500\n",
      "Stations:13159800\n",
      "Stations:13186000\n",
      "Stations:13190500\n",
      "Stations:10092700\n",
      "Stations:13039500\n",
      "Stations:13042500\n",
      "Stations:13046000\n",
      "Stations:13046995\n",
      "Stations:13047500\n",
      "Stations:13047600\n",
      "Stations:13049500\n",
      "Stations:13050500\n",
      "Stations:13055000\n",
      "Stations:13249500\n",
      "Stations:13250000\n",
      "Stations:13095175\n",
      "Stations:13095500\n",
      "Stations:13152500\n",
      "Stations:13316500\n",
      "Stations:13317000\n",
      "Stations:13336500\n",
      "Stations:13337000\n",
      "Stations:13337500\n",
      "Stations:13338500\n",
      "Stations:13038000\n",
      "Stations:13038500\n",
      "Stations:13112000\n",
      "Stations:13089500\n",
      "Stations:12413500\n",
      "Stations:12413860\n",
      "Stations:12417650\n",
      "Stations:12419000\n",
      "Stations:13345000\n",
      "Stations:13346800\n",
      "Stations:13302005\n",
      "Stations:13302500\n",
      "Stations:13305000\n",
      "Stations:13305310\n",
      "Stations:13306370\n",
      "Stations:13306385\n",
      "Stations:13307000\n",
      "Stations:13310199\n",
      "Stations:13338950\n",
      "Stations:13055250\n",
      "Stations:13055340\n",
      "Stations:13056500\n",
      "Stations:13057000\n",
      "Stations:13081500\n",
      "Stations:13317660\n",
      "Stations:13341050\n",
      "Stations:13341140\n",
      "Stations:13341570\n",
      "Stations:13342450\n",
      "Stations:13342500\n",
      "Stations:13168500\n",
      "Stations:13176400\n",
      "Stations:13251000\n",
      "Stations:13077000\n",
      "Stations:12411000\n",
      "Stations:12413000\n",
      "Stations:12413125\n",
      "Stations:12413130\n",
      "Stations:12413131\n",
      "Stations:12413210\n",
      "Stations:12413355\n",
      "Stations:12413875\n",
      "Stations:12414500\n",
      "Stations:13052200\n",
      "Stations:13087505\n",
      "Stations:\n",
      "Stations:13087995\n",
      "Stations:13090500\n",
      "Stations:13092747\n",
      "Stations:13094000\n",
      "Stations:13108150\n",
      "Stations:13236500\n",
      "Stations:13239000\n",
      "Stations:13240000\n",
      "Stations:13309220\n",
      "Stations:13310700\n",
      "Stations:13310800\n",
      "Stations:13310850\n",
      "Stations:13311000\n",
      "Stations:13311250\n",
      "Stations:13311450\n",
      "Stations:13313000\n",
      "Stations:13258500\n",
      "Stations:13265500\n",
      "Stations:13266000\n",
      "Stations:13269000\n",
      "Stations:12355347\n",
      "Stations:12301250\n",
      "Stations:12301933\n",
      "Stations:12302055\n",
      "Stations:12304500\n",
      "Stations:12305000\n",
      "Stations:480608115242901\n",
      "Stations:12389500\n",
      "Stations:12390700\n",
      "Stations:13105000\n",
      "Stations:13161500\n",
      "Stations:13162225\n",
      "Stations:10396000\n",
      "Stations:13181000\n",
      "Stations:13183000\n",
      "Stations:13233300\n",
      "Stations:13333000\n",
      "Stations:13334300\n",
      "Stations:13022500\n",
      "Stations:13023000\n",
      "Stations:13027500\n",
      "Stations:13010065\n",
      "Stations:13011000\n",
      "Stations:13011500\n",
      "Stations:13011900\n",
      "Stations:13013650\n",
      "Stations:13015000\n",
      "Stations:13018750\n",
      "Stations:13206000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-09028d98c170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mtest_indx_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msrch_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mfound_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indx_lbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mdaily_strmflw_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"streamflow_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indx_lbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;31m#                 print(f\"Index: {test_indx_lbl}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mcnty_dly_strmflw_ttl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnty_dly_strmflw_ttl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdaily_strmflw_avg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Refernces:\n",
    "#     - Get a list of dates between two dates\n",
    "#         - https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-50.php\n",
    "#     - Check if a variable is string\n",
    "#         - https://www.geeksforgeeks.org/python-check-if-a-variable-is-string/\n",
    "\n",
    "\n",
    "bgn_date_datetime = datetime.datetime.strptime(bgn_date, '%Y-%m-%d')\n",
    "end_date_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "# print(type(end_dt_datetime ))\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each Date\n",
    "# *********************************************************************************************\n",
    "\n",
    "for dt in daterange(bgn_date_datetime, end_date_datetime):\n",
    "    srch_date = dt.strftime(\"%Y-%m-%d\")\n",
    "#     print(dt.strftime(\"%Y-%m-%d\")) # This is a String\n",
    "    dly_strmflw_ttl = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each County\n",
    "# *********************************************************************************************\n",
    "    for i, county_dict in enumerate(cnty_lst):\n",
    "#         print(f\"Index No: {i}\")\n",
    "    \n",
    "    # Get dictionary keys as a list\n",
    "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
    "        county_lst = list(county_dict.keys())\n",
    "        county = county_lst[0]\n",
    "        cnty_dly_strmflw_ttl = 0\n",
    "#         print(f\"County List Keys: {county_lst}\")\n",
    "#         print(f\"County: {county}\")\n",
    "#         print(\"----------------------------------------------------\")\n",
    "#         print(\"----------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each Station Within a County\n",
    "# *********************************************************************************************\n",
    "\n",
    "        for x, station_dict in enumerate(county_dict[county]):\n",
    "            station_lst_keys = list(station_dict.keys())\n",
    "            station_lst_statn_Name = station_lst_keys[0]\n",
    "            station_lst_data = station_lst_keys[3]\n",
    "#             print(station_lst_keys)\n",
    "#         print(station_lst_File_Name)\n",
    "#             print(station_lst)\n",
    "            print(f\"Stations:{station_dict[station_lst_statn_Name]}\")\n",
    "            df = station_dict[station_lst_data]\n",
    "#             print(type(df))\n",
    "#             pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Data\"][\"date\"])\n",
    "            data_df = cnty_lst[i][county][x][\"Data\"]\n",
    "#             print(data_df)\n",
    "#             print(f\"Data:{df}\")\n",
    "\n",
    "# If the DataFrame is a String Data Type, Which Means it's Empty\n",
    "            if isinstance(data_df, str): \n",
    "                continue\n",
    "\n",
    "            elif not isinstance(data_df, str):\n",
    "# Find the Index for the Date \n",
    "                test_indx_lbl = data_df[data_df[\"date\"] == srch_date].index.tolist()\n",
    "                found_date = data_df[\"date\"][test_indx_lbl]\n",
    "                daily_strmflw_avg = data_df[\"streamflow_rate\"][test_indx_lbl][0]\n",
    "#                 print(f\"Index: {test_indx_lbl}\")\n",
    "                cnty_dly_strmflw_ttl = cnty_dly_strmflw_ttl + daily_strmflw_avg\n",
    "                print(f\"Date: {found_date}\")\n",
    "                print(f\"Daily Streamflow Average: {daily_strmflw_avg}\")\n",
    "#                 print(type(daily_strmflw_avg))\n",
    "                print(\"----------------------------------------------------\")\n",
    "# Is the Daily Streamflow Below the Streams Extended Streamflow Average\n",
    "                statn_indx_lbl = statn_table_df_splt_StatnNmbr_test[statn_table_df_splt_StatnNmbr_test[\"numbers\"] == station_dict[station_lst_statn_Name]].index.tolist()\n",
    "                extndd_yrs_median_array = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_median\"].values[statn_indx_lbl]\n",
    "                extndd_yrs_median = extndd_yrs_median_array[0]\n",
    "                print(statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_median\"][statn_indx_lbl])\n",
    "                print(f\"Extended Years Median: {extndd_yrs_median}\")\n",
    "                print(type(extndd_yrs_median))\n",
    "                print(\"----------------------------------------------------\")\n",
    "            \n",
    "                \n",
    "                if extndd_yrs_median > daily_strmflw_avg:\n",
    "                    print(f\"{extndd_yrs_median} > {daily_strmflw_avg}\")\n",
    "        \n",
    "#         print(\"====================================================\")\n",
    "#         print(f\"{county} Daily Streamflow Average: {cnty_dly_strmflw_ttl}\")\n",
    "#         dly_strmflw_ttl = dly_strmflw_ttl + cnty_dly_strmflw_ttl\n",
    "#         print(\"====================================================\")\n",
    "\n",
    "#     print(\"====================================================\")\n",
    "#     print(f\"{srch_date} Daily Streamflow Average: {dly_strmflw_ttl}\")\n",
    "#     print(\"====================================================\")\n",
    "\n",
    "    \n",
    "    \n",
    "# # Create a dataframe with the county, each day, weighted average,\n",
    "# # Weighted Average\n",
    "#     print(\"====================================================\")\n",
    "#     wghtd_avg = cnty_dly_strmflw_ttl / dly_strmflw_ttl\n",
    "#     print(f\"{srch_date} Daily Streamflow Average: {dly_strmflw_ttl}\")\n",
    "#     print(\"====================================================\")\n",
    "#     print(\"********************************************************************\")\n",
    "                \n",
    "# #     pprint.pprint(a_dict[county])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst[\"Station_Nmbr\"][0]\n",
    "# input_fle_dict[\"File_Name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for station in input_fle_dict[\"df_Name\"]:\n",
    "#     print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_nm = input_fle_lst[0]\n",
    "input_fle_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40482738/how-to-name-dataframe-with-variables-in-pandas\n",
    "\n",
    "N = 10 # 5 in sample\n",
    "dfs = {'name' + str(i):df for i in range(1,N)}\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"name2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # 5 in sample\n",
    "# for input_fle_nm in input_fle_lst:\n",
    "input_fle_nm =\"\"\n",
    "dfs = {input_fle_nm:df for input_fle_nm in input_fle_dict[\"df_Name\"]}\n",
    "# print (input_fle_nm)\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[2]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "# *********************************************************************************************\n",
    "#                                   Step 1 Create Variables\n",
    "# *********************************************************************************************\n",
    "\n",
    "#     Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
    "    input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']\n",
    "\n",
    "#     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "    df = pd.DataFrame(columns = clmn_nms)\n",
    "#     print(df)\n",
    "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# *********************************************************************************************\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 2 Create a Dataframe for the Streamflow\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "    with open(input_fle_path_fr_lp,'r') as fh:\n",
    "        for curline in dropwhile(is_comment, fh):\n",
    "#             print(curline)\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "            to_append = curline[:-1].split(\"\\t\")\n",
    "            a_series = pd.Series(to_append, index = clmn_nms)\n",
    "            print(a_series)\n",
    "            print(\"********************************************************************\")\n",
    "    #             Dataframe\n",
    "    #             Dataframe Name\n",
    "            statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "            df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(input_fle_nm)\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "    df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "    df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "    df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "    avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "#     avg_strmflw = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_mean\"]\n",
    "    print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "#     print(df[\"streamflow_rate\"])\n",
    "#     print(\"********************************************************************\")\n",
    "    print (df)\n",
    "    \n",
    "    count = 0\n",
    "    print(len(df))\n",
    "    \n",
    "    for i_df in range(len(df)):\n",
    "#         print (df[\"streamflow_rate\"][2])\n",
    "        print (df[\"streamflow_rate\"][i_df])\n",
    "#         print (df_row)\n",
    "        if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "            count = count + 1\n",
    "            \n",
    "            print (\"True\")\n",
    "        elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "            print (\"False\")\n",
    "        print(\"********************************************************************\")\n",
    "        print(\"********************************************************************\")\n",
    "\n",
    "    pct_blw_avg = (count / len(df) * 100)\n",
    "    print (pct_blw_avg)\n",
    "# Add a value into an empty dictionay element\n",
    "#     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "    statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "    statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "    statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "#     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "    # df_nm = df_nm.drop(index = [0, 1])\n",
    "    # \"_\" + statn_nm + \"_df\" = df\n",
    "    # df_nm\n",
    "    # df\n",
    "    # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next Step, take the total number of streams that are below its 38 year average and create a\n",
    "precent of that per day (calculate a percent by county then a total precent for the state (Use \n",
    "weighted averaging for the county and for the state, so that bigger streams have more weight in the\n",
    "precent)). This will tell us how many streams are below average per day and we can relate that to \n",
    "how many fires were reported that day and how many lightning strikes occured that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts\n",
    "# statn_data_lst_of_dicts[0]\n",
    "# statn_data_lst_of_dicts[0][\"Data\"]\n",
    "\n",
    "# data_df = statn_data_lst_of_dicts[0][\"Data\"]\n",
    "# data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Refernces:\n",
    "#     - Get a list of dates between two dates\n",
    "#         - https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-50.php\n",
    "\n",
    "\n",
    "bgn_date_datetime = datetime.datetime.strptime(bgn_date, '%Y-%m-%d')\n",
    "end_date_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "start_dt = date(2015, 12, 20)\n",
    "end_dt = date(2016, 1, 11)\n",
    "# print(type(end_dt_datetime ))\n",
    "\n",
    "for dt in daterange(bgn_date_datetime, end_date_datetime):\n",
    "    \n",
    "    print(dt.strftime(\"%Y-%m-%d\")) # This is a String\n",
    "#     print(type(dt.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "        # Find the Index for the Station  \n",
    "#     test_indx_lbl = data_df[data_df[\"date\"] == dt].index.tolist()\n",
    "\n",
    "#     print(f'Index No: {test_indx_lbl[0]}')\n",
    "#     print(f'Streamflow Rate: {data_df[\"streamflow_rate\"][test_indx_lbl[0]]}')\n",
    "#     print(\"********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Index for the Station  \n",
    "test_indx_lbl = data_df[data_df[\"date\"] == \"1990-01-05\"].index.tolist()\n",
    "\n",
    "print(f'Index No: {test_indx_lbl[0]}')\n",
    "print(f'Streamflow Rate: {data_df[\"streamflow_rate\"][test_indx_lbl[0]]}')\n",
    "\n",
    "\n",
    "\n",
    "# To Do:\n",
    "#     - Create a dataframe with the date, county name, total streamflow, average streamflow, weighted \n",
    "#         percent\n",
    "#     - Count how many Stations have a recorded streamflow for that day\n",
    "#         - Make and if statement: If the data exist then count_total else skip that station and go \n",
    "#             to the next station\n",
    "#         - If the data exist then sum the amount of water flowing in the streams for each county\n",
    "#             - Weighted precent for each stream per day\n",
    "#             - Use the count_county and weighted_average_percent to create a streamflow weighted \n",
    "#                 average per county (weighted average is how many county streams are below it's\n",
    "#                 extended average)\n",
    "#             - Add the streamflow rate to the state streamflow\n",
    "#             - Create streamflow weighted average for the state of Idaho using the county streamflow\n",
    "#                 (weighted average is how many county streams are below it's extended average)\n",
    "#             - Append the streamflow weighted average to the new dataframe\n",
    "#                  - The dataframe would include the date, streamflow weighted average, lightning\n",
    "#                      strikes, average prcp, average temp., average humdity, dew point, number of \n",
    "#                      camping permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"_\" + input_fle_nm + \"_df\")\n",
    "# test = \"_\" + input_fle_nm\n",
    "# test[:-4]\n",
    "# input_fle_dict[\"df_Name\"]\n",
    "# _13073000_df.head()\n",
    "# _13206000_df.drop(index = [0, 1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict['Station_Nmbr'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
    "\n",
    "count = 0 \n",
    "\n",
    "with open(input_fle_path,'r') as fh:\n",
    "    for curline in dropwhile(is_comment, fh):\n",
    "        print(f\"Index Number: {count} {curline}\")\n",
    "        count = count + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe for the Data\n",
    "\n",
    "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]\n",
    "\n",
    "_13206000_df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a String\n",
    "#     - https://www.geeksforgeeks.org/python-string-split/\n",
    "# Pandas Series\n",
    "#     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "\n",
    "print(type(curline))\n",
    "print(curline)\n",
    "print((curline.split(\"\\t\")))\n",
    "print(type(curline.split(\"\\t\")))\n",
    "\n",
    "to_append = curline[:-1].split(\"\\t\")\n",
    "a_series = pd.Series(to_append, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Lighting Data from the National Centers for Enviromental Information (NCEI) National Oceanic and Atmospheric Administration (NOAA) Severe Weather Data Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Create the Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://www.ncdc.noaa.gov/severe-weather/severe-weather-data-inventory\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Map Search')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "year = \"2001\"\n",
    "\n",
    "\n",
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//input[@class='esri-input esri-search__input'])[1]\"))).send_keys(\"Idaho, USA\")\n",
    "# time.sleep(5)\n",
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='esri-search__submit-button esri-widget--button'])[1]\"))).click()\n",
    "# time.sleep(10)\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='custom-select swdi-select']/option[text()=\" + dataset + \"])\"))).click()\n",
    "\n",
    "# # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "# driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()=\" + year + \"]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Get All the Options in the Dropdown List:\n",
    "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "#     - Remove a List of Unwanted Characters from a String:\n",
    "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "\n",
    "\n",
    "yrs_lghtnng_strks = [\"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]\n",
    "dataset = \"Lightning Strikes\"\n",
    "\n",
    "lghtnng_strks_df = pd.DataFrame()\n",
    "bad_chars = ['(', 'events)']\n",
    "\n",
    "for yr in yrs_lghtnng_strks:\n",
    "    WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + yr + \"])\"))).click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
    "    select.select_by_visible_text(dataset)    \n",
    "    \n",
    "    time.sleep(15)\n",
    "    \n",
    "    lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "    options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "    \n",
    "    for element in options:\n",
    "#     print (element.get_attribute(\"text\"))\n",
    "        text = element.get_attribute(\"text\")\n",
    "\n",
    "        count = 1\n",
    "    \n",
    "        for i in bad_chars:\n",
    "            text = text.replace(i, \"\")\n",
    "            \n",
    "            if count == 2:\n",
    "                text = text.replace(i, \"\")\n",
    "#                 print (text.split())\n",
    "#                 print (text.split()[0])\n",
    "#                 print (text.split()[1])\n",
    "#                 print (\"**************************\")\n",
    "                count = 0\n",
    "\n",
    "                lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
    "                                                            \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
    "\n",
    "            count = 1 + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = lghtnng_strks_df\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many seconds of phone calls are recorded in total?\n",
    "# print(test_df['number_of_strikes'].sum())\n",
    "# test_df\n",
    "\n",
    "# test_df.groupby(['month']).groups.keys()\n",
    "\n",
    "# test_df.groupby([test_df[\"date\"].dt.month]).sum().reset_index()\n",
    "\n",
    "\n",
    "# Split the String into Just the Year-Month:\n",
    "#     - https://stackoverflow.com/questions/26646191/pandas-groupby-month-and-year\n",
    "\n",
    "def getYearMonth(s):\n",
    "  return s.split(\"-\")[0]+\"-\"+s.split(\"-\")[1]\n",
    "\n",
    "test_df['YearMonth']= test_df['date'].apply(lambda x: getYearMonth(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.dtypes)\n",
    "\n",
    "# Change the Date Column to a datetime Data Type\n",
    "# test_df['date']= pd.to_datetime(test_df['date'])\n",
    "# or\n",
    "# test_df.astype({'date': 'datetime64'})\n",
    "\n",
    "# Change the \"number_of_strikes\" Column to an Integer (\"int32\") Data Type\n",
    "test_df = test_df.astype({'number_of_strikes': 'int32'})\n",
    "print(\"*******************************************\")\n",
    "print(test_df.dtypes)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_YearMonth_df = test_df.groupby(\"YearMonth\")[\"number_of_strikes\"].sum()\n",
    "test_YearMonth_df = pd.DataFrame(test_YearMonth_df)\n",
    "test_YearMonth_df = test_YearMonth_df.reset_index()\n",
    "test_YearMonth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect'])\"))).click()\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect']/option[text()=\" + dataset + \"])\"))).click()\n",
    "# driver.find_element_by_xpath(\"//select[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
    "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
    "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']\").click()\n",
    "\n",
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
    "\n",
    "select.select_by_visible_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_YearMonth_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     Shading an area between two points in a matplotlib plot:\n",
    "#         - https://stackoverflow.com/questions/3681872/shading-an-area-between-two-points-in-a-matplotlib-plot\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(test_YearMonth_df))\n",
    "\n",
    "plt.figure(figsize = (25,20))\n",
    "plt.bar(x_axis, test_YearMonth_df[\"number_of_strikes\"])\n",
    "plt.xticks(x_axis, test_YearMonth_df[\"YearMonth\"], rotation = \"vertical\")\n",
    "plt.hlines(10,0,92, alpha = 1, color = \"red\")\n",
    "plt.axvspan(0, 3, color='y', alpha=0.4, lw=0) # Highlighting the 1992 Lightning Strikes\n",
    "plt.axvspan(4, 8, color='g', alpha=0.4, lw=0) # Highlighting the 1993 Lightning Strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "\n",
    "# lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "\n",
    "# options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "# print(options)\n",
    "\n",
    "# for element in options:\n",
    "#     print (element.get_attribute(\"text\").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Get All the Options in the Dropdown List:\n",
    "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "#     - Remove a List of Unwanted Characters from a String:\n",
    "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "\n",
    "lghtnng_strks_df = pd.DataFrame()\n",
    "\n",
    "lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "\n",
    "options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "bad_chars = ['(', 'events)']\n",
    "\n",
    "for element in options:\n",
    "#     print (element.get_attribute(\"text\"))\n",
    "    text = element.get_attribute(\"text\")\n",
    "    \n",
    "    count = 1\n",
    "    \n",
    "    for i in bad_chars:\n",
    "        text = text.replace(i, \"\")\n",
    "        \n",
    "        if count == 2:\n",
    "            text = text.replace(i, \"\")\n",
    "            print (text.split())\n",
    "            print (text.split()[0])\n",
    "            print (text.split()[1])\n",
    "            print (\"**************************\")\n",
    "            count = 0\n",
    "            \n",
    "            lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
    "                                                        \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
    "            \n",
    "        count = 1 + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lghtnng_strks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dropdown_value(year):\n",
    "    # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "    driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()='2001']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pythonspot.com/selenium-textbox/\n",
    "\n",
    "text_area = driver.find_element_by_class_name('esri-input esri-search__input')\n",
    "text_area.send_keys(\"This text is send using Python code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Mean Streamflow Rate for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "\n",
    "input_fle_dict[\"Data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)\n",
    "statn_data_lst_of_dicts[0][\"Data\"][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of a dictionary within a list (I modified this codes since my dictionary isn't in a list)\n",
    "#     - https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value\n",
    "\n",
    "def find_avg (lst, key, value):\n",
    "    for i, a_dict_2 in enumerate(lst):\n",
    "        print(a_dict_2[key])\n",
    "    #         print(input_fle_dict[\"Station_Nmbr\"])\n",
    "    #         print(\"********************************************************************\")\n",
    "#         if a_dict_2[key] == value:    \n",
    "#         if station == value:\n",
    "#             print(i)\n",
    "    \n",
    "                \n",
    "    \n",
    "#             avg_strmflw_rte = dict_nm[\"Data\"][i][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             dict_nm[\"Avg_Streamflow\"][i].append(avg_strmflw_rte )\n",
    "\n",
    "#             avg_strmflw = lst[i][\"Data\"][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             lst[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "        \n",
    "#             return i # avg_strmflw_rte\n",
    "    #             print(\"********************************************************************\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"][0].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_avg(statn_data_lst_of_dicts, \"Station_Nmbr\", \"13206000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [{'id':'1234','name':'Jason'}, {'id':'2345','name':'Tom'}, {'id':'3456','name':'Art'}]\n",
    "\n",
    "tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None)\n",
    "tom_index\n",
    "\n",
    "# tom_index = next((index for (index, d) in enumerate(input_fle_dict) if d[\"Station_Nmbr\"] == 13075910), None)\n",
    "# print(tom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types1 = [type(k) for k in input_fle_dict[\"Station_Nmbr\"]]\n",
    "types1\n",
    "# type(13075000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = [{'id':'1234','name':'Jason'},\n",
    "         {'id':'2345','name':'Tom'},\n",
    "         {'id':'3456','name':'Art'}]\n",
    "\n",
    "def find_index(dicts, key, value):\n",
    "    class Null: pass\n",
    "    for i, d in enumerate(dicts):\n",
    "        if d.get(key, Null) == value:\n",
    "            return d\n",
    "    else:\n",
    "        raise ValueError('no dict with the key and value combination found')\n",
    "\n",
    "print (find_index(dicts, 'name', 'Tom'))\n",
    "# 1\n",
    "# find_index(dicts, 'name', 'Ensnare')\n",
    "# ValueError: no dict with the key and value combination found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, key, value):\n",
    "#     i = 0\n",
    "    for i, dic in enumerate(lst):\n",
    "        print(lst)\n",
    "        print(dic)\n",
    "        print(\"********************************************************************\")\n",
    "        if dic[key] == value:\n",
    "            return i\n",
    "            print(\"********************************************************************\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find(lst, \"name\", \"Tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "search_key = \"13075000\"\n",
    "\n",
    "temp = list(input_fle_dict.items())  Station_Nmbr\n",
    "res = list(input_fle_dict.keys()).index(search_key) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
    "    \n",
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "    temp = list(test_dict.items())  \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0] == search_key] \n",
    "    \n",
    "    \n",
    "    input_fle_dict[\"Data\"][0][\"streamflow_rate\"] = input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Data/Idaho_Streamflow_Data/13206000.txt\", \"r\")\n",
    "lines = file.readlines()[26:]\n",
    "\n",
    "print(type(lines))\n",
    "print(lines)\n",
    "\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a Row from the List\n",
    "#     - https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del lines[0:1]\n",
    "lines\n",
    "# print((lines[1].split(\"\\t\")))\n",
    "test = lines[1][:-1].split(\"\\t\")\n",
    "test\n",
    "\n",
    "a_series = pd.Series(test, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Text File and Convert to a Dataframe\n",
    "data = pd.read_csv('Data/Idaho_Streamflow_Data/13206000.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Empty Rows\n",
    "import numpy as np\n",
    "np.where(pd.isnull(statn_table_df_splt_StatnNmbr_nmbrs_clmn))\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"] = statn_table_df[\"StationNumber\"].astype(str)\n",
    "print(statn_table.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if \"County\" in statn_table[\"StationNumber\"][0]:\n",
    "        print(\"true\")\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([0, 4], axis = 0)\n",
    "statn_table_df_drp_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the County Names from the Table\n",
    "# test = statn_table.drop([0, 4], axis = 0)\n",
    "# test.head()\n",
    "\n",
    "# Count the number of Rows in the Dataframe\n",
    "count = 0\n",
    "for statn_table_df_row in statn_table_df.index:\n",
    "\n",
    "    if \"County\" in statn_table_df[\"StationNumber\"][statn_table_df_row]:\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([statn_table_df_row], axis = 0)\n",
    "        count = count + 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_drp_cnty.head(15)\n",
    "# statn_table_df_drp_cnty.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statn_table_df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# Select(driver.find_element_by_id('rdb'))\n",
    "\n",
    "tab_sprtd_rado = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(tab_sprtd_rado)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# url = \"https://www.usgs.gov/\"\n",
    "browser.visit(url)\n",
    "window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Collect the latest News Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
