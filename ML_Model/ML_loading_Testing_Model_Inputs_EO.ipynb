{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES\n",
    "# FOR DATA\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "# import requests\n",
    "# import datefinder\n",
    "\n",
    "# # FOR SQL LITE\n",
    "# from sqlalchemy import create_engine\n",
    "# from datetime import date\n",
    "\n",
    "# # FOR PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "# FOR MODELING\n",
    "from scipy.optimize import curve_fit\n",
    "# from splinter import Browser\n",
    "# from bs4 import BeautifulSoup as BS\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('NN_fireClassModel.pkl', 'rb') as f:\n",
    "    fireClassModel = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test set score: {fireClassModel.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEAN UP AND REMOVE UNWANTED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get dummy variables for nominal property column\n",
    "# # idaho_Fire_Weather_df = pd.get_dummies(idaho_Fire_Weather_df, columns=[\"FIRE_SIZE_CLASS\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"CITY\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"NAME\"])\n",
    "\n",
    "# # FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# # # replace values in each column according to the dictionaries above\n",
    "# # clean_fires_Idaho_2000_2015_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "# idaho_Fire_Weather_Drought_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables for nominal property column\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"NAME\"])\n",
    "\n",
    "# FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# # replace values in each column according to the dictionaries above\n",
    "# idaho_Fire_Weather_Drought_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "# idaho_Fire_Weather_Drought_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and associate cities using the lat lng coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FPA_ID</th>\n",
       "      <th>SOURCE_SYSTEM_TYPE</th>\n",
       "      <th>SOURCE_SYSTEM</th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "      <th>DAY_PRCP_1</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>155</td>\n",
       "      <td>FS-1419238</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.08</td>\n",
       "      <td>69.98</td>\n",
       "      <td>71.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>FS-1419278</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-07-01</td>\n",
       "      <td>2005-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.04</td>\n",
       "      <td>62.06</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>FS-1419291</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-07-03</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>FS-1419292</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-07-03</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>FS-1419293</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-07-06</td>\n",
       "      <td>2005-07-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64.94</td>\n",
       "      <td>68.00</td>\n",
       "      <td>71.96</td>\n",
       "      <td>71.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15482</td>\n",
       "      <td>15482</td>\n",
       "      <td>1847559</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847559</td>\n",
       "      <td>300274043</td>\n",
       "      <td>SFO-2015IDIDL2202015025</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-05</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.26</td>\n",
       "      <td>58.28</td>\n",
       "      <td>48.92</td>\n",
       "      <td>49.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15483</td>\n",
       "      <td>15483</td>\n",
       "      <td>1847684</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847684</td>\n",
       "      <td>300274204</td>\n",
       "      <td>SFO-2015IDIDL2102015023</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-10</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.28</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15484</td>\n",
       "      <td>15484</td>\n",
       "      <td>1847710</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847710</td>\n",
       "      <td>300274236</td>\n",
       "      <td>SFO-2015IDIDL2102015021</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15485</td>\n",
       "      <td>15485</td>\n",
       "      <td>1847762</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847762</td>\n",
       "      <td>300274306</td>\n",
       "      <td>SFO-2015IDIDL9802015030</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-13</td>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.28</td>\n",
       "      <td>58.46</td>\n",
       "      <td>61.52</td>\n",
       "      <td>63.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15486</td>\n",
       "      <td>15486</td>\n",
       "      <td>1848009</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1848009</td>\n",
       "      <td>300274600</td>\n",
       "      <td>SFO-2015IDIDL2102015024</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.18</td>\n",
       "      <td>51.80</td>\n",
       "      <td>53.06</td>\n",
       "      <td>55.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15487 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  OBJECTID  Shape  Join_Count  TARGET_FID     FOD_ID  \\\n",
       "0               0       152  Point           1         152        155   \n",
       "1               1       169  Point           1         169        172   \n",
       "2               2       173  Point           1         173        176   \n",
       "3               3       174  Point           1         174        177   \n",
       "4               4       175  Point           1         175        178   \n",
       "...           ...       ...    ...         ...         ...        ...   \n",
       "15482       15482   1847559  Point           1     1847559  300274043   \n",
       "15483       15483   1847684  Point           1     1847684  300274204   \n",
       "15484       15484   1847710  Point           1     1847710  300274236   \n",
       "15485       15485   1847762  Point           1     1847762  300274306   \n",
       "15486       15486   1848009  Point           1     1848009  300274600   \n",
       "\n",
       "                        FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
       "0                   FS-1419238                FED   FS-FIRESTAT   \n",
       "1                   FS-1419278                FED   FS-FIRESTAT   \n",
       "2                   FS-1419291                FED   FS-FIRESTAT   \n",
       "3                   FS-1419292                FED   FS-FIRESTAT   \n",
       "4                   FS-1419293                FED   FS-FIRESTAT   \n",
       "...                        ...                ...           ...   \n",
       "15482  SFO-2015IDIDL2202015025             NONFED       ST-NASF   \n",
       "15483  SFO-2015IDIDL2102015023             NONFED       ST-NASF   \n",
       "15484  SFO-2015IDIDL2102015021             NONFED       ST-NASF   \n",
       "15485  SFO-2015IDIDL9802015030             NONFED       ST-NASF   \n",
       "15486  SFO-2015IDIDL2102015024             NONFED       ST-NASF   \n",
       "\n",
       "      NWCG_REPORTING_AGENCY  ...        DAY3        DAY4 DAY_PRCP_1  \\\n",
       "0                        FS  ...  2005-07-15  2005-07-16        0.5   \n",
       "1                        FS  ...  2005-07-01  2005-07-02        0.0   \n",
       "2                        FS  ...  2005-07-03  2005-07-04        0.0   \n",
       "3                        FS  ...  2005-07-03  2005-07-04        0.0   \n",
       "4                        FS  ...  2005-07-06  2005-07-07        0.0   \n",
       "...                     ...  ...         ...         ...        ...   \n",
       "15482                ST/C&L  ...  2015-10-05  2015-10-06        1.3   \n",
       "15483                ST/C&L  ...  2015-10-10  2015-10-11        0.2   \n",
       "15484                ST/C&L  ...  2015-10-11  2015-10-12        0.0   \n",
       "15485                ST/C&L  ...  2015-10-13  2015-10-14        0.0   \n",
       "15486                ST/C&L  ...  2015-10-16  2015-10-17        0.0   \n",
       "\n",
       "      DAY_PRCP_2  DAY_PRCP_3 DAY_PRCP_4 DAY_AVG_TEMP_1 DAY_AVG_TEMP_2  \\\n",
       "0            0.0         0.0        0.0          77.00          69.08   \n",
       "1            0.0         0.0        0.0          64.04          62.06   \n",
       "2            0.0         0.0        0.0          69.08          66.92   \n",
       "3            0.0         0.0        0.0          69.08          66.92   \n",
       "4            0.0         0.0        0.8          64.94          68.00   \n",
       "...          ...         ...        ...            ...            ...   \n",
       "15482        0.0         0.0        0.0          60.26          58.28   \n",
       "15483        0.0         0.9        0.0          58.28          60.08   \n",
       "15484        0.9         0.0        0.0          60.08          66.74   \n",
       "15485        0.0         0.0        0.0          67.28          58.46   \n",
       "15486        0.0         0.0        0.0          50.18          51.80   \n",
       "\n",
       "      DAY_AVG_TEMP_3 DAY_AVG_TEMP_4  \n",
       "0              69.98          71.06  \n",
       "1              69.08          66.92  \n",
       "2              64.04          64.94  \n",
       "3              64.04          64.94  \n",
       "4              71.96          71.96  \n",
       "...              ...            ...  \n",
       "15482          48.92          49.64  \n",
       "15483          66.74          59.36  \n",
       "15484          59.36          50.00  \n",
       "15485          61.52          63.68  \n",
       "15486          53.06          55.40  \n",
       "\n",
       "[15487 rows x 116 columns]"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idaho_Fire_Weather_Drought_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Avg for values\n",
    "Day1_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_1'].mean()\n",
    "Day2_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_2'].mean()\n",
    "Day3_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_3'].mean()\n",
    "Day4_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_4'].mean()\n",
    "Day1_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'].mean()\n",
    "Day2_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'].mean()\n",
    "Day3_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'].mean()\n",
    "Day4_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'].mean()\n",
    "\n",
    "# Use Avg values to fill any null values\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_1'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_1'].fillna(Day1_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_2'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_2'].fillna(Day2_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_3'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_3'].fillna(Day3_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_4'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_4'].fillna(Day4_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'].fillna(Day1_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'].fillna(Day2_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'].fillna(Day3_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'].fillna(Day4_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>DISCOVERY_DATE_CONVERTED</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>AVE_SIZE12</th>\n",
       "      <th>CROP_ACR12</th>\n",
       "      <th>None</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>DAY_PRCP_1</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>FIRE_SIZE_CLASS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039485</td>\n",
       "      <td>-0.032507</td>\n",
       "      <td>0.160932</td>\n",
       "      <td>0.157311</td>\n",
       "      <td>-0.065962</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.088865</td>\n",
       "      <td>0.034377</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>-0.029500</td>\n",
       "      <td>-0.054438</td>\n",
       "      <td>-0.074597</td>\n",
       "      <td>-0.076990</td>\n",
       "      <td>0.012327</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.043590</td>\n",
       "      <td>0.078059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DISCOVERY_DATE_CONVERTED</td>\n",
       "      <td>-0.039485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051657</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>-0.107652</td>\n",
       "      <td>0.106430</td>\n",
       "      <td>0.090870</td>\n",
       "      <td>0.134617</td>\n",
       "      <td>0.152003</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>-0.028344</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>-0.010255</td>\n",
       "      <td>-0.033419</td>\n",
       "      <td>-0.061273</td>\n",
       "      <td>-0.110434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FIRE_YEAR</td>\n",
       "      <td>-0.032507</td>\n",
       "      <td>-0.051657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.140139</td>\n",
       "      <td>-0.188722</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>-0.119810</td>\n",
       "      <td>-0.163571</td>\n",
       "      <td>-0.202830</td>\n",
       "      <td>-0.168943</td>\n",
       "      <td>-0.114602</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.026526</td>\n",
       "      <td>0.037010</td>\n",
       "      <td>0.111129</td>\n",
       "      <td>0.107039</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>0.104179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVE_SIZE12</td>\n",
       "      <td>0.160932</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>-0.140139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571380</td>\n",
       "      <td>-0.137073</td>\n",
       "      <td>0.131352</td>\n",
       "      <td>0.135573</td>\n",
       "      <td>0.091559</td>\n",
       "      <td>0.083473</td>\n",
       "      <td>0.046812</td>\n",
       "      <td>-0.006052</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>-0.013977</td>\n",
       "      <td>0.036630</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.060058</td>\n",
       "      <td>0.059310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CROP_ACR12</td>\n",
       "      <td>0.157311</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>-0.188722</td>\n",
       "      <td>0.571380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.135187</td>\n",
       "      <td>0.135277</td>\n",
       "      <td>0.141688</td>\n",
       "      <td>0.108183</td>\n",
       "      <td>0.132088</td>\n",
       "      <td>0.102180</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>-0.023994</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>-0.012188</td>\n",
       "      <td>-0.050913</td>\n",
       "      <td>-0.056902</td>\n",
       "      <td>-0.044874</td>\n",
       "      <td>-0.022190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>None</td>\n",
       "      <td>-0.065962</td>\n",
       "      <td>-0.107652</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>-0.137073</td>\n",
       "      <td>-0.135187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.995751</td>\n",
       "      <td>-0.723732</td>\n",
       "      <td>-0.472200</td>\n",
       "      <td>-0.248983</td>\n",
       "      <td>-0.087706</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>-0.011360</td>\n",
       "      <td>-0.008045</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.025653</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>0.032694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D0</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.106430</td>\n",
       "      <td>-0.119810</td>\n",
       "      <td>0.131352</td>\n",
       "      <td>0.135277</td>\n",
       "      <td>-0.995751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726378</td>\n",
       "      <td>0.473902</td>\n",
       "      <td>0.249879</td>\n",
       "      <td>0.088022</td>\n",
       "      <td>-0.008279</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>-0.008942</td>\n",
       "      <td>-0.024527</td>\n",
       "      <td>-0.037737</td>\n",
       "      <td>-0.033154</td>\n",
       "      <td>-0.031903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D1</td>\n",
       "      <td>0.088865</td>\n",
       "      <td>0.090870</td>\n",
       "      <td>-0.163571</td>\n",
       "      <td>0.135573</td>\n",
       "      <td>0.141688</td>\n",
       "      <td>-0.723732</td>\n",
       "      <td>0.726378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703901</td>\n",
       "      <td>0.373141</td>\n",
       "      <td>0.131763</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>-0.023422</td>\n",
       "      <td>-0.035005</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>-0.015709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D2</td>\n",
       "      <td>0.034377</td>\n",
       "      <td>0.134617</td>\n",
       "      <td>-0.202830</td>\n",
       "      <td>0.091559</td>\n",
       "      <td>0.108183</td>\n",
       "      <td>-0.472200</td>\n",
       "      <td>0.473902</td>\n",
       "      <td>0.703901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587261</td>\n",
       "      <td>0.211572</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>-0.023274</td>\n",
       "      <td>-0.079071</td>\n",
       "      <td>-0.090207</td>\n",
       "      <td>-0.092614</td>\n",
       "      <td>-0.089342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D3</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.152003</td>\n",
       "      <td>-0.168943</td>\n",
       "      <td>0.083473</td>\n",
       "      <td>0.132088</td>\n",
       "      <td>-0.248983</td>\n",
       "      <td>0.249879</td>\n",
       "      <td>0.373141</td>\n",
       "      <td>0.587261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425661</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.012214</td>\n",
       "      <td>-0.020633</td>\n",
       "      <td>-0.018498</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>-0.125164</td>\n",
       "      <td>-0.131088</td>\n",
       "      <td>-0.120926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D4</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>-0.114602</td>\n",
       "      <td>0.046812</td>\n",
       "      <td>0.102180</td>\n",
       "      <td>-0.087706</td>\n",
       "      <td>0.088022</td>\n",
       "      <td>0.131763</td>\n",
       "      <td>0.211572</td>\n",
       "      <td>0.425661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>-0.053431</td>\n",
       "      <td>-0.074054</td>\n",
       "      <td>-0.073701</td>\n",
       "      <td>-0.069552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_1</td>\n",
       "      <td>-0.029500</td>\n",
       "      <td>-0.028344</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>-0.006052</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>-0.008279</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135768</td>\n",
       "      <td>0.050506</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>-0.114486</td>\n",
       "      <td>-0.149527</td>\n",
       "      <td>-0.121413</td>\n",
       "      <td>-0.091950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_2</td>\n",
       "      <td>-0.054438</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>-0.023994</td>\n",
       "      <td>-0.011360</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.012214</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.135768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129404</td>\n",
       "      <td>0.033576</td>\n",
       "      <td>-0.021438</td>\n",
       "      <td>-0.096657</td>\n",
       "      <td>-0.131440</td>\n",
       "      <td>-0.105085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_3</td>\n",
       "      <td>-0.074597</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.026526</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>-0.008045</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>-0.020633</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.050506</td>\n",
       "      <td>0.129404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090678</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>-0.073328</td>\n",
       "      <td>-0.134258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_4</td>\n",
       "      <td>-0.076990</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.037010</td>\n",
       "      <td>-0.013977</td>\n",
       "      <td>-0.012188</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>-0.008942</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>-0.023274</td>\n",
       "      <td>-0.018498</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>0.033576</td>\n",
       "      <td>0.090678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.074231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_1</td>\n",
       "      <td>0.012327</td>\n",
       "      <td>-0.010255</td>\n",
       "      <td>0.111129</td>\n",
       "      <td>0.036630</td>\n",
       "      <td>-0.050913</td>\n",
       "      <td>0.025653</td>\n",
       "      <td>-0.024527</td>\n",
       "      <td>-0.023422</td>\n",
       "      <td>-0.079071</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>-0.053431</td>\n",
       "      <td>-0.114486</td>\n",
       "      <td>-0.021438</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881935</td>\n",
       "      <td>0.777410</td>\n",
       "      <td>0.703229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_2</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>-0.033419</td>\n",
       "      <td>0.107039</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>-0.056902</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>-0.037737</td>\n",
       "      <td>-0.035005</td>\n",
       "      <td>-0.090207</td>\n",
       "      <td>-0.125164</td>\n",
       "      <td>-0.074054</td>\n",
       "      <td>-0.149527</td>\n",
       "      <td>-0.096657</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.881935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874621</td>\n",
       "      <td>0.759900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_3</td>\n",
       "      <td>0.043590</td>\n",
       "      <td>-0.061273</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>0.060058</td>\n",
       "      <td>-0.044874</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>-0.033154</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>-0.092614</td>\n",
       "      <td>-0.131088</td>\n",
       "      <td>-0.073701</td>\n",
       "      <td>-0.121413</td>\n",
       "      <td>-0.131440</td>\n",
       "      <td>-0.073328</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.777410</td>\n",
       "      <td>0.874621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_4</td>\n",
       "      <td>0.078059</td>\n",
       "      <td>-0.110434</td>\n",
       "      <td>0.104179</td>\n",
       "      <td>0.059310</td>\n",
       "      <td>-0.022190</td>\n",
       "      <td>0.032694</td>\n",
       "      <td>-0.031903</td>\n",
       "      <td>-0.015709</td>\n",
       "      <td>-0.089342</td>\n",
       "      <td>-0.120926</td>\n",
       "      <td>-0.069552</td>\n",
       "      <td>-0.091950</td>\n",
       "      <td>-0.105085</td>\n",
       "      <td>-0.134258</td>\n",
       "      <td>-0.074231</td>\n",
       "      <td>0.703229</td>\n",
       "      <td>0.759900</td>\n",
       "      <td>0.853114</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FIRE_SIZE_CLASS  DISCOVERY_DATE_CONVERTED  \\\n",
       "FIRE_SIZE_CLASS                  1.000000                 -0.039485   \n",
       "DISCOVERY_DATE_CONVERTED        -0.039485                  1.000000   \n",
       "FIRE_YEAR                       -0.032507                 -0.051657   \n",
       "AVE_SIZE12                       0.160932                  0.027828   \n",
       "CROP_ACR12                       0.157311                  0.002336   \n",
       "None                            -0.065962                 -0.107652   \n",
       "D0                               0.066057                  0.106430   \n",
       "D1                               0.088865                  0.090870   \n",
       "D2                               0.034377                  0.134617   \n",
       "D3                               0.006644                  0.152003   \n",
       "D4                              -0.003103                  0.044361   \n",
       "DAY_PRCP_1                      -0.029500                 -0.028344   \n",
       "DAY_PRCP_2                      -0.054438                  0.012246   \n",
       "DAY_PRCP_3                      -0.074597                  0.028762   \n",
       "DAY_PRCP_4                      -0.076990                  0.009134   \n",
       "DAY_AVG_TEMP_1                   0.012327                 -0.010255   \n",
       "DAY_AVG_TEMP_2                   0.011437                 -0.033419   \n",
       "DAY_AVG_TEMP_3                   0.043590                 -0.061273   \n",
       "DAY_AVG_TEMP_4                   0.078059                 -0.110434   \n",
       "\n",
       "                          FIRE_YEAR  AVE_SIZE12  CROP_ACR12      None  \\\n",
       "FIRE_SIZE_CLASS           -0.032507    0.160932    0.157311 -0.065962   \n",
       "DISCOVERY_DATE_CONVERTED  -0.051657    0.027828    0.002336 -0.107652   \n",
       "FIRE_YEAR                  1.000000   -0.140139   -0.188722  0.122336   \n",
       "AVE_SIZE12                -0.140139    1.000000    0.571380 -0.137073   \n",
       "CROP_ACR12                -0.188722    0.571380    1.000000 -0.135187   \n",
       "None                       0.122336   -0.137073   -0.135187  1.000000   \n",
       "D0                        -0.119810    0.131352    0.135277 -0.995751   \n",
       "D1                        -0.163571    0.135573    0.141688 -0.723732   \n",
       "D2                        -0.202830    0.091559    0.108183 -0.472200   \n",
       "D3                        -0.168943    0.083473    0.132088 -0.248983   \n",
       "D4                        -0.114602    0.046812    0.102180 -0.087706   \n",
       "DAY_PRCP_1                 0.033148   -0.006052   -0.004251  0.008517   \n",
       "DAY_PRCP_2                 0.047487   -0.018983   -0.023994 -0.011360   \n",
       "DAY_PRCP_3                 0.026526   -0.006477   -0.031849 -0.008045   \n",
       "DAY_PRCP_4                 0.037010   -0.013977   -0.012188  0.009782   \n",
       "DAY_AVG_TEMP_1             0.111129    0.036630   -0.050913  0.025653   \n",
       "DAY_AVG_TEMP_2             0.107039    0.044597   -0.056902  0.039470   \n",
       "DAY_AVG_TEMP_3             0.100226    0.060058   -0.044874  0.034612   \n",
       "DAY_AVG_TEMP_4             0.104179    0.059310   -0.022190  0.032694   \n",
       "\n",
       "                                D0        D1        D2        D3        D4  \\\n",
       "FIRE_SIZE_CLASS           0.066057  0.088865  0.034377  0.006644 -0.003103   \n",
       "DISCOVERY_DATE_CONVERTED  0.106430  0.090870  0.134617  0.152003  0.044361   \n",
       "FIRE_YEAR                -0.119810 -0.163571 -0.202830 -0.168943 -0.114602   \n",
       "AVE_SIZE12                0.131352  0.135573  0.091559  0.083473  0.046812   \n",
       "CROP_ACR12                0.135277  0.141688  0.108183  0.132088  0.102180   \n",
       "None                     -0.995751 -0.723732 -0.472200 -0.248983 -0.087706   \n",
       "D0                        1.000000  0.726378  0.473902  0.249879  0.088022   \n",
       "D1                        0.726378  1.000000  0.703901  0.373141  0.131763   \n",
       "D2                        0.473902  0.703901  1.000000  0.587261  0.211572   \n",
       "D3                        0.249879  0.373141  0.587261  1.000000  0.425661   \n",
       "D4                        0.088022  0.131763  0.211572  0.425661  1.000000   \n",
       "DAY_PRCP_1               -0.008279  0.006715  0.022861 -0.004332  0.001443   \n",
       "DAY_PRCP_2                0.010693  0.008598  0.010859 -0.012214  0.001041   \n",
       "DAY_PRCP_3                0.007879 -0.006008  0.010129 -0.020633  0.001154   \n",
       "DAY_PRCP_4               -0.008942 -0.033356 -0.023274 -0.018498 -0.001889   \n",
       "DAY_AVG_TEMP_1           -0.024527 -0.023422 -0.079071 -0.120081 -0.053431   \n",
       "DAY_AVG_TEMP_2           -0.037737 -0.035005 -0.090207 -0.125164 -0.074054   \n",
       "DAY_AVG_TEMP_3           -0.033154 -0.027347 -0.092614 -0.131088 -0.073701   \n",
       "DAY_AVG_TEMP_4           -0.031903 -0.015709 -0.089342 -0.120926 -0.069552   \n",
       "\n",
       "                          DAY_PRCP_1  DAY_PRCP_2  DAY_PRCP_3  DAY_PRCP_4  \\\n",
       "FIRE_SIZE_CLASS            -0.029500   -0.054438   -0.074597   -0.076990   \n",
       "DISCOVERY_DATE_CONVERTED   -0.028344    0.012246    0.028762    0.009134   \n",
       "FIRE_YEAR                   0.033148    0.047487    0.026526    0.037010   \n",
       "AVE_SIZE12                 -0.006052   -0.018983   -0.006477   -0.013977   \n",
       "CROP_ACR12                 -0.004251   -0.023994   -0.031849   -0.012188   \n",
       "None                        0.008517   -0.011360   -0.008045    0.009782   \n",
       "D0                         -0.008279    0.010693    0.007879   -0.008942   \n",
       "D1                          0.006715    0.008598   -0.006008   -0.033356   \n",
       "D2                          0.022861    0.010859    0.010129   -0.023274   \n",
       "D3                         -0.004332   -0.012214   -0.020633   -0.018498   \n",
       "D4                          0.001443    0.001041    0.001154   -0.001889   \n",
       "DAY_PRCP_1                  1.000000    0.135768    0.050506    0.010305   \n",
       "DAY_PRCP_2                  0.135768    1.000000    0.129404    0.033576   \n",
       "DAY_PRCP_3                  0.050506    0.129404    1.000000    0.090678   \n",
       "DAY_PRCP_4                  0.010305    0.033576    0.090678    1.000000   \n",
       "DAY_AVG_TEMP_1             -0.114486   -0.021438    0.007686    0.018046   \n",
       "DAY_AVG_TEMP_2             -0.149527   -0.096657   -0.011680    0.023598   \n",
       "DAY_AVG_TEMP_3             -0.121413   -0.131440   -0.073328    0.000100   \n",
       "DAY_AVG_TEMP_4             -0.091950   -0.105085   -0.134258   -0.074231   \n",
       "\n",
       "                          DAY_AVG_TEMP_1  DAY_AVG_TEMP_2  DAY_AVG_TEMP_3  \\\n",
       "FIRE_SIZE_CLASS                 0.012327        0.011437        0.043590   \n",
       "DISCOVERY_DATE_CONVERTED       -0.010255       -0.033419       -0.061273   \n",
       "FIRE_YEAR                       0.111129        0.107039        0.100226   \n",
       "AVE_SIZE12                      0.036630        0.044597        0.060058   \n",
       "CROP_ACR12                     -0.050913       -0.056902       -0.044874   \n",
       "None                            0.025653        0.039470        0.034612   \n",
       "D0                             -0.024527       -0.037737       -0.033154   \n",
       "D1                             -0.023422       -0.035005       -0.027347   \n",
       "D2                             -0.079071       -0.090207       -0.092614   \n",
       "D3                             -0.120081       -0.125164       -0.131088   \n",
       "D4                             -0.053431       -0.074054       -0.073701   \n",
       "DAY_PRCP_1                     -0.114486       -0.149527       -0.121413   \n",
       "DAY_PRCP_2                     -0.021438       -0.096657       -0.131440   \n",
       "DAY_PRCP_3                      0.007686       -0.011680       -0.073328   \n",
       "DAY_PRCP_4                      0.018046        0.023598        0.000100   \n",
       "DAY_AVG_TEMP_1                  1.000000        0.881935        0.777410   \n",
       "DAY_AVG_TEMP_2                  0.881935        1.000000        0.874621   \n",
       "DAY_AVG_TEMP_3                  0.777410        0.874621        1.000000   \n",
       "DAY_AVG_TEMP_4                  0.703229        0.759900        0.853114   \n",
       "\n",
       "                          DAY_AVG_TEMP_4  \n",
       "FIRE_SIZE_CLASS                 0.078059  \n",
       "DISCOVERY_DATE_CONVERTED       -0.110434  \n",
       "FIRE_YEAR                       0.104179  \n",
       "AVE_SIZE12                      0.059310  \n",
       "CROP_ACR12                     -0.022190  \n",
       "None                            0.032694  \n",
       "D0                             -0.031903  \n",
       "D1                             -0.015709  \n",
       "D2                             -0.089342  \n",
       "D3                             -0.120926  \n",
       "D4                             -0.069552  \n",
       "DAY_PRCP_1                     -0.091950  \n",
       "DAY_PRCP_2                     -0.105085  \n",
       "DAY_PRCP_3                     -0.134258  \n",
       "DAY_PRCP_4                     -0.074231  \n",
       "DAY_AVG_TEMP_1                  0.703229  \n",
       "DAY_AVG_TEMP_2                  0.759900  \n",
       "DAY_AVG_TEMP_3                  0.853114  \n",
       "DAY_AVG_TEMP_4                  1.000000  "
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_df = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'DISCOVERY_DATE_CONVERTED', 'FIRE_YEAR', 'STAT_CAUSE_DESCR', 'AVE_SIZE12', 'CROP_ACR12', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "                                   'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# Corr_df = idaho_Fire_Weather_Drought_df[['NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "#                                    'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "    \n",
    "Corr_df['FIRE_SIZE_CLASS']= Corr_df['FIRE_SIZE_CLASS'].astype('category').cat.codes\n",
    "\n",
    "Corr_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING A NEURAL NETWORK MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INVESTIGATING INPUTS\n",
    "# # Possible X columns\n",
    "# # [['DISCOVERY_DATE_CONVERTED', 'FIRE_SIZE_CLASS', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', \n",
    "# #   'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# New_df = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_DATE_CONVERTED', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "#                                    'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "# New_df['FIRE_SIZE_CLASS']= New_df['FIRE_SIZE_CLASS'].astype('category').cat.codes\n",
    "# # New_df['AVE_FAM_SZ']= New_df['AVE_FAM_SZ'].apply(lambda x: x//1)\n",
    "\n",
    "# # Drop Y column\n",
    "# New_df = New_df.drop(['FIRE_SIZE_CLASS'], axis=1)\n",
    "# New_df = New_df.drop(['STAT_CAUSE_DESCR'], axis=1)\n",
    "\n",
    "# # Run PCA \n",
    "# from sklearn.decomposition import PCA\n",
    "# n_components=40\n",
    "# pca = PCA(n_components=n_components)\n",
    "\n",
    "# # Create multiple columns for County \"NAME\"\n",
    "# New_df = pd.get_dummies(New_df, columns=['NAME'])\n",
    "# # New_df = pd.get_dummies(New_df, columns=['STAT_CAUSE_DESCR'])\n",
    "\n",
    "# NoOfCols = n_components\n",
    "\n",
    "# X_Array = New_df.to_numpy()\n",
    "# pca.fit(X_Array)\n",
    "# # print(pca.singular_values_)\n",
    "# x = pca.transform(X_Array)\n",
    "# x\n",
    "# # print(x.shape)\n",
    "# # type(x)\n",
    "# # x\n",
    "\n",
    "# NoOfCols = n_components\n",
    "# NoOfRuns = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15487, 69)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE X VALUES\n",
    "# X by Keep\n",
    "X = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'DISCOVERY_DATE_CONVERTED', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "                                   'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# Either Or\n",
    "X = X.drop(['FIRE_SIZE_CLASS'], axis=1)\n",
    "# X = pd.get_dummies(X, columns=['FIRE_SIZE_CLASS'])\n",
    "X = pd.get_dummies(X, columns=['NAME'])\n",
    "\n",
    "NoOfCols = 69\n",
    "NoOfRuns = 1000\n",
    "X = X.values.reshape(-1, NoOfCols)\n",
    "\n",
    "# X = X.to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "type(X)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15487, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE y VALUES\n",
    "y = idaho_Fire_Weather_Drought_df[['STAT_CAUSE_DESCR']]\n",
    "\n",
    "# y = idaho_Fire_Weather_Drought_df[['STAT_CAUSE_DESCR', 'FIRE_SIZE_CLASS']]\n",
    "# y = pd.get_dummies(y, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "\n",
    "# y = y.values.reshape(-1, 2)\n",
    "\n",
    "# print(y.shape)\n",
    "# # type(y)\n",
    "# y\n",
    "\n",
    "# LABEL ENCODE Y\n",
    "# Import required module\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create an object of the label encoder class\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# apply \"le.fit_transform\"\n",
    "old_y = y.apply(le.fit_transform)\n",
    "y = old_y\n",
    "\n",
    "# # Change the shape of y v1\n",
    "new_y = np.array(old_y)\n",
    "y = new_y.reshape(-1, 1) \n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AND TRIAN SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11615, 69)\n"
     ]
    }
   ],
   "source": [
    "# # Scale your data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# # y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# # Create variables to hold the scaled train & test data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# # y_train_scaled = y_scaler.transform(y_train)\n",
    "# # y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encode the categorical target variable to the necessary format for the model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 neural network models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11615, 69)"
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X Inputs\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11615, 69)\n",
      "(11615, 69)\n",
      "(11615, 13)\n"
     ]
    }
   ],
   "source": [
    "# X Inputs\n",
    "print(X_train.shape)\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "# Y Inputs\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_326 (Dense)            (None, 20)                1400      \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 22,277\n",
      "Trainable params: 22,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Normal neural network with X inputs, 1 hidden layer, 10 nodes in hidden layer, and 7 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "fire_cause_model_v1 = Sequential()\n",
    "fire_cause_model_v1.add(Dense(units=20, activation='sigmoid', input_dim=NoOfCols))\n",
    "fire_cause_model_v1.add(Dense(128, activation='relu'))\n",
    "fire_cause_model_v1.add(Dropout(.1))\n",
    "fire_cause_model_v1.add(Dense(128, activation='relu'))\n",
    "fire_cause_model_v1.add(Dense(units=13, activation='softmax'))\n",
    "\n",
    "# view the model's architecture\n",
    "fire_cause_model_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "363/363 - 1s - loss: 1.4044 - accuracy: 0.6232\n",
      "Epoch 2/1000\n",
      "363/363 - 0s - loss: 1.3306 - accuracy: 0.6297\n",
      "Epoch 3/1000\n",
      "363/363 - 0s - loss: 1.2980 - accuracy: 0.6365\n",
      "Epoch 4/1000\n",
      "363/363 - 0s - loss: 1.2544 - accuracy: 0.6505\n",
      "Epoch 5/1000\n",
      "363/363 - 0s - loss: 1.2110 - accuracy: 0.6603\n",
      "Epoch 6/1000\n",
      "363/363 - 0s - loss: 1.1857 - accuracy: 0.6633\n",
      "Epoch 7/1000\n",
      "363/363 - 0s - loss: 1.1690 - accuracy: 0.6657\n",
      "Epoch 8/1000\n",
      "363/363 - 0s - loss: 1.1578 - accuracy: 0.6700\n",
      "Epoch 9/1000\n",
      "363/363 - 0s - loss: 1.1447 - accuracy: 0.6682\n",
      "Epoch 10/1000\n",
      "363/363 - 0s - loss: 1.1344 - accuracy: 0.6725\n",
      "Epoch 11/1000\n",
      "363/363 - 0s - loss: 1.1288 - accuracy: 0.6734\n",
      "Epoch 12/1000\n",
      "363/363 - 0s - loss: 1.1220 - accuracy: 0.6744\n",
      "Epoch 13/1000\n",
      "363/363 - 0s - loss: 1.1125 - accuracy: 0.6742\n",
      "Epoch 14/1000\n",
      "363/363 - 0s - loss: 1.1043 - accuracy: 0.6769\n",
      "Epoch 15/1000\n",
      "363/363 - 0s - loss: 1.1053 - accuracy: 0.6763\n",
      "Epoch 16/1000\n",
      "363/363 - 0s - loss: 1.0983 - accuracy: 0.6783\n",
      "Epoch 17/1000\n",
      "363/363 - 0s - loss: 1.0939 - accuracy: 0.6788\n",
      "Epoch 18/1000\n",
      "363/363 - 0s - loss: 1.0933 - accuracy: 0.6814\n",
      "Epoch 19/1000\n",
      "363/363 - 0s - loss: 1.0872 - accuracy: 0.6812\n",
      "Epoch 20/1000\n",
      "363/363 - 0s - loss: 1.0888 - accuracy: 0.6820\n",
      "Epoch 21/1000\n",
      "363/363 - 0s - loss: 1.0749 - accuracy: 0.6844\n",
      "Epoch 22/1000\n",
      "363/363 - 0s - loss: 1.0759 - accuracy: 0.6829\n",
      "Epoch 23/1000\n",
      "363/363 - 0s - loss: 1.0748 - accuracy: 0.6867\n",
      "Epoch 24/1000\n",
      "363/363 - 0s - loss: 1.0692 - accuracy: 0.6855\n",
      "Epoch 25/1000\n",
      "363/363 - 0s - loss: 1.0668 - accuracy: 0.6876\n",
      "Epoch 26/1000\n",
      "363/363 - 0s - loss: 1.0680 - accuracy: 0.6846\n",
      "Epoch 27/1000\n",
      "363/363 - 0s - loss: 1.0596 - accuracy: 0.6864\n",
      "Epoch 28/1000\n",
      "363/363 - 0s - loss: 1.0558 - accuracy: 0.6876\n",
      "Epoch 29/1000\n",
      "363/363 - 0s - loss: 1.0625 - accuracy: 0.6871\n",
      "Epoch 30/1000\n",
      "363/363 - 0s - loss: 1.0519 - accuracy: 0.6913\n",
      "Epoch 31/1000\n",
      "363/363 - 0s - loss: 1.0548 - accuracy: 0.6876\n",
      "Epoch 32/1000\n",
      "363/363 - 0s - loss: 1.0481 - accuracy: 0.6909\n",
      "Epoch 33/1000\n",
      "363/363 - 0s - loss: 1.0438 - accuracy: 0.6898\n",
      "Epoch 34/1000\n",
      "363/363 - 0s - loss: 1.0458 - accuracy: 0.6901\n",
      "Epoch 35/1000\n",
      "363/363 - 0s - loss: 1.0358 - accuracy: 0.6914\n",
      "Epoch 36/1000\n",
      "363/363 - 0s - loss: 1.0385 - accuracy: 0.6932\n",
      "Epoch 37/1000\n",
      "363/363 - 0s - loss: 1.0383 - accuracy: 0.6906\n",
      "Epoch 38/1000\n",
      "363/363 - 0s - loss: 1.0349 - accuracy: 0.6920\n",
      "Epoch 39/1000\n",
      "363/363 - 0s - loss: 1.0314 - accuracy: 0.6930\n",
      "Epoch 40/1000\n",
      "363/363 - 0s - loss: 1.0296 - accuracy: 0.6930\n",
      "Epoch 41/1000\n",
      "363/363 - 0s - loss: 1.0269 - accuracy: 0.6938\n",
      "Epoch 42/1000\n",
      "363/363 - 0s - loss: 1.0222 - accuracy: 0.6941\n",
      "Epoch 43/1000\n",
      "363/363 - 0s - loss: 1.0223 - accuracy: 0.6978\n",
      "Epoch 44/1000\n",
      "363/363 - 0s - loss: 1.0178 - accuracy: 0.6960\n",
      "Epoch 45/1000\n",
      "363/363 - 0s - loss: 1.0154 - accuracy: 0.6976\n",
      "Epoch 46/1000\n",
      "363/363 - 0s - loss: 1.0111 - accuracy: 0.6991\n",
      "Epoch 47/1000\n",
      "363/363 - 0s - loss: 1.0086 - accuracy: 0.6990\n",
      "Epoch 48/1000\n",
      "363/363 - 0s - loss: 1.0082 - accuracy: 0.6987\n",
      "Epoch 49/1000\n",
      "363/363 - 0s - loss: 1.0029 - accuracy: 0.6990\n",
      "Epoch 50/1000\n",
      "363/363 - 0s - loss: 1.0025 - accuracy: 0.7021\n",
      "Epoch 51/1000\n",
      "363/363 - 0s - loss: 0.9970 - accuracy: 0.7019\n",
      "Epoch 52/1000\n",
      "363/363 - 0s - loss: 0.9950 - accuracy: 0.7032\n",
      "Epoch 53/1000\n",
      "363/363 - 0s - loss: 0.9914 - accuracy: 0.7021\n",
      "Epoch 54/1000\n",
      "363/363 - 0s - loss: 0.9920 - accuracy: 0.7019\n",
      "Epoch 55/1000\n",
      "363/363 - 0s - loss: 0.9922 - accuracy: 0.7025\n",
      "Epoch 56/1000\n",
      "363/363 - 0s - loss: 0.9911 - accuracy: 0.7026\n",
      "Epoch 57/1000\n",
      "363/363 - 0s - loss: 0.9900 - accuracy: 0.7054\n",
      "Epoch 58/1000\n",
      "363/363 - 0s - loss: 0.9847 - accuracy: 0.7050\n",
      "Epoch 59/1000\n",
      "363/363 - 0s - loss: 0.9783 - accuracy: 0.7065\n",
      "Epoch 60/1000\n",
      "363/363 - 0s - loss: 0.9785 - accuracy: 0.7044\n",
      "Epoch 61/1000\n",
      "363/363 - 0s - loss: 0.9787 - accuracy: 0.7050\n",
      "Epoch 62/1000\n",
      "363/363 - 0s - loss: 0.9740 - accuracy: 0.7056\n",
      "Epoch 63/1000\n",
      "363/363 - 0s - loss: 0.9693 - accuracy: 0.7078\n",
      "Epoch 64/1000\n",
      "363/363 - 0s - loss: 0.9722 - accuracy: 0.7087\n",
      "Epoch 65/1000\n",
      "363/363 - 0s - loss: 0.9727 - accuracy: 0.7099\n",
      "Epoch 66/1000\n",
      "363/363 - 0s - loss: 0.9667 - accuracy: 0.7079\n",
      "Epoch 67/1000\n",
      "363/363 - 0s - loss: 0.9684 - accuracy: 0.7103\n",
      "Epoch 68/1000\n",
      "363/363 - 0s - loss: 0.9667 - accuracy: 0.7067\n",
      "Epoch 69/1000\n",
      "363/363 - 0s - loss: 0.9609 - accuracy: 0.7120\n",
      "Epoch 70/1000\n",
      "363/363 - 0s - loss: 0.9631 - accuracy: 0.7087\n",
      "Epoch 71/1000\n",
      "363/363 - 0s - loss: 0.9563 - accuracy: 0.7122\n",
      "Epoch 72/1000\n",
      "363/363 - 0s - loss: 0.9587 - accuracy: 0.7098\n",
      "Epoch 73/1000\n",
      "363/363 - 0s - loss: 0.9539 - accuracy: 0.7114\n",
      "Epoch 74/1000\n",
      "363/363 - 0s - loss: 0.9554 - accuracy: 0.7138\n",
      "Epoch 75/1000\n",
      "363/363 - 0s - loss: 0.9448 - accuracy: 0.7139\n",
      "Epoch 76/1000\n",
      "363/363 - 0s - loss: 0.9471 - accuracy: 0.7115\n",
      "Epoch 77/1000\n",
      "363/363 - 0s - loss: 0.9458 - accuracy: 0.7133\n",
      "Epoch 78/1000\n",
      "363/363 - 0s - loss: 0.9454 - accuracy: 0.7140\n",
      "Epoch 79/1000\n",
      "363/363 - 0s - loss: 0.9455 - accuracy: 0.7099\n",
      "Epoch 80/1000\n",
      "363/363 - 0s - loss: 0.9363 - accuracy: 0.7150\n",
      "Epoch 81/1000\n",
      "363/363 - 0s - loss: 0.9326 - accuracy: 0.7139\n",
      "Epoch 82/1000\n",
      "363/363 - 0s - loss: 0.9373 - accuracy: 0.7148\n",
      "Epoch 83/1000\n",
      "363/363 - 0s - loss: 0.9313 - accuracy: 0.7124\n",
      "Epoch 84/1000\n",
      "363/363 - 0s - loss: 0.9344 - accuracy: 0.7130\n",
      "Epoch 85/1000\n",
      "363/363 - 0s - loss: 0.9328 - accuracy: 0.7118\n",
      "Epoch 86/1000\n",
      "363/363 - 0s - loss: 0.9312 - accuracy: 0.7148\n",
      "Epoch 87/1000\n",
      "363/363 - 0s - loss: 0.9303 - accuracy: 0.7165\n",
      "Epoch 88/1000\n",
      "363/363 - 0s - loss: 0.9203 - accuracy: 0.7144\n",
      "Epoch 89/1000\n",
      "363/363 - 0s - loss: 0.9257 - accuracy: 0.7180\n",
      "Epoch 90/1000\n",
      "363/363 - 0s - loss: 0.9252 - accuracy: 0.7150\n",
      "Epoch 91/1000\n",
      "363/363 - 0s - loss: 0.9205 - accuracy: 0.7172\n",
      "Epoch 92/1000\n",
      "363/363 - 0s - loss: 0.9234 - accuracy: 0.7160\n",
      "Epoch 93/1000\n",
      "363/363 - 0s - loss: 0.9201 - accuracy: 0.7192\n",
      "Epoch 94/1000\n",
      "363/363 - 0s - loss: 0.9187 - accuracy: 0.7192\n",
      "Epoch 95/1000\n",
      "363/363 - 0s - loss: 0.9143 - accuracy: 0.7179\n",
      "Epoch 96/1000\n",
      "363/363 - 0s - loss: 0.9101 - accuracy: 0.7205\n",
      "Epoch 97/1000\n",
      "363/363 - 0s - loss: 0.9139 - accuracy: 0.7157\n",
      "Epoch 98/1000\n",
      "363/363 - 0s - loss: 0.9129 - accuracy: 0.7204\n",
      "Epoch 99/1000\n",
      "363/363 - 0s - loss: 0.9112 - accuracy: 0.7206\n",
      "Epoch 100/1000\n",
      "363/363 - 0s - loss: 0.9104 - accuracy: 0.7179\n",
      "Epoch 101/1000\n",
      "363/363 - 0s - loss: 0.9008 - accuracy: 0.7184\n",
      "Epoch 102/1000\n",
      "363/363 - 0s - loss: 0.9054 - accuracy: 0.7203\n",
      "Epoch 103/1000\n",
      "363/363 - 0s - loss: 0.9042 - accuracy: 0.7200\n",
      "Epoch 104/1000\n",
      "363/363 - 0s - loss: 0.9033 - accuracy: 0.7225\n",
      "Epoch 105/1000\n",
      "363/363 - 0s - loss: 0.9048 - accuracy: 0.7219\n",
      "Epoch 106/1000\n",
      "363/363 - 0s - loss: 0.9011 - accuracy: 0.7214\n",
      "Epoch 107/1000\n",
      "363/363 - 0s - loss: 0.8941 - accuracy: 0.7240\n",
      "Epoch 108/1000\n",
      "363/363 - 0s - loss: 0.8981 - accuracy: 0.7224\n",
      "Epoch 109/1000\n",
      "363/363 - 0s - loss: 0.8881 - accuracy: 0.7212\n",
      "Epoch 110/1000\n",
      "363/363 - 0s - loss: 0.8863 - accuracy: 0.7247\n",
      "Epoch 111/1000\n",
      "363/363 - 0s - loss: 0.8871 - accuracy: 0.7227\n",
      "Epoch 112/1000\n",
      "363/363 - 0s - loss: 0.8906 - accuracy: 0.7238\n",
      "Epoch 113/1000\n",
      "363/363 - 0s - loss: 0.8846 - accuracy: 0.7246\n",
      "Epoch 114/1000\n",
      "363/363 - 0s - loss: 0.8836 - accuracy: 0.7257\n",
      "Epoch 115/1000\n",
      "363/363 - 0s - loss: 0.8816 - accuracy: 0.7243\n",
      "Epoch 116/1000\n",
      "363/363 - 0s - loss: 0.8822 - accuracy: 0.7245\n",
      "Epoch 117/1000\n",
      "363/363 - 0s - loss: 0.8861 - accuracy: 0.7253\n",
      "Epoch 118/1000\n",
      "363/363 - 0s - loss: 0.8765 - accuracy: 0.7279\n",
      "Epoch 119/1000\n",
      "363/363 - 0s - loss: 0.8813 - accuracy: 0.7270\n",
      "Epoch 120/1000\n",
      "363/363 - 0s - loss: 0.8741 - accuracy: 0.7270\n",
      "Epoch 121/1000\n",
      "363/363 - 0s - loss: 0.8759 - accuracy: 0.7264\n",
      "Epoch 122/1000\n",
      "363/363 - 0s - loss: 0.8758 - accuracy: 0.7258\n",
      "Epoch 123/1000\n",
      "363/363 - 0s - loss: 0.8700 - accuracy: 0.7297\n",
      "Epoch 124/1000\n",
      "363/363 - 0s - loss: 0.8738 - accuracy: 0.7264\n",
      "Epoch 125/1000\n",
      "363/363 - 0s - loss: 0.8727 - accuracy: 0.7295\n",
      "Epoch 126/1000\n",
      "363/363 - 0s - loss: 0.8640 - accuracy: 0.7290\n",
      "Epoch 127/1000\n",
      "363/363 - 0s - loss: 0.8673 - accuracy: 0.7299\n",
      "Epoch 128/1000\n",
      "363/363 - 0s - loss: 0.8601 - accuracy: 0.7269\n",
      "Epoch 129/1000\n",
      "363/363 - 0s - loss: 0.8593 - accuracy: 0.7309\n",
      "Epoch 130/1000\n",
      "363/363 - 0s - loss: 0.8725 - accuracy: 0.7258\n",
      "Epoch 131/1000\n",
      "363/363 - 0s - loss: 0.8575 - accuracy: 0.7310\n",
      "Epoch 132/1000\n",
      "363/363 - 0s - loss: 0.8547 - accuracy: 0.7301\n",
      "Epoch 133/1000\n",
      "363/363 - 0s - loss: 0.8588 - accuracy: 0.7304\n",
      "Epoch 134/1000\n",
      "363/363 - 0s - loss: 0.8565 - accuracy: 0.7297\n",
      "Epoch 135/1000\n",
      "363/363 - 0s - loss: 0.8518 - accuracy: 0.7317\n",
      "Epoch 136/1000\n",
      "363/363 - 0s - loss: 0.8536 - accuracy: 0.7317\n",
      "Epoch 137/1000\n",
      "363/363 - 0s - loss: 0.8490 - accuracy: 0.7325\n",
      "Epoch 138/1000\n",
      "363/363 - 0s - loss: 0.8486 - accuracy: 0.7329\n",
      "Epoch 139/1000\n",
      "363/363 - 0s - loss: 0.8474 - accuracy: 0.7342\n",
      "Epoch 140/1000\n",
      "363/363 - 0s - loss: 0.8497 - accuracy: 0.7341\n",
      "Epoch 141/1000\n",
      "363/363 - 0s - loss: 0.8467 - accuracy: 0.7305\n",
      "Epoch 142/1000\n",
      "363/363 - 0s - loss: 0.8456 - accuracy: 0.7350\n",
      "Epoch 143/1000\n",
      "363/363 - 0s - loss: 0.8495 - accuracy: 0.7334\n",
      "Epoch 144/1000\n",
      "363/363 - 0s - loss: 0.8346 - accuracy: 0.7355\n",
      "Epoch 145/1000\n",
      "363/363 - 0s - loss: 0.8486 - accuracy: 0.7336\n",
      "Epoch 146/1000\n",
      "363/363 - 0s - loss: 0.8356 - accuracy: 0.7359\n",
      "Epoch 147/1000\n",
      "363/363 - 0s - loss: 0.8379 - accuracy: 0.7361\n",
      "Epoch 148/1000\n",
      "363/363 - 0s - loss: 0.8359 - accuracy: 0.7384\n",
      "Epoch 149/1000\n",
      "363/363 - 0s - loss: 0.8337 - accuracy: 0.7369\n",
      "Epoch 150/1000\n",
      "363/363 - 0s - loss: 0.8314 - accuracy: 0.7370\n",
      "Epoch 151/1000\n",
      "363/363 - 0s - loss: 0.8348 - accuracy: 0.7415\n",
      "Epoch 152/1000\n",
      "363/363 - 0s - loss: 0.8335 - accuracy: 0.7357\n",
      "Epoch 153/1000\n",
      "363/363 - 0s - loss: 0.8256 - accuracy: 0.7409\n",
      "Epoch 154/1000\n",
      "363/363 - 0s - loss: 0.8236 - accuracy: 0.7389\n",
      "Epoch 155/1000\n",
      "363/363 - 0s - loss: 0.8207 - accuracy: 0.7405\n",
      "Epoch 156/1000\n",
      "363/363 - 0s - loss: 0.8264 - accuracy: 0.7384\n",
      "Epoch 157/1000\n",
      "363/363 - 0s - loss: 0.8293 - accuracy: 0.7391\n",
      "Epoch 158/1000\n",
      "363/363 - 0s - loss: 0.8148 - accuracy: 0.7398\n",
      "Epoch 159/1000\n",
      "363/363 - 0s - loss: 0.8243 - accuracy: 0.7364\n",
      "Epoch 160/1000\n",
      "363/363 - 0s - loss: 0.8245 - accuracy: 0.7415\n",
      "Epoch 161/1000\n",
      "363/363 - 0s - loss: 0.8185 - accuracy: 0.7394\n",
      "Epoch 162/1000\n",
      "363/363 - 0s - loss: 0.8106 - accuracy: 0.7430\n",
      "Epoch 163/1000\n",
      "363/363 - 0s - loss: 0.8177 - accuracy: 0.7448\n",
      "Epoch 164/1000\n",
      "363/363 - 0s - loss: 0.8173 - accuracy: 0.7381\n",
      "Epoch 165/1000\n",
      "363/363 - 0s - loss: 0.8122 - accuracy: 0.7425\n",
      "Epoch 166/1000\n",
      "363/363 - 0s - loss: 0.8220 - accuracy: 0.7404\n",
      "Epoch 167/1000\n",
      "363/363 - 0s - loss: 0.8112 - accuracy: 0.7454\n",
      "Epoch 168/1000\n",
      "363/363 - 0s - loss: 0.8055 - accuracy: 0.7439\n",
      "Epoch 169/1000\n",
      "363/363 - 0s - loss: 0.8015 - accuracy: 0.7432\n",
      "Epoch 170/1000\n",
      "363/363 - 0s - loss: 0.8088 - accuracy: 0.7412\n",
      "Epoch 171/1000\n",
      "363/363 - 0s - loss: 0.8076 - accuracy: 0.7425\n",
      "Epoch 172/1000\n",
      "363/363 - 0s - loss: 0.8079 - accuracy: 0.7432\n",
      "Epoch 173/1000\n",
      "363/363 - 0s - loss: 0.8036 - accuracy: 0.7453\n",
      "Epoch 174/1000\n",
      "363/363 - 0s - loss: 0.8014 - accuracy: 0.7465\n",
      "Epoch 175/1000\n",
      "363/363 - 0s - loss: 0.7921 - accuracy: 0.7479\n",
      "Epoch 176/1000\n",
      "363/363 - 0s - loss: 0.8051 - accuracy: 0.7465\n",
      "Epoch 177/1000\n",
      "363/363 - 0s - loss: 0.7956 - accuracy: 0.7492\n",
      "Epoch 178/1000\n",
      "363/363 - 0s - loss: 0.7871 - accuracy: 0.7477\n",
      "Epoch 179/1000\n",
      "363/363 - 0s - loss: 0.7906 - accuracy: 0.7477\n",
      "Epoch 180/1000\n",
      "363/363 - 0s - loss: 0.7968 - accuracy: 0.7454\n",
      "Epoch 181/1000\n",
      "363/363 - 0s - loss: 0.7881 - accuracy: 0.7468\n",
      "Epoch 182/1000\n",
      "363/363 - 0s - loss: 0.8017 - accuracy: 0.7459\n",
      "Epoch 183/1000\n",
      "363/363 - 0s - loss: 0.7888 - accuracy: 0.7464\n",
      "Epoch 184/1000\n",
      "363/363 - 0s - loss: 0.7901 - accuracy: 0.7480\n",
      "Epoch 185/1000\n",
      "363/363 - 0s - loss: 0.7858 - accuracy: 0.7489\n",
      "Epoch 186/1000\n",
      "363/363 - 0s - loss: 0.7845 - accuracy: 0.7512\n",
      "Epoch 187/1000\n",
      "363/363 - 0s - loss: 0.7781 - accuracy: 0.7475\n",
      "Epoch 188/1000\n",
      "363/363 - 0s - loss: 0.7832 - accuracy: 0.7498\n",
      "Epoch 189/1000\n",
      "363/363 - 0s - loss: 0.7900 - accuracy: 0.7475\n",
      "Epoch 190/1000\n",
      "363/363 - 0s - loss: 0.7878 - accuracy: 0.7514\n",
      "Epoch 191/1000\n",
      "363/363 - 0s - loss: 0.7846 - accuracy: 0.7470\n",
      "Epoch 192/1000\n",
      "363/363 - 0s - loss: 0.7858 - accuracy: 0.7489\n",
      "Epoch 193/1000\n",
      "363/363 - 0s - loss: 0.7776 - accuracy: 0.7503\n",
      "Epoch 194/1000\n",
      "363/363 - 0s - loss: 0.7813 - accuracy: 0.7493\n",
      "Epoch 195/1000\n",
      "363/363 - 0s - loss: 0.7825 - accuracy: 0.7518\n",
      "Epoch 196/1000\n",
      "363/363 - 0s - loss: 0.7711 - accuracy: 0.7555\n",
      "Epoch 197/1000\n",
      "363/363 - 0s - loss: 0.7786 - accuracy: 0.7503\n",
      "Epoch 198/1000\n",
      "363/363 - 0s - loss: 0.7718 - accuracy: 0.7508\n",
      "Epoch 199/1000\n",
      "363/363 - 0s - loss: 0.7707 - accuracy: 0.7544\n",
      "Epoch 200/1000\n",
      "363/363 - 0s - loss: 0.7804 - accuracy: 0.7527\n",
      "Epoch 201/1000\n",
      "363/363 - 0s - loss: 0.7815 - accuracy: 0.7488\n",
      "Epoch 202/1000\n",
      "363/363 - 0s - loss: 0.7774 - accuracy: 0.7515\n",
      "Epoch 203/1000\n",
      "363/363 - 0s - loss: 0.7662 - accuracy: 0.7526\n",
      "Epoch 204/1000\n",
      "363/363 - 0s - loss: 0.7594 - accuracy: 0.7540\n",
      "Epoch 205/1000\n",
      "363/363 - 0s - loss: 0.7776 - accuracy: 0.7497\n",
      "Epoch 206/1000\n",
      "363/363 - 0s - loss: 0.7649 - accuracy: 0.7519\n",
      "Epoch 207/1000\n",
      "363/363 - 0s - loss: 0.7695 - accuracy: 0.7509\n",
      "Epoch 208/1000\n",
      "363/363 - 0s - loss: 0.7619 - accuracy: 0.7542\n",
      "Epoch 209/1000\n",
      "363/363 - 0s - loss: 0.7710 - accuracy: 0.7525\n",
      "Epoch 210/1000\n",
      "363/363 - 0s - loss: 0.7627 - accuracy: 0.7558\n",
      "Epoch 211/1000\n",
      "363/363 - 0s - loss: 0.7637 - accuracy: 0.7554\n",
      "Epoch 212/1000\n",
      "363/363 - 0s - loss: 0.7600 - accuracy: 0.7537\n",
      "Epoch 213/1000\n",
      "363/363 - 0s - loss: 0.7711 - accuracy: 0.7525\n",
      "Epoch 214/1000\n",
      "363/363 - 0s - loss: 0.7591 - accuracy: 0.7556\n",
      "Epoch 215/1000\n",
      "363/363 - 0s - loss: 0.7616 - accuracy: 0.7583\n",
      "Epoch 216/1000\n",
      "363/363 - 0s - loss: 0.7586 - accuracy: 0.7566\n",
      "Epoch 217/1000\n",
      "363/363 - 0s - loss: 0.7614 - accuracy: 0.7582\n",
      "Epoch 218/1000\n",
      "363/363 - 0s - loss: 0.7597 - accuracy: 0.7522\n",
      "Epoch 219/1000\n",
      "363/363 - 0s - loss: 0.7577 - accuracy: 0.7541\n",
      "Epoch 220/1000\n",
      "363/363 - 0s - loss: 0.7619 - accuracy: 0.7551\n",
      "Epoch 221/1000\n",
      "363/363 - 0s - loss: 0.7589 - accuracy: 0.7557\n",
      "Epoch 222/1000\n",
      "363/363 - 0s - loss: 0.7569 - accuracy: 0.7572\n",
      "Epoch 223/1000\n",
      "363/363 - 0s - loss: 0.7498 - accuracy: 0.7624\n",
      "Epoch 224/1000\n",
      "363/363 - 0s - loss: 0.7480 - accuracy: 0.7601\n",
      "Epoch 225/1000\n",
      "363/363 - 0s - loss: 0.7610 - accuracy: 0.7574\n",
      "Epoch 226/1000\n",
      "363/363 - 0s - loss: 0.7445 - accuracy: 0.7594\n",
      "Epoch 227/1000\n",
      "363/363 - 0s - loss: 0.7454 - accuracy: 0.7584\n",
      "Epoch 228/1000\n",
      "363/363 - 0s - loss: 0.7431 - accuracy: 0.7570\n",
      "Epoch 229/1000\n",
      "363/363 - 0s - loss: 0.7438 - accuracy: 0.7582\n",
      "Epoch 230/1000\n",
      "363/363 - 0s - loss: 0.7432 - accuracy: 0.7625\n",
      "Epoch 231/1000\n",
      "363/363 - 0s - loss: 0.7464 - accuracy: 0.7562\n",
      "Epoch 232/1000\n",
      "363/363 - 0s - loss: 0.7415 - accuracy: 0.7617\n",
      "Epoch 233/1000\n",
      "363/363 - 0s - loss: 0.7523 - accuracy: 0.7543\n",
      "Epoch 234/1000\n",
      "363/363 - 0s - loss: 0.7397 - accuracy: 0.7609\n",
      "Epoch 235/1000\n",
      "363/363 - 0s - loss: 0.7393 - accuracy: 0.7613\n",
      "Epoch 236/1000\n",
      "363/363 - 0s - loss: 0.7398 - accuracy: 0.7601\n",
      "Epoch 237/1000\n",
      "363/363 - 0s - loss: 0.7370 - accuracy: 0.7631\n",
      "Epoch 238/1000\n",
      "363/363 - 0s - loss: 0.7423 - accuracy: 0.7602\n",
      "Epoch 239/1000\n",
      "363/363 - 0s - loss: 0.7337 - accuracy: 0.7638\n",
      "Epoch 240/1000\n",
      "363/363 - 0s - loss: 0.7451 - accuracy: 0.7581\n",
      "Epoch 241/1000\n",
      "363/363 - 0s - loss: 0.7259 - accuracy: 0.7650\n",
      "Epoch 242/1000\n",
      "363/363 - 0s - loss: 0.7373 - accuracy: 0.7645\n",
      "Epoch 243/1000\n",
      "363/363 - 0s - loss: 0.7348 - accuracy: 0.7603\n",
      "Epoch 244/1000\n",
      "363/363 - 0s - loss: 0.7316 - accuracy: 0.7614\n",
      "Epoch 245/1000\n",
      "363/363 - 0s - loss: 0.7310 - accuracy: 0.7629\n",
      "Epoch 246/1000\n",
      "363/363 - 0s - loss: 0.7357 - accuracy: 0.7657\n",
      "Epoch 247/1000\n",
      "363/363 - 0s - loss: 0.7275 - accuracy: 0.7663\n",
      "Epoch 248/1000\n",
      "363/363 - 0s - loss: 0.7291 - accuracy: 0.7628\n",
      "Epoch 249/1000\n",
      "363/363 - 0s - loss: 0.7224 - accuracy: 0.7669\n",
      "Epoch 250/1000\n",
      "363/363 - 0s - loss: 0.7196 - accuracy: 0.7673\n",
      "Epoch 251/1000\n",
      "363/363 - 0s - loss: 0.7301 - accuracy: 0.7653\n",
      "Epoch 252/1000\n",
      "363/363 - 0s - loss: 0.7358 - accuracy: 0.7621\n",
      "Epoch 253/1000\n",
      "363/363 - 0s - loss: 0.7377 - accuracy: 0.7605\n",
      "Epoch 254/1000\n",
      "363/363 - 0s - loss: 0.7282 - accuracy: 0.7629\n",
      "Epoch 255/1000\n",
      "363/363 - 0s - loss: 0.7247 - accuracy: 0.7673\n",
      "Epoch 256/1000\n",
      "363/363 - 0s - loss: 0.7321 - accuracy: 0.7609\n",
      "Epoch 257/1000\n",
      "363/363 - 0s - loss: 0.7356 - accuracy: 0.7630\n",
      "Epoch 258/1000\n",
      "363/363 - 0s - loss: 0.7317 - accuracy: 0.7610\n",
      "Epoch 259/1000\n",
      "363/363 - 0s - loss: 0.7233 - accuracy: 0.7664\n",
      "Epoch 260/1000\n",
      "363/363 - 0s - loss: 0.7258 - accuracy: 0.7639\n",
      "Epoch 261/1000\n",
      "363/363 - 0s - loss: 0.7209 - accuracy: 0.7681\n",
      "Epoch 262/1000\n",
      "363/363 - 0s - loss: 0.7313 - accuracy: 0.7632\n",
      "Epoch 263/1000\n",
      "363/363 - 0s - loss: 0.7138 - accuracy: 0.7632\n",
      "Epoch 264/1000\n",
      "363/363 - 0s - loss: 0.7273 - accuracy: 0.7631\n",
      "Epoch 265/1000\n",
      "363/363 - 0s - loss: 0.7203 - accuracy: 0.7674\n",
      "Epoch 266/1000\n",
      "363/363 - 0s - loss: 0.7229 - accuracy: 0.7675\n",
      "Epoch 267/1000\n",
      "363/363 - 0s - loss: 0.7203 - accuracy: 0.7648\n",
      "Epoch 268/1000\n",
      "363/363 - 0s - loss: 0.7182 - accuracy: 0.7652\n",
      "Epoch 269/1000\n",
      "363/363 - 0s - loss: 0.7095 - accuracy: 0.7713\n",
      "Epoch 270/1000\n",
      "363/363 - 0s - loss: 0.7166 - accuracy: 0.7669\n",
      "Epoch 271/1000\n",
      "363/363 - 0s - loss: 0.7214 - accuracy: 0.7671\n",
      "Epoch 272/1000\n",
      "363/363 - 0s - loss: 0.7113 - accuracy: 0.7693\n",
      "Epoch 273/1000\n",
      "363/363 - 0s - loss: 0.7196 - accuracy: 0.7664\n",
      "Epoch 274/1000\n",
      "363/363 - 0s - loss: 0.7186 - accuracy: 0.7663\n",
      "Epoch 275/1000\n",
      "363/363 - 0s - loss: 0.7172 - accuracy: 0.7650\n",
      "Epoch 276/1000\n",
      "363/363 - 0s - loss: 0.7152 - accuracy: 0.7681\n",
      "Epoch 277/1000\n",
      "363/363 - 0s - loss: 0.7037 - accuracy: 0.7715\n",
      "Epoch 278/1000\n",
      "363/363 - 0s - loss: 0.7085 - accuracy: 0.7675\n",
      "Epoch 279/1000\n",
      "363/363 - 0s - loss: 0.7117 - accuracy: 0.7669\n",
      "Epoch 280/1000\n",
      "363/363 - 0s - loss: 0.7136 - accuracy: 0.7632\n",
      "Epoch 281/1000\n",
      "363/363 - 0s - loss: 0.7133 - accuracy: 0.7680\n",
      "Epoch 282/1000\n",
      "363/363 - 0s - loss: 0.7057 - accuracy: 0.7693\n",
      "Epoch 283/1000\n",
      "363/363 - 0s - loss: 0.7102 - accuracy: 0.7681\n",
      "Epoch 284/1000\n",
      "363/363 - 0s - loss: 0.7020 - accuracy: 0.7726\n",
      "Epoch 285/1000\n",
      "363/363 - 0s - loss: 0.7141 - accuracy: 0.7681\n",
      "Epoch 286/1000\n",
      "363/363 - 0s - loss: 0.6989 - accuracy: 0.7745\n",
      "Epoch 287/1000\n",
      "363/363 - 0s - loss: 0.7031 - accuracy: 0.7710\n",
      "Epoch 288/1000\n",
      "363/363 - 0s - loss: 0.7040 - accuracy: 0.7693\n",
      "Epoch 289/1000\n",
      "363/363 - 0s - loss: 0.7044 - accuracy: 0.7727\n",
      "Epoch 290/1000\n",
      "363/363 - 0s - loss: 0.7109 - accuracy: 0.7694\n",
      "Epoch 291/1000\n",
      "363/363 - 0s - loss: 0.7080 - accuracy: 0.7700\n",
      "Epoch 292/1000\n",
      "363/363 - 0s - loss: 0.7006 - accuracy: 0.7725\n",
      "Epoch 293/1000\n",
      "363/363 - 0s - loss: 0.7050 - accuracy: 0.7687\n",
      "Epoch 294/1000\n",
      "363/363 - 0s - loss: 0.7025 - accuracy: 0.7700\n",
      "Epoch 295/1000\n",
      "363/363 - 0s - loss: 0.7082 - accuracy: 0.7692\n",
      "Epoch 296/1000\n",
      "363/363 - 0s - loss: 0.7084 - accuracy: 0.7681\n",
      "Epoch 297/1000\n",
      "363/363 - 0s - loss: 0.7013 - accuracy: 0.7716\n",
      "Epoch 298/1000\n",
      "363/363 - 0s - loss: 0.7000 - accuracy: 0.7712\n",
      "Epoch 299/1000\n",
      "363/363 - 0s - loss: 0.6937 - accuracy: 0.7722\n",
      "Epoch 300/1000\n",
      "363/363 - 0s - loss: 0.7061 - accuracy: 0.7714\n",
      "Epoch 301/1000\n",
      "363/363 - 0s - loss: 0.6971 - accuracy: 0.7724\n",
      "Epoch 302/1000\n",
      "363/363 - 0s - loss: 0.6970 - accuracy: 0.7690\n",
      "Epoch 303/1000\n",
      "363/363 - 0s - loss: 0.6992 - accuracy: 0.7731\n",
      "Epoch 304/1000\n",
      "363/363 - 0s - loss: 0.6940 - accuracy: 0.7725\n",
      "Epoch 305/1000\n",
      "363/363 - 0s - loss: 0.6906 - accuracy: 0.7746\n",
      "Epoch 306/1000\n",
      "363/363 - 0s - loss: 0.6846 - accuracy: 0.7762\n",
      "Epoch 307/1000\n",
      "363/363 - 0s - loss: 0.6896 - accuracy: 0.7760\n",
      "Epoch 308/1000\n",
      "363/363 - 0s - loss: 0.6921 - accuracy: 0.7749\n",
      "Epoch 309/1000\n",
      "363/363 - 0s - loss: 0.6889 - accuracy: 0.7738\n",
      "Epoch 310/1000\n",
      "363/363 - 0s - loss: 0.6868 - accuracy: 0.7731\n",
      "Epoch 311/1000\n",
      "363/363 - 0s - loss: 0.6886 - accuracy: 0.7746\n",
      "Epoch 312/1000\n",
      "363/363 - 0s - loss: 0.6955 - accuracy: 0.7752\n",
      "Epoch 313/1000\n",
      "363/363 - 0s - loss: 0.6861 - accuracy: 0.7735\n",
      "Epoch 314/1000\n",
      "363/363 - 0s - loss: 0.6997 - accuracy: 0.7714\n",
      "Epoch 315/1000\n",
      "363/363 - 0s - loss: 0.6801 - accuracy: 0.7773\n",
      "Epoch 316/1000\n",
      "363/363 - 0s - loss: 0.6849 - accuracy: 0.7755\n",
      "Epoch 317/1000\n",
      "363/363 - 0s - loss: 0.6760 - accuracy: 0.7742\n",
      "Epoch 318/1000\n",
      "363/363 - 0s - loss: 0.6850 - accuracy: 0.7736\n",
      "Epoch 319/1000\n",
      "363/363 - 0s - loss: 0.6787 - accuracy: 0.7773\n",
      "Epoch 320/1000\n",
      "363/363 - 0s - loss: 0.6900 - accuracy: 0.7749\n",
      "Epoch 321/1000\n",
      "363/363 - 0s - loss: 0.6724 - accuracy: 0.7787\n",
      "Epoch 322/1000\n",
      "363/363 - 0s - loss: 0.6888 - accuracy: 0.7742\n",
      "Epoch 323/1000\n",
      "363/363 - 0s - loss: 0.6809 - accuracy: 0.7748\n",
      "Epoch 324/1000\n",
      "363/363 - 0s - loss: 0.6836 - accuracy: 0.7765\n",
      "Epoch 325/1000\n",
      "363/363 - 0s - loss: 0.6921 - accuracy: 0.7696\n",
      "Epoch 326/1000\n",
      "363/363 - 0s - loss: 0.6752 - accuracy: 0.7754\n",
      "Epoch 327/1000\n",
      "363/363 - 0s - loss: 0.6748 - accuracy: 0.7796\n",
      "Epoch 328/1000\n",
      "363/363 - 0s - loss: 0.6798 - accuracy: 0.7775\n",
      "Epoch 329/1000\n",
      "363/363 - 0s - loss: 0.6890 - accuracy: 0.7699\n",
      "Epoch 330/1000\n",
      "363/363 - 0s - loss: 0.6817 - accuracy: 0.7765\n",
      "Epoch 331/1000\n",
      "363/363 - 0s - loss: 0.6805 - accuracy: 0.7765\n",
      "Epoch 332/1000\n",
      "363/363 - 0s - loss: 0.6728 - accuracy: 0.7764\n",
      "Epoch 333/1000\n",
      "363/363 - 0s - loss: 0.6807 - accuracy: 0.7779\n",
      "Epoch 334/1000\n",
      "363/363 - 0s - loss: 0.6763 - accuracy: 0.7795\n",
      "Epoch 335/1000\n",
      "363/363 - 0s - loss: 0.6795 - accuracy: 0.7749\n",
      "Epoch 336/1000\n",
      "363/363 - 0s - loss: 0.6758 - accuracy: 0.7783\n",
      "Epoch 337/1000\n",
      "363/363 - 0s - loss: 0.6717 - accuracy: 0.7793\n",
      "Epoch 338/1000\n",
      "363/363 - 0s - loss: 0.6812 - accuracy: 0.7780\n",
      "Epoch 339/1000\n",
      "363/363 - 0s - loss: 0.6844 - accuracy: 0.7736\n",
      "Epoch 340/1000\n",
      "363/363 - 0s - loss: 0.6802 - accuracy: 0.7809\n",
      "Epoch 341/1000\n",
      "363/363 - 0s - loss: 0.6723 - accuracy: 0.7771\n",
      "Epoch 342/1000\n",
      "363/363 - 0s - loss: 0.6714 - accuracy: 0.7813\n",
      "Epoch 343/1000\n",
      "363/363 - 0s - loss: 0.6824 - accuracy: 0.7774\n",
      "Epoch 344/1000\n",
      "363/363 - 0s - loss: 0.6736 - accuracy: 0.7783\n",
      "Epoch 345/1000\n",
      "363/363 - 0s - loss: 0.6752 - accuracy: 0.7784\n",
      "Epoch 346/1000\n",
      "363/363 - 0s - loss: 0.6840 - accuracy: 0.7753\n",
      "Epoch 347/1000\n",
      "363/363 - 0s - loss: 0.6663 - accuracy: 0.7809\n",
      "Epoch 348/1000\n",
      "363/363 - 0s - loss: 0.6653 - accuracy: 0.7821\n",
      "Epoch 349/1000\n",
      "363/363 - 0s - loss: 0.6722 - accuracy: 0.7781\n",
      "Epoch 350/1000\n",
      "363/363 - 0s - loss: 0.6713 - accuracy: 0.7795\n",
      "Epoch 351/1000\n",
      "363/363 - 0s - loss: 0.6670 - accuracy: 0.7823\n",
      "Epoch 352/1000\n",
      "363/363 - 0s - loss: 0.6626 - accuracy: 0.7854\n",
      "Epoch 353/1000\n",
      "363/363 - 0s - loss: 0.6732 - accuracy: 0.7780\n",
      "Epoch 354/1000\n",
      "363/363 - 0s - loss: 0.6607 - accuracy: 0.7832\n",
      "Epoch 355/1000\n",
      "363/363 - 0s - loss: 0.6740 - accuracy: 0.7774\n",
      "Epoch 356/1000\n",
      "363/363 - 0s - loss: 0.6693 - accuracy: 0.7771\n",
      "Epoch 357/1000\n",
      "363/363 - 0s - loss: 0.6651 - accuracy: 0.7835\n",
      "Epoch 358/1000\n",
      "363/363 - 0s - loss: 0.6816 - accuracy: 0.7761\n",
      "Epoch 359/1000\n",
      "363/363 - 0s - loss: 0.6684 - accuracy: 0.7811\n",
      "Epoch 360/1000\n",
      "363/363 - 0s - loss: 0.6646 - accuracy: 0.7829\n",
      "Epoch 361/1000\n",
      "363/363 - 0s - loss: 0.6662 - accuracy: 0.7757\n",
      "Epoch 362/1000\n",
      "363/363 - 0s - loss: 0.6754 - accuracy: 0.7774\n",
      "Epoch 363/1000\n",
      "363/363 - 0s - loss: 0.6709 - accuracy: 0.7807\n",
      "Epoch 364/1000\n",
      "363/363 - 0s - loss: 0.6570 - accuracy: 0.7837\n",
      "Epoch 365/1000\n",
      "363/363 - 0s - loss: 0.6560 - accuracy: 0.7805\n",
      "Epoch 366/1000\n",
      "363/363 - 0s - loss: 0.6467 - accuracy: 0.7827\n",
      "Epoch 367/1000\n",
      "363/363 - 0s - loss: 0.6663 - accuracy: 0.7839\n",
      "Epoch 368/1000\n",
      "363/363 - 0s - loss: 0.6627 - accuracy: 0.7827\n",
      "Epoch 369/1000\n",
      "363/363 - 0s - loss: 0.6636 - accuracy: 0.7811\n",
      "Epoch 370/1000\n",
      "363/363 - 0s - loss: 0.6578 - accuracy: 0.7824\n",
      "Epoch 371/1000\n",
      "363/363 - 0s - loss: 0.6657 - accuracy: 0.7788\n",
      "Epoch 372/1000\n",
      "363/363 - 0s - loss: 0.6516 - accuracy: 0.7848\n",
      "Epoch 373/1000\n",
      "363/363 - 0s - loss: 0.6567 - accuracy: 0.7818\n",
      "Epoch 374/1000\n",
      "363/363 - 0s - loss: 0.6569 - accuracy: 0.7815\n",
      "Epoch 375/1000\n",
      "363/363 - 0s - loss: 0.6671 - accuracy: 0.7815\n",
      "Epoch 376/1000\n",
      "363/363 - 0s - loss: 0.6564 - accuracy: 0.7816\n",
      "Epoch 377/1000\n",
      "363/363 - 0s - loss: 0.6552 - accuracy: 0.7836\n",
      "Epoch 378/1000\n",
      "363/363 - 0s - loss: 0.6491 - accuracy: 0.7870\n",
      "Epoch 379/1000\n",
      "363/363 - 0s - loss: 0.6544 - accuracy: 0.7823\n",
      "Epoch 380/1000\n",
      "363/363 - 0s - loss: 0.6659 - accuracy: 0.7818\n",
      "Epoch 381/1000\n",
      "363/363 - 0s - loss: 0.6598 - accuracy: 0.7857\n",
      "Epoch 382/1000\n",
      "363/363 - 0s - loss: 0.6606 - accuracy: 0.7828\n",
      "Epoch 383/1000\n",
      "363/363 - 0s - loss: 0.6554 - accuracy: 0.7852\n",
      "Epoch 384/1000\n",
      "363/363 - 0s - loss: 0.6557 - accuracy: 0.7853\n",
      "Epoch 385/1000\n",
      "363/363 - 0s - loss: 0.6533 - accuracy: 0.7852\n",
      "Epoch 386/1000\n",
      "363/363 - 0s - loss: 0.6432 - accuracy: 0.7844\n",
      "Epoch 387/1000\n",
      "363/363 - 0s - loss: 0.6511 - accuracy: 0.7891\n",
      "Epoch 388/1000\n",
      "363/363 - 0s - loss: 0.6444 - accuracy: 0.7868\n",
      "Epoch 389/1000\n",
      "363/363 - 0s - loss: 0.6588 - accuracy: 0.7834\n",
      "Epoch 390/1000\n",
      "363/363 - 0s - loss: 0.6606 - accuracy: 0.7797\n",
      "Epoch 391/1000\n",
      "363/363 - 0s - loss: 0.6488 - accuracy: 0.7853\n",
      "Epoch 392/1000\n",
      "363/363 - 0s - loss: 0.6567 - accuracy: 0.7830\n",
      "Epoch 393/1000\n",
      "363/363 - 0s - loss: 0.6541 - accuracy: 0.7832\n",
      "Epoch 394/1000\n",
      "363/363 - 0s - loss: 0.6628 - accuracy: 0.7840\n",
      "Epoch 395/1000\n",
      "363/363 - 0s - loss: 0.6574 - accuracy: 0.7862\n",
      "Epoch 396/1000\n",
      "363/363 - 0s - loss: 0.6589 - accuracy: 0.7793\n",
      "Epoch 397/1000\n",
      "363/363 - 0s - loss: 0.6500 - accuracy: 0.7875\n",
      "Epoch 398/1000\n",
      "363/363 - 0s - loss: 0.6478 - accuracy: 0.7853\n",
      "Epoch 399/1000\n",
      "363/363 - 0s - loss: 0.6567 - accuracy: 0.7870\n",
      "Epoch 400/1000\n",
      "363/363 - 0s - loss: 0.6488 - accuracy: 0.7833\n",
      "Epoch 401/1000\n",
      "363/363 - 0s - loss: 0.6442 - accuracy: 0.7880\n",
      "Epoch 402/1000\n",
      "363/363 - 0s - loss: 0.6573 - accuracy: 0.7836\n",
      "Epoch 403/1000\n",
      "363/363 - 0s - loss: 0.6493 - accuracy: 0.7873\n",
      "Epoch 404/1000\n",
      "363/363 - 0s - loss: 0.6496 - accuracy: 0.7857\n",
      "Epoch 405/1000\n",
      "363/363 - 0s - loss: 0.6557 - accuracy: 0.7852\n",
      "Epoch 406/1000\n",
      "363/363 - 0s - loss: 0.6441 - accuracy: 0.7868\n",
      "Epoch 407/1000\n",
      "363/363 - 0s - loss: 0.6512 - accuracy: 0.7857\n",
      "Epoch 408/1000\n",
      "363/363 - 0s - loss: 0.6576 - accuracy: 0.7826\n",
      "Epoch 409/1000\n",
      "363/363 - 0s - loss: 0.6487 - accuracy: 0.7861\n",
      "Epoch 410/1000\n",
      "363/363 - 0s - loss: 0.6424 - accuracy: 0.7911\n",
      "Epoch 411/1000\n",
      "363/363 - 0s - loss: 0.6510 - accuracy: 0.7849\n",
      "Epoch 412/1000\n",
      "363/363 - 0s - loss: 0.6355 - accuracy: 0.7941\n",
      "Epoch 413/1000\n",
      "363/363 - 0s - loss: 0.6494 - accuracy: 0.7877\n",
      "Epoch 414/1000\n",
      "363/363 - 0s - loss: 0.6373 - accuracy: 0.7913\n",
      "Epoch 415/1000\n",
      "363/363 - 0s - loss: 0.6317 - accuracy: 0.7917\n",
      "Epoch 416/1000\n",
      "363/363 - 0s - loss: 0.6471 - accuracy: 0.7896\n",
      "Epoch 417/1000\n",
      "363/363 - 0s - loss: 0.6536 - accuracy: 0.7867\n",
      "Epoch 418/1000\n",
      "363/363 - 0s - loss: 0.6461 - accuracy: 0.7866\n",
      "Epoch 419/1000\n",
      "363/363 - 0s - loss: 0.6400 - accuracy: 0.7867\n",
      "Epoch 420/1000\n",
      "363/363 - 0s - loss: 0.6570 - accuracy: 0.7843\n",
      "Epoch 421/1000\n",
      "363/363 - 0s - loss: 0.6362 - accuracy: 0.7941\n",
      "Epoch 422/1000\n",
      "363/363 - 0s - loss: 0.6487 - accuracy: 0.7839\n",
      "Epoch 423/1000\n",
      "363/363 - 0s - loss: 0.6417 - accuracy: 0.7901\n",
      "Epoch 424/1000\n",
      "363/363 - 0s - loss: 0.6350 - accuracy: 0.7919\n",
      "Epoch 425/1000\n",
      "363/363 - 0s - loss: 0.6424 - accuracy: 0.7848\n",
      "Epoch 426/1000\n",
      "363/363 - 0s - loss: 0.6475 - accuracy: 0.7873\n",
      "Epoch 427/1000\n",
      "363/363 - 0s - loss: 0.6381 - accuracy: 0.7889\n",
      "Epoch 428/1000\n",
      "363/363 - 0s - loss: 0.6559 - accuracy: 0.7873\n",
      "Epoch 429/1000\n",
      "363/363 - 0s - loss: 0.6285 - accuracy: 0.7881\n",
      "Epoch 430/1000\n",
      "363/363 - 0s - loss: 0.6404 - accuracy: 0.7907\n",
      "Epoch 431/1000\n",
      "363/363 - 0s - loss: 0.6336 - accuracy: 0.7897\n",
      "Epoch 432/1000\n",
      "363/363 - 0s - loss: 0.6353 - accuracy: 0.7898\n",
      "Epoch 433/1000\n",
      "363/363 - 0s - loss: 0.6475 - accuracy: 0.7859\n",
      "Epoch 434/1000\n",
      "363/363 - 0s - loss: 0.6416 - accuracy: 0.7901\n",
      "Epoch 435/1000\n",
      "363/363 - 0s - loss: 0.6465 - accuracy: 0.7860\n",
      "Epoch 436/1000\n",
      "363/363 - 0s - loss: 0.6351 - accuracy: 0.7915\n",
      "Epoch 437/1000\n",
      "363/363 - 0s - loss: 0.6401 - accuracy: 0.7873\n",
      "Epoch 438/1000\n",
      "363/363 - 0s - loss: 0.6363 - accuracy: 0.7893\n",
      "Epoch 439/1000\n",
      "363/363 - 0s - loss: 0.6406 - accuracy: 0.7895\n",
      "Epoch 440/1000\n",
      "363/363 - 0s - loss: 0.6360 - accuracy: 0.7893\n",
      "Epoch 441/1000\n",
      "363/363 - 0s - loss: 0.6389 - accuracy: 0.7888\n",
      "Epoch 442/1000\n",
      "363/363 - 0s - loss: 0.6369 - accuracy: 0.7902\n",
      "Epoch 443/1000\n",
      "363/363 - 0s - loss: 0.6382 - accuracy: 0.7895\n",
      "Epoch 444/1000\n",
      "363/363 - 0s - loss: 0.6352 - accuracy: 0.7902\n",
      "Epoch 445/1000\n",
      "363/363 - 0s - loss: 0.6310 - accuracy: 0.7881\n",
      "Epoch 446/1000\n",
      "363/363 - 0s - loss: 0.6362 - accuracy: 0.7911\n",
      "Epoch 447/1000\n",
      "363/363 - 0s - loss: 0.6313 - accuracy: 0.7907\n",
      "Epoch 448/1000\n",
      "363/363 - 0s - loss: 0.6298 - accuracy: 0.7947\n",
      "Epoch 449/1000\n",
      "363/363 - 0s - loss: 0.6454 - accuracy: 0.7897\n",
      "Epoch 450/1000\n",
      "363/363 - 0s - loss: 0.6418 - accuracy: 0.7888\n",
      "Epoch 451/1000\n",
      "363/363 - 0s - loss: 0.6347 - accuracy: 0.7872\n",
      "Epoch 452/1000\n",
      "363/363 - 0s - loss: 0.6400 - accuracy: 0.7897\n",
      "Epoch 453/1000\n",
      "363/363 - 0s - loss: 0.6358 - accuracy: 0.7892\n",
      "Epoch 454/1000\n",
      "363/363 - 0s - loss: 0.6266 - accuracy: 0.7890\n",
      "Epoch 455/1000\n",
      "363/363 - 0s - loss: 0.6283 - accuracy: 0.7930\n",
      "Epoch 456/1000\n",
      "363/363 - 0s - loss: 0.6342 - accuracy: 0.7902\n",
      "Epoch 457/1000\n",
      "363/363 - 0s - loss: 0.6343 - accuracy: 0.7872\n",
      "Epoch 458/1000\n",
      "363/363 - 0s - loss: 0.6365 - accuracy: 0.7891\n",
      "Epoch 459/1000\n",
      "363/363 - 0s - loss: 0.6257 - accuracy: 0.7908\n",
      "Epoch 460/1000\n",
      "363/363 - 0s - loss: 0.6270 - accuracy: 0.7934\n",
      "Epoch 461/1000\n",
      "363/363 - 0s - loss: 0.6486 - accuracy: 0.7895\n",
      "Epoch 462/1000\n",
      "363/363 - 0s - loss: 0.6270 - accuracy: 0.7929\n",
      "Epoch 463/1000\n",
      "363/363 - 0s - loss: 0.6353 - accuracy: 0.7893\n",
      "Epoch 464/1000\n",
      "363/363 - 0s - loss: 0.6270 - accuracy: 0.7876\n",
      "Epoch 465/1000\n",
      "363/363 - 0s - loss: 0.6357 - accuracy: 0.7885\n",
      "Epoch 466/1000\n",
      "363/363 - 0s - loss: 0.6282 - accuracy: 0.7902\n",
      "Epoch 467/1000\n",
      "363/363 - 0s - loss: 0.6305 - accuracy: 0.7916\n",
      "Epoch 468/1000\n",
      "363/363 - 0s - loss: 0.6303 - accuracy: 0.7912\n",
      "Epoch 469/1000\n",
      "363/363 - 0s - loss: 0.6158 - accuracy: 0.7942\n",
      "Epoch 470/1000\n",
      "363/363 - 0s - loss: 0.6404 - accuracy: 0.7854\n",
      "Epoch 471/1000\n",
      "363/363 - 0s - loss: 0.6293 - accuracy: 0.7912\n",
      "Epoch 472/1000\n",
      "363/363 - 0s - loss: 0.6158 - accuracy: 0.7966\n",
      "Epoch 473/1000\n",
      "363/363 - 0s - loss: 0.6277 - accuracy: 0.7898\n",
      "Epoch 474/1000\n",
      "363/363 - 0s - loss: 0.6335 - accuracy: 0.7923\n",
      "Epoch 475/1000\n",
      "363/363 - 0s - loss: 0.6203 - accuracy: 0.7929\n",
      "Epoch 476/1000\n",
      "363/363 - 0s - loss: 0.6125 - accuracy: 0.7953\n",
      "Epoch 477/1000\n",
      "363/363 - 0s - loss: 0.6323 - accuracy: 0.7917\n",
      "Epoch 478/1000\n",
      "363/363 - 0s - loss: 0.6156 - accuracy: 0.7938\n",
      "Epoch 479/1000\n",
      "363/363 - 0s - loss: 0.6323 - accuracy: 0.7923\n",
      "Epoch 480/1000\n",
      "363/363 - 0s - loss: 0.6302 - accuracy: 0.7904\n",
      "Epoch 481/1000\n",
      "363/363 - 0s - loss: 0.6231 - accuracy: 0.7930\n",
      "Epoch 482/1000\n",
      "363/363 - 0s - loss: 0.5985 - accuracy: 0.8000\n",
      "Epoch 483/1000\n",
      "363/363 - 0s - loss: 0.6293 - accuracy: 0.7907\n",
      "Epoch 484/1000\n",
      "363/363 - 0s - loss: 0.6304 - accuracy: 0.7886\n",
      "Epoch 485/1000\n",
      "363/363 - 0s - loss: 0.6325 - accuracy: 0.7889\n",
      "Epoch 486/1000\n",
      "363/363 - 0s - loss: 0.6191 - accuracy: 0.7966\n",
      "Epoch 487/1000\n",
      "363/363 - 0s - loss: 0.6294 - accuracy: 0.7937\n",
      "Epoch 488/1000\n",
      "363/363 - 0s - loss: 0.6350 - accuracy: 0.7891\n",
      "Epoch 489/1000\n",
      "363/363 - 0s - loss: 0.6217 - accuracy: 0.7917\n",
      "Epoch 490/1000\n",
      "363/363 - 0s - loss: 0.6221 - accuracy: 0.7917\n",
      "Epoch 491/1000\n",
      "363/363 - 0s - loss: 0.6285 - accuracy: 0.7891\n",
      "Epoch 492/1000\n",
      "363/363 - 0s - loss: 0.6356 - accuracy: 0.7885\n",
      "Epoch 493/1000\n",
      "363/363 - 0s - loss: 0.6205 - accuracy: 0.7947\n",
      "Epoch 494/1000\n",
      "363/363 - 0s - loss: 0.6216 - accuracy: 0.7947\n",
      "Epoch 495/1000\n",
      "363/363 - 0s - loss: 0.6308 - accuracy: 0.7941\n",
      "Epoch 496/1000\n",
      "363/363 - 0s - loss: 0.6143 - accuracy: 0.7910\n",
      "Epoch 497/1000\n",
      "363/363 - 0s - loss: 0.6090 - accuracy: 0.7994\n",
      "Epoch 498/1000\n",
      "363/363 - 0s - loss: 0.6160 - accuracy: 0.7967\n",
      "Epoch 499/1000\n",
      "363/363 - 0s - loss: 0.6270 - accuracy: 0.7906\n",
      "Epoch 500/1000\n",
      "363/363 - 0s - loss: 0.6377 - accuracy: 0.7862\n",
      "Epoch 501/1000\n",
      "363/363 - 0s - loss: 0.6161 - accuracy: 0.7954\n",
      "Epoch 502/1000\n",
      "363/363 - 0s - loss: 0.6242 - accuracy: 0.7910\n",
      "Epoch 503/1000\n",
      "363/363 - 0s - loss: 0.6176 - accuracy: 0.7925\n",
      "Epoch 504/1000\n",
      "363/363 - 0s - loss: 0.6119 - accuracy: 0.7947\n",
      "Epoch 505/1000\n",
      "363/363 - 0s - loss: 0.6188 - accuracy: 0.7962\n",
      "Epoch 506/1000\n",
      "363/363 - 0s - loss: 0.6096 - accuracy: 0.8000\n",
      "Epoch 507/1000\n",
      "363/363 - 0s - loss: 0.6268 - accuracy: 0.7927\n",
      "Epoch 508/1000\n",
      "363/363 - 0s - loss: 0.6232 - accuracy: 0.7951\n",
      "Epoch 509/1000\n",
      "363/363 - 0s - loss: 0.6208 - accuracy: 0.7928\n",
      "Epoch 510/1000\n",
      "363/363 - 0s - loss: 0.6218 - accuracy: 0.7958\n",
      "Epoch 511/1000\n",
      "363/363 - 0s - loss: 0.6167 - accuracy: 0.7934\n",
      "Epoch 512/1000\n",
      "363/363 - 0s - loss: 0.6178 - accuracy: 0.7940\n",
      "Epoch 513/1000\n",
      "363/363 - 0s - loss: 0.6166 - accuracy: 0.7942\n",
      "Epoch 514/1000\n",
      "363/363 - 0s - loss: 0.6160 - accuracy: 0.7964\n",
      "Epoch 515/1000\n",
      "363/363 - 0s - loss: 0.6107 - accuracy: 0.7975\n",
      "Epoch 516/1000\n",
      "363/363 - 0s - loss: 0.6125 - accuracy: 0.7942\n",
      "Epoch 517/1000\n",
      "363/363 - 0s - loss: 0.6159 - accuracy: 0.7978\n",
      "Epoch 518/1000\n",
      "363/363 - 0s - loss: 0.6095 - accuracy: 0.7963\n",
      "Epoch 519/1000\n",
      "363/363 - 0s - loss: 0.6152 - accuracy: 0.7948\n",
      "Epoch 520/1000\n",
      "363/363 - 0s - loss: 0.6107 - accuracy: 0.7938\n",
      "Epoch 521/1000\n",
      "363/363 - 0s - loss: 0.6209 - accuracy: 0.7947\n",
      "Epoch 522/1000\n",
      "363/363 - 0s - loss: 0.6142 - accuracy: 0.7978\n",
      "Epoch 523/1000\n",
      "363/363 - 0s - loss: 0.6062 - accuracy: 0.7982\n",
      "Epoch 524/1000\n",
      "363/363 - 0s - loss: 0.6075 - accuracy: 0.7984\n",
      "Epoch 525/1000\n",
      "363/363 - 0s - loss: 0.6148 - accuracy: 0.7954\n",
      "Epoch 526/1000\n",
      "363/363 - 0s - loss: 0.5966 - accuracy: 0.8016\n",
      "Epoch 527/1000\n",
      "363/363 - 0s - loss: 0.6030 - accuracy: 0.7994\n",
      "Epoch 528/1000\n",
      "363/363 - 0s - loss: 0.6242 - accuracy: 0.7910\n",
      "Epoch 529/1000\n",
      "363/363 - 0s - loss: 0.6193 - accuracy: 0.7946\n",
      "Epoch 530/1000\n",
      "363/363 - 0s - loss: 0.6119 - accuracy: 0.7991\n",
      "Epoch 531/1000\n",
      "363/363 - 0s - loss: 0.6222 - accuracy: 0.7929\n",
      "Epoch 532/1000\n",
      "363/363 - 0s - loss: 0.5934 - accuracy: 0.8032\n",
      "Epoch 533/1000\n",
      "363/363 - 0s - loss: 0.6246 - accuracy: 0.7930\n",
      "Epoch 534/1000\n",
      "363/363 - 0s - loss: 0.6220 - accuracy: 0.7922\n",
      "Epoch 535/1000\n",
      "363/363 - 0s - loss: 0.6131 - accuracy: 0.7925\n",
      "Epoch 536/1000\n",
      "363/363 - 0s - loss: 0.5933 - accuracy: 0.8008\n",
      "Epoch 537/1000\n",
      "363/363 - 0s - loss: 0.5981 - accuracy: 0.8016\n",
      "Epoch 538/1000\n",
      "363/363 - 0s - loss: 0.6043 - accuracy: 0.7996\n",
      "Epoch 539/1000\n",
      "363/363 - 0s - loss: 0.6274 - accuracy: 0.7906\n",
      "Epoch 540/1000\n",
      "363/363 - 0s - loss: 0.6126 - accuracy: 0.7984\n",
      "Epoch 541/1000\n",
      "363/363 - 0s - loss: 0.6009 - accuracy: 0.8007\n",
      "Epoch 542/1000\n",
      "363/363 - 0s - loss: 0.6125 - accuracy: 0.7953\n",
      "Epoch 543/1000\n",
      "363/363 - 0s - loss: 0.6102 - accuracy: 0.7967\n",
      "Epoch 544/1000\n",
      "363/363 - 0s - loss: 0.6185 - accuracy: 0.7951\n",
      "Epoch 545/1000\n",
      "363/363 - 0s - loss: 0.5930 - accuracy: 0.8044\n",
      "Epoch 546/1000\n",
      "363/363 - 0s - loss: 0.6190 - accuracy: 0.7961\n",
      "Epoch 547/1000\n",
      "363/363 - 0s - loss: 0.5959 - accuracy: 0.8034\n",
      "Epoch 548/1000\n",
      "363/363 - 0s - loss: 0.6122 - accuracy: 0.7955\n",
      "Epoch 549/1000\n",
      "363/363 - 0s - loss: 0.6134 - accuracy: 0.7982\n",
      "Epoch 550/1000\n",
      "363/363 - 0s - loss: 0.6111 - accuracy: 0.7994\n",
      "Epoch 551/1000\n",
      "363/363 - 0s - loss: 0.6029 - accuracy: 0.8017\n",
      "Epoch 552/1000\n",
      "363/363 - 0s - loss: 0.6121 - accuracy: 0.7942\n",
      "Epoch 553/1000\n",
      "363/363 - 0s - loss: 0.5980 - accuracy: 0.8031\n",
      "Epoch 554/1000\n",
      "363/363 - 0s - loss: 0.6073 - accuracy: 0.8006\n",
      "Epoch 555/1000\n",
      "363/363 - 0s - loss: 0.6103 - accuracy: 0.7993\n",
      "Epoch 556/1000\n",
      "363/363 - 0s - loss: 0.6096 - accuracy: 0.7989\n",
      "Epoch 557/1000\n",
      "363/363 - 0s - loss: 0.6076 - accuracy: 0.8007\n",
      "Epoch 558/1000\n",
      "363/363 - 0s - loss: 0.6058 - accuracy: 0.7971\n",
      "Epoch 559/1000\n",
      "363/363 - 0s - loss: 0.6133 - accuracy: 0.7941\n",
      "Epoch 560/1000\n",
      "363/363 - 0s - loss: 0.6017 - accuracy: 0.7980\n",
      "Epoch 561/1000\n",
      "363/363 - 0s - loss: 0.6046 - accuracy: 0.7980\n",
      "Epoch 562/1000\n",
      "363/363 - 0s - loss: 0.6064 - accuracy: 0.7970\n",
      "Epoch 563/1000\n",
      "363/363 - 0s - loss: 0.6004 - accuracy: 0.7982\n",
      "Epoch 564/1000\n",
      "363/363 - 0s - loss: 0.6045 - accuracy: 0.7978\n",
      "Epoch 565/1000\n",
      "363/363 - 0s - loss: 0.5974 - accuracy: 0.8045\n",
      "Epoch 566/1000\n",
      "363/363 - 0s - loss: 0.6119 - accuracy: 0.7967\n",
      "Epoch 567/1000\n",
      "363/363 - 0s - loss: 0.6082 - accuracy: 0.7984\n",
      "Epoch 568/1000\n",
      "363/363 - 0s - loss: 0.6147 - accuracy: 0.7974\n",
      "Epoch 569/1000\n",
      "363/363 - 0s - loss: 0.5966 - accuracy: 0.8011\n",
      "Epoch 570/1000\n",
      "363/363 - 0s - loss: 0.5912 - accuracy: 0.8040\n",
      "Epoch 571/1000\n",
      "363/363 - 0s - loss: 0.6097 - accuracy: 0.7999\n",
      "Epoch 572/1000\n",
      "363/363 - 0s - loss: 0.6047 - accuracy: 0.7958\n",
      "Epoch 573/1000\n",
      "363/363 - 0s - loss: 0.5938 - accuracy: 0.8005\n",
      "Epoch 574/1000\n",
      "363/363 - 0s - loss: 0.5872 - accuracy: 0.8040\n",
      "Epoch 575/1000\n",
      "363/363 - 0s - loss: 0.6155 - accuracy: 0.7966\n",
      "Epoch 576/1000\n",
      "363/363 - 0s - loss: 0.6066 - accuracy: 0.7987\n",
      "Epoch 577/1000\n",
      "363/363 - 0s - loss: 0.6006 - accuracy: 0.7983\n",
      "Epoch 578/1000\n",
      "363/363 - 0s - loss: 0.5858 - accuracy: 0.8066\n",
      "Epoch 579/1000\n",
      "363/363 - 0s - loss: 0.5850 - accuracy: 0.8065\n",
      "Epoch 580/1000\n",
      "363/363 - 0s - loss: 0.6028 - accuracy: 0.8008\n",
      "Epoch 581/1000\n",
      "363/363 - 0s - loss: 0.6011 - accuracy: 0.7970\n",
      "Epoch 582/1000\n",
      "363/363 - 0s - loss: 0.6051 - accuracy: 0.8005\n",
      "Epoch 583/1000\n",
      "363/363 - 0s - loss: 0.6098 - accuracy: 0.7996\n",
      "Epoch 584/1000\n",
      "363/363 - 0s - loss: 0.6057 - accuracy: 0.7969\n",
      "Epoch 585/1000\n",
      "363/363 - 0s - loss: 0.6074 - accuracy: 0.7993\n",
      "Epoch 586/1000\n",
      "363/363 - 0s - loss: 0.5894 - accuracy: 0.8049\n",
      "Epoch 587/1000\n",
      "363/363 - 0s - loss: 0.6084 - accuracy: 0.7987\n",
      "Epoch 588/1000\n",
      "363/363 - 0s - loss: 0.6160 - accuracy: 0.8004\n",
      "Epoch 589/1000\n",
      "363/363 - 0s - loss: 0.5953 - accuracy: 0.8019\n",
      "Epoch 590/1000\n",
      "363/363 - 0s - loss: 0.5931 - accuracy: 0.8038\n",
      "Epoch 591/1000\n",
      "363/363 - 0s - loss: 0.6002 - accuracy: 0.8021\n",
      "Epoch 592/1000\n",
      "363/363 - 0s - loss: 0.6235 - accuracy: 0.7944\n",
      "Epoch 593/1000\n",
      "363/363 - 0s - loss: 0.6120 - accuracy: 0.7956\n",
      "Epoch 594/1000\n",
      "363/363 - 0s - loss: 0.5909 - accuracy: 0.8046\n",
      "Epoch 595/1000\n",
      "363/363 - 0s - loss: 0.5946 - accuracy: 0.7987\n",
      "Epoch 596/1000\n",
      "363/363 - 0s - loss: 0.6065 - accuracy: 0.7986\n",
      "Epoch 597/1000\n",
      "363/363 - 0s - loss: 0.6141 - accuracy: 0.7974\n",
      "Epoch 598/1000\n",
      "363/363 - 0s - loss: 0.5986 - accuracy: 0.7995\n",
      "Epoch 599/1000\n",
      "363/363 - 0s - loss: 0.5923 - accuracy: 0.8038\n",
      "Epoch 600/1000\n",
      "363/363 - 0s - loss: 0.5966 - accuracy: 0.8014\n",
      "Epoch 601/1000\n",
      "363/363 - 0s - loss: 0.6106 - accuracy: 0.7985\n",
      "Epoch 602/1000\n",
      "363/363 - 0s - loss: 0.5914 - accuracy: 0.8026\n",
      "Epoch 603/1000\n",
      "363/363 - 0s - loss: 0.6103 - accuracy: 0.7953\n",
      "Epoch 604/1000\n",
      "363/363 - 0s - loss: 0.6014 - accuracy: 0.7969\n",
      "Epoch 605/1000\n",
      "363/363 - 0s - loss: 0.5809 - accuracy: 0.8044\n",
      "Epoch 606/1000\n",
      "363/363 - 0s - loss: 0.5929 - accuracy: 0.7995\n",
      "Epoch 607/1000\n",
      "363/363 - 0s - loss: 0.5986 - accuracy: 0.8021\n",
      "Epoch 608/1000\n",
      "363/363 - 0s - loss: 0.5904 - accuracy: 0.8038\n",
      "Epoch 609/1000\n",
      "363/363 - 0s - loss: 0.5957 - accuracy: 0.8056\n",
      "Epoch 610/1000\n",
      "363/363 - 0s - loss: 0.5870 - accuracy: 0.8027\n",
      "Epoch 611/1000\n",
      "363/363 - 0s - loss: 0.6078 - accuracy: 0.8011\n",
      "Epoch 612/1000\n",
      "363/363 - 0s - loss: 0.5915 - accuracy: 0.8003\n",
      "Epoch 613/1000\n",
      "363/363 - 0s - loss: 0.5865 - accuracy: 0.8093\n",
      "Epoch 614/1000\n",
      "363/363 - 0s - loss: 0.6202 - accuracy: 0.7950\n",
      "Epoch 615/1000\n",
      "363/363 - 0s - loss: 0.5967 - accuracy: 0.7989\n",
      "Epoch 616/1000\n",
      "363/363 - 0s - loss: 0.6043 - accuracy: 0.7967\n",
      "Epoch 617/1000\n",
      "363/363 - 0s - loss: 0.5752 - accuracy: 0.8039\n",
      "Epoch 618/1000\n",
      "363/363 - 0s - loss: 0.5847 - accuracy: 0.8037\n",
      "Epoch 619/1000\n",
      "363/363 - 0s - loss: 0.5909 - accuracy: 0.8031\n",
      "Epoch 620/1000\n",
      "363/363 - 0s - loss: 0.5840 - accuracy: 0.8065\n",
      "Epoch 621/1000\n",
      "363/363 - 0s - loss: 0.6002 - accuracy: 0.7997\n",
      "Epoch 622/1000\n",
      "363/363 - 0s - loss: 0.5868 - accuracy: 0.8048\n",
      "Epoch 623/1000\n",
      "363/363 - 0s - loss: 0.5892 - accuracy: 0.8057\n",
      "Epoch 624/1000\n",
      "363/363 - 0s - loss: 0.5899 - accuracy: 0.8032\n",
      "Epoch 625/1000\n",
      "363/363 - 0s - loss: 0.5893 - accuracy: 0.8005\n",
      "Epoch 626/1000\n",
      "363/363 - 0s - loss: 0.6119 - accuracy: 0.7968\n",
      "Epoch 627/1000\n",
      "363/363 - 0s - loss: 0.6009 - accuracy: 0.7985\n",
      "Epoch 628/1000\n",
      "363/363 - 0s - loss: 0.5960 - accuracy: 0.8018\n",
      "Epoch 629/1000\n",
      "363/363 - 0s - loss: 0.5827 - accuracy: 0.8027\n",
      "Epoch 630/1000\n",
      "363/363 - 0s - loss: 0.5825 - accuracy: 0.8055\n",
      "Epoch 631/1000\n",
      "363/363 - 0s - loss: 0.5928 - accuracy: 0.8050\n",
      "Epoch 632/1000\n",
      "363/363 - 0s - loss: 0.5938 - accuracy: 0.8026\n",
      "Epoch 633/1000\n",
      "363/363 - 0s - loss: 0.5769 - accuracy: 0.8076\n",
      "Epoch 634/1000\n",
      "363/363 - 0s - loss: 0.5855 - accuracy: 0.8037\n",
      "Epoch 635/1000\n",
      "363/363 - 0s - loss: 0.6004 - accuracy: 0.8006\n",
      "Epoch 636/1000\n",
      "363/363 - 0s - loss: 0.5990 - accuracy: 0.8003\n",
      "Epoch 637/1000\n",
      "363/363 - 0s - loss: 0.6105 - accuracy: 0.7988\n",
      "Epoch 638/1000\n",
      "363/363 - 0s - loss: 0.5952 - accuracy: 0.8005\n",
      "Epoch 639/1000\n",
      "363/363 - 0s - loss: 0.5973 - accuracy: 0.8021\n",
      "Epoch 640/1000\n",
      "363/363 - 0s - loss: 0.5826 - accuracy: 0.8051\n",
      "Epoch 641/1000\n",
      "363/363 - 0s - loss: 0.5818 - accuracy: 0.8032\n",
      "Epoch 642/1000\n",
      "363/363 - 0s - loss: 0.5900 - accuracy: 0.8040\n",
      "Epoch 643/1000\n",
      "363/363 - 0s - loss: 0.5855 - accuracy: 0.8066\n",
      "Epoch 644/1000\n",
      "363/363 - 0s - loss: 0.5809 - accuracy: 0.8059\n",
      "Epoch 645/1000\n",
      "363/363 - 0s - loss: 0.5975 - accuracy: 0.8041\n",
      "Epoch 646/1000\n",
      "363/363 - 0s - loss: 0.5879 - accuracy: 0.8032\n",
      "Epoch 647/1000\n",
      "363/363 - 0s - loss: 0.5924 - accuracy: 0.7987\n",
      "Epoch 648/1000\n",
      "363/363 - 0s - loss: 0.5744 - accuracy: 0.8110\n",
      "Epoch 649/1000\n",
      "363/363 - 0s - loss: 0.5931 - accuracy: 0.8017\n",
      "Epoch 650/1000\n",
      "363/363 - 0s - loss: 0.5952 - accuracy: 0.8006\n",
      "Epoch 651/1000\n",
      "363/363 - 0s - loss: 0.5811 - accuracy: 0.8071\n",
      "Epoch 652/1000\n",
      "363/363 - 0s - loss: 0.5875 - accuracy: 0.8040\n",
      "Epoch 653/1000\n",
      "363/363 - 0s - loss: 0.5889 - accuracy: 0.8045\n",
      "Epoch 654/1000\n",
      "363/363 - 0s - loss: 0.5866 - accuracy: 0.8051\n",
      "Epoch 655/1000\n",
      "363/363 - 0s - loss: 0.5815 - accuracy: 0.8040\n",
      "Epoch 656/1000\n",
      "363/363 - 0s - loss: 0.5703 - accuracy: 0.8099\n",
      "Epoch 657/1000\n",
      "363/363 - 0s - loss: 0.5879 - accuracy: 0.8041\n",
      "Epoch 658/1000\n",
      "363/363 - 0s - loss: 0.5939 - accuracy: 0.8024\n",
      "Epoch 659/1000\n",
      "363/363 - 0s - loss: 0.5957 - accuracy: 0.8007\n",
      "Epoch 660/1000\n",
      "363/363 - 0s - loss: 0.5969 - accuracy: 0.8025\n",
      "Epoch 661/1000\n",
      "363/363 - 0s - loss: 0.5893 - accuracy: 0.8050\n",
      "Epoch 662/1000\n",
      "363/363 - 0s - loss: 0.5764 - accuracy: 0.8035\n",
      "Epoch 663/1000\n",
      "363/363 - 0s - loss: 0.5763 - accuracy: 0.8078\n",
      "Epoch 664/1000\n",
      "363/363 - 0s - loss: 0.5892 - accuracy: 0.8042\n",
      "Epoch 665/1000\n",
      "363/363 - 0s - loss: 0.5867 - accuracy: 0.8046\n",
      "Epoch 666/1000\n",
      "363/363 - 0s - loss: 0.6018 - accuracy: 0.7999\n",
      "Epoch 667/1000\n",
      "363/363 - 0s - loss: 0.5905 - accuracy: 0.8040\n",
      "Epoch 668/1000\n",
      "363/363 - 0s - loss: 0.5797 - accuracy: 0.8087\n",
      "Epoch 669/1000\n",
      "363/363 - 0s - loss: 0.5878 - accuracy: 0.8024\n",
      "Epoch 670/1000\n",
      "363/363 - 0s - loss: 0.5960 - accuracy: 0.8013\n",
      "Epoch 671/1000\n",
      "363/363 - 0s - loss: 0.5941 - accuracy: 0.8035\n",
      "Epoch 672/1000\n",
      "363/363 - 0s - loss: 0.5854 - accuracy: 0.8040\n",
      "Epoch 673/1000\n",
      "363/363 - 0s - loss: 0.5817 - accuracy: 0.8065\n",
      "Epoch 674/1000\n",
      "363/363 - 0s - loss: 0.5820 - accuracy: 0.8071\n",
      "Epoch 675/1000\n",
      "363/363 - 0s - loss: 0.5758 - accuracy: 0.8084\n",
      "Epoch 676/1000\n",
      "363/363 - 0s - loss: 0.5835 - accuracy: 0.8040\n",
      "Epoch 677/1000\n",
      "363/363 - 0s - loss: 0.5882 - accuracy: 0.8032\n",
      "Epoch 678/1000\n",
      "363/363 - 0s - loss: 0.5750 - accuracy: 0.8084\n",
      "Epoch 679/1000\n",
      "363/363 - 0s - loss: 0.5731 - accuracy: 0.8092\n",
      "Epoch 680/1000\n",
      "363/363 - 0s - loss: 0.5890 - accuracy: 0.8019\n",
      "Epoch 681/1000\n",
      "363/363 - 0s - loss: 0.5865 - accuracy: 0.8045\n",
      "Epoch 682/1000\n",
      "363/363 - 0s - loss: 0.5794 - accuracy: 0.8065\n",
      "Epoch 683/1000\n",
      "363/363 - 0s - loss: 0.5897 - accuracy: 0.8053\n",
      "Epoch 684/1000\n",
      "363/363 - 0s - loss: 0.5737 - accuracy: 0.8064\n",
      "Epoch 685/1000\n",
      "363/363 - 0s - loss: 0.5894 - accuracy: 0.8040\n",
      "Epoch 686/1000\n",
      "363/363 - 0s - loss: 0.5840 - accuracy: 0.8024\n",
      "Epoch 687/1000\n",
      "363/363 - 0s - loss: 0.5925 - accuracy: 0.8030\n",
      "Epoch 688/1000\n",
      "363/363 - 0s - loss: 0.5825 - accuracy: 0.8053\n",
      "Epoch 689/1000\n",
      "363/363 - 0s - loss: 0.5830 - accuracy: 0.8067\n",
      "Epoch 690/1000\n",
      "363/363 - 0s - loss: 0.5840 - accuracy: 0.8033\n",
      "Epoch 691/1000\n",
      "363/363 - 0s - loss: 0.5840 - accuracy: 0.8078\n",
      "Epoch 692/1000\n",
      "363/363 - 0s - loss: 0.5731 - accuracy: 0.8097\n",
      "Epoch 693/1000\n",
      "363/363 - 0s - loss: 0.5933 - accuracy: 0.8010\n",
      "Epoch 694/1000\n",
      "363/363 - 0s - loss: 0.5802 - accuracy: 0.8048\n",
      "Epoch 695/1000\n",
      "363/363 - 0s - loss: 0.5730 - accuracy: 0.8081\n",
      "Epoch 696/1000\n",
      "363/363 - 0s - loss: 0.5773 - accuracy: 0.8077\n",
      "Epoch 697/1000\n",
      "363/363 - 0s - loss: 0.5855 - accuracy: 0.8018\n",
      "Epoch 698/1000\n",
      "363/363 - 0s - loss: 0.5837 - accuracy: 0.8054\n",
      "Epoch 699/1000\n",
      "363/363 - 0s - loss: 0.5750 - accuracy: 0.8073\n",
      "Epoch 700/1000\n",
      "363/363 - 0s - loss: 0.5720 - accuracy: 0.8116\n",
      "Epoch 701/1000\n",
      "363/363 - 0s - loss: 0.5653 - accuracy: 0.8113\n",
      "Epoch 702/1000\n",
      "363/363 - 0s - loss: 0.5850 - accuracy: 0.8029\n",
      "Epoch 703/1000\n",
      "363/363 - 0s - loss: 0.5739 - accuracy: 0.8056\n",
      "Epoch 704/1000\n",
      "363/363 - 0s - loss: 0.5870 - accuracy: 0.8036\n",
      "Epoch 705/1000\n",
      "363/363 - 0s - loss: 0.5917 - accuracy: 0.7996\n",
      "Epoch 706/1000\n",
      "363/363 - 0s - loss: 0.5820 - accuracy: 0.8074\n",
      "Epoch 707/1000\n",
      "363/363 - 0s - loss: 0.5710 - accuracy: 0.8074\n",
      "Epoch 708/1000\n",
      "363/363 - 0s - loss: 0.5820 - accuracy: 0.8079\n",
      "Epoch 709/1000\n",
      "363/363 - 0s - loss: 0.5802 - accuracy: 0.8048\n",
      "Epoch 710/1000\n",
      "363/363 - 0s - loss: 0.5869 - accuracy: 0.8046\n",
      "Epoch 711/1000\n",
      "363/363 - 0s - loss: 0.5793 - accuracy: 0.8115\n",
      "Epoch 712/1000\n",
      "363/363 - 0s - loss: 0.5781 - accuracy: 0.8057\n",
      "Epoch 713/1000\n",
      "363/363 - 0s - loss: 0.5833 - accuracy: 0.8071\n",
      "Epoch 714/1000\n",
      "363/363 - 0s - loss: 0.5739 - accuracy: 0.8077\n",
      "Epoch 715/1000\n",
      "363/363 - 0s - loss: 0.5744 - accuracy: 0.8054\n",
      "Epoch 716/1000\n",
      "363/363 - 0s - loss: 0.5858 - accuracy: 0.8038\n",
      "Epoch 717/1000\n",
      "363/363 - 0s - loss: 0.5923 - accuracy: 0.8014\n",
      "Epoch 718/1000\n",
      "363/363 - 0s - loss: 0.5695 - accuracy: 0.8075\n",
      "Epoch 719/1000\n",
      "363/363 - 0s - loss: 0.5671 - accuracy: 0.8075\n",
      "Epoch 720/1000\n",
      "363/363 - 0s - loss: 0.5802 - accuracy: 0.8047\n",
      "Epoch 721/1000\n",
      "363/363 - 0s - loss: 0.5752 - accuracy: 0.8065\n",
      "Epoch 722/1000\n",
      "363/363 - 0s - loss: 0.5980 - accuracy: 0.8016\n",
      "Epoch 723/1000\n",
      "363/363 - 0s - loss: 0.5867 - accuracy: 0.8056\n",
      "Epoch 724/1000\n",
      "363/363 - 0s - loss: 0.5744 - accuracy: 0.8085\n",
      "Epoch 725/1000\n",
      "363/363 - 0s - loss: 0.5746 - accuracy: 0.8090\n",
      "Epoch 726/1000\n",
      "363/363 - 0s - loss: 0.5772 - accuracy: 0.8127\n",
      "Epoch 727/1000\n",
      "363/363 - 0s - loss: 0.6017 - accuracy: 0.8026\n",
      "Epoch 728/1000\n",
      "363/363 - 0s - loss: 0.5553 - accuracy: 0.8133\n",
      "Epoch 729/1000\n",
      "363/363 - 0s - loss: 0.5728 - accuracy: 0.8092\n",
      "Epoch 730/1000\n",
      "363/363 - 0s - loss: 0.5770 - accuracy: 0.8058\n",
      "Epoch 731/1000\n",
      "363/363 - 0s - loss: 0.5818 - accuracy: 0.8059\n",
      "Epoch 732/1000\n",
      "363/363 - 0s - loss: 0.5755 - accuracy: 0.8044\n",
      "Epoch 733/1000\n",
      "363/363 - 0s - loss: 0.5771 - accuracy: 0.8108\n",
      "Epoch 734/1000\n",
      "363/363 - 0s - loss: 0.5756 - accuracy: 0.8098\n",
      "Epoch 735/1000\n",
      "363/363 - 0s - loss: 0.5718 - accuracy: 0.8105\n",
      "Epoch 736/1000\n",
      "363/363 - 0s - loss: 0.5787 - accuracy: 0.8048\n",
      "Epoch 737/1000\n",
      "363/363 - 0s - loss: 0.5740 - accuracy: 0.8078\n",
      "Epoch 738/1000\n",
      "363/363 - 0s - loss: 0.5781 - accuracy: 0.8048\n",
      "Epoch 739/1000\n",
      "363/363 - 0s - loss: 0.5772 - accuracy: 0.8065\n",
      "Epoch 740/1000\n",
      "363/363 - 0s - loss: 0.5760 - accuracy: 0.8087\n",
      "Epoch 741/1000\n",
      "363/363 - 0s - loss: 0.5655 - accuracy: 0.8124\n",
      "Epoch 742/1000\n",
      "363/363 - 0s - loss: 0.5818 - accuracy: 0.8071\n",
      "Epoch 743/1000\n",
      "363/363 - 0s - loss: 0.5694 - accuracy: 0.8121\n",
      "Epoch 744/1000\n",
      "363/363 - 0s - loss: 0.5719 - accuracy: 0.8106\n",
      "Epoch 745/1000\n",
      "363/363 - 0s - loss: 0.5825 - accuracy: 0.8056\n",
      "Epoch 746/1000\n",
      "363/363 - 0s - loss: 0.5759 - accuracy: 0.8110\n",
      "Epoch 747/1000\n",
      "363/363 - 0s - loss: 0.5799 - accuracy: 0.8077\n",
      "Epoch 748/1000\n",
      "363/363 - 0s - loss: 0.5684 - accuracy: 0.8095\n",
      "Epoch 749/1000\n",
      "363/363 - 0s - loss: 0.5744 - accuracy: 0.8085\n",
      "Epoch 750/1000\n",
      "363/363 - 0s - loss: 0.5717 - accuracy: 0.8105\n",
      "Epoch 751/1000\n",
      "363/363 - 0s - loss: 0.5644 - accuracy: 0.8125\n",
      "Epoch 752/1000\n",
      "363/363 - 0s - loss: 0.5704 - accuracy: 0.8093\n",
      "Epoch 753/1000\n",
      "363/363 - 0s - loss: 0.5724 - accuracy: 0.8091\n",
      "Epoch 754/1000\n",
      "363/363 - 0s - loss: 0.5839 - accuracy: 0.8065\n",
      "Epoch 755/1000\n",
      "363/363 - 0s - loss: 0.5623 - accuracy: 0.8143\n",
      "Epoch 756/1000\n",
      "363/363 - 0s - loss: 0.5834 - accuracy: 0.8054\n",
      "Epoch 757/1000\n",
      "363/363 - 0s - loss: 0.5863 - accuracy: 0.8031\n",
      "Epoch 758/1000\n",
      "363/363 - 0s - loss: 0.5709 - accuracy: 0.8112\n",
      "Epoch 759/1000\n",
      "363/363 - 0s - loss: 0.5912 - accuracy: 0.8048\n",
      "Epoch 760/1000\n",
      "363/363 - 0s - loss: 0.5815 - accuracy: 0.8067\n",
      "Epoch 761/1000\n",
      "363/363 - 0s - loss: 0.5819 - accuracy: 0.8033\n",
      "Epoch 762/1000\n",
      "363/363 - 0s - loss: 0.5775 - accuracy: 0.8039\n",
      "Epoch 763/1000\n",
      "363/363 - 0s - loss: 0.5652 - accuracy: 0.8127\n",
      "Epoch 764/1000\n",
      "363/363 - 0s - loss: 0.5767 - accuracy: 0.8090\n",
      "Epoch 765/1000\n",
      "363/363 - 0s - loss: 0.5706 - accuracy: 0.8127\n",
      "Epoch 766/1000\n",
      "363/363 - 0s - loss: 0.5762 - accuracy: 0.8090\n",
      "Epoch 767/1000\n",
      "363/363 - 0s - loss: 0.5688 - accuracy: 0.8120\n",
      "Epoch 768/1000\n",
      "363/363 - 0s - loss: 0.5793 - accuracy: 0.8065\n",
      "Epoch 769/1000\n",
      "363/363 - 0s - loss: 0.5819 - accuracy: 0.8056\n",
      "Epoch 770/1000\n",
      "363/363 - 0s - loss: 0.5723 - accuracy: 0.8095\n",
      "Epoch 771/1000\n",
      "363/363 - 0s - loss: 0.5563 - accuracy: 0.8142\n",
      "Epoch 772/1000\n",
      "363/363 - 0s - loss: 0.5809 - accuracy: 0.8042\n",
      "Epoch 773/1000\n",
      "363/363 - 0s - loss: 0.5711 - accuracy: 0.8070\n",
      "Epoch 774/1000\n",
      "363/363 - 0s - loss: 0.5834 - accuracy: 0.8034\n",
      "Epoch 775/1000\n",
      "363/363 - 0s - loss: 0.5610 - accuracy: 0.8137\n",
      "Epoch 776/1000\n",
      "363/363 - 0s - loss: 0.5885 - accuracy: 0.8059\n",
      "Epoch 777/1000\n",
      "363/363 - 0s - loss: 0.5707 - accuracy: 0.8068\n",
      "Epoch 778/1000\n",
      "363/363 - 0s - loss: 0.5667 - accuracy: 0.8079\n",
      "Epoch 779/1000\n",
      "363/363 - 0s - loss: 0.5674 - accuracy: 0.8112\n",
      "Epoch 780/1000\n",
      "363/363 - 0s - loss: 0.5724 - accuracy: 0.8068\n",
      "Epoch 781/1000\n",
      "363/363 - 0s - loss: 0.5638 - accuracy: 0.8083\n",
      "Epoch 782/1000\n",
      "363/363 - 0s - loss: 0.5664 - accuracy: 0.8128\n",
      "Epoch 783/1000\n",
      "363/363 - 0s - loss: 0.5710 - accuracy: 0.8115\n",
      "Epoch 784/1000\n",
      "363/363 - 0s - loss: 0.5861 - accuracy: 0.8064\n",
      "Epoch 785/1000\n",
      "363/363 - 0s - loss: 0.5698 - accuracy: 0.8142\n",
      "Epoch 786/1000\n",
      "363/363 - 0s - loss: 0.5684 - accuracy: 0.8058\n",
      "Epoch 787/1000\n",
      "363/363 - 0s - loss: 0.5673 - accuracy: 0.8063\n",
      "Epoch 788/1000\n",
      "363/363 - 0s - loss: 0.5668 - accuracy: 0.8095\n",
      "Epoch 789/1000\n",
      "363/363 - 0s - loss: 0.5898 - accuracy: 0.8058\n",
      "Epoch 790/1000\n",
      "363/363 - 0s - loss: 0.5623 - accuracy: 0.8116\n",
      "Epoch 791/1000\n",
      "363/363 - 0s - loss: 0.5645 - accuracy: 0.8102\n",
      "Epoch 792/1000\n",
      "363/363 - 0s - loss: 0.5751 - accuracy: 0.8031\n",
      "Epoch 793/1000\n",
      "363/363 - 0s - loss: 0.5538 - accuracy: 0.8130\n",
      "Epoch 794/1000\n",
      "363/363 - 0s - loss: 0.5643 - accuracy: 0.8115\n",
      "Epoch 795/1000\n",
      "363/363 - 0s - loss: 0.5849 - accuracy: 0.8050\n",
      "Epoch 796/1000\n",
      "363/363 - 0s - loss: 0.5499 - accuracy: 0.8150\n",
      "Epoch 797/1000\n",
      "363/363 - 0s - loss: 0.5663 - accuracy: 0.8098\n",
      "Epoch 798/1000\n",
      "363/363 - 0s - loss: 0.5678 - accuracy: 0.8085\n",
      "Epoch 799/1000\n",
      "363/363 - 0s - loss: 0.5772 - accuracy: 0.8052\n",
      "Epoch 800/1000\n",
      "363/363 - 0s - loss: 0.5954 - accuracy: 0.8045\n",
      "Epoch 801/1000\n",
      "363/363 - 0s - loss: 0.5673 - accuracy: 0.8116\n",
      "Epoch 802/1000\n",
      "363/363 - 0s - loss: 0.5585 - accuracy: 0.8133\n",
      "Epoch 803/1000\n",
      "363/363 - 0s - loss: 0.5561 - accuracy: 0.8168\n",
      "Epoch 804/1000\n",
      "363/363 - 0s - loss: 0.5718 - accuracy: 0.8121\n",
      "Epoch 805/1000\n",
      "363/363 - 0s - loss: 0.5657 - accuracy: 0.8108\n",
      "Epoch 806/1000\n",
      "363/363 - 0s - loss: 0.5707 - accuracy: 0.8080\n",
      "Epoch 807/1000\n",
      "363/363 - 0s - loss: 0.5525 - accuracy: 0.8164\n",
      "Epoch 808/1000\n",
      "363/363 - 0s - loss: 0.5479 - accuracy: 0.8176\n",
      "Epoch 809/1000\n",
      "363/363 - 0s - loss: 0.5599 - accuracy: 0.8063\n",
      "Epoch 810/1000\n",
      "363/363 - 0s - loss: 0.5620 - accuracy: 0.8131\n",
      "Epoch 811/1000\n",
      "363/363 - 0s - loss: 0.5687 - accuracy: 0.8059\n",
      "Epoch 812/1000\n",
      "363/363 - 0s - loss: 0.5637 - accuracy: 0.8125\n",
      "Epoch 813/1000\n",
      "363/363 - 0s - loss: 0.5631 - accuracy: 0.8081\n",
      "Epoch 814/1000\n",
      "363/363 - 0s - loss: 0.5657 - accuracy: 0.8105\n",
      "Epoch 815/1000\n",
      "363/363 - 0s - loss: 0.5764 - accuracy: 0.8077\n",
      "Epoch 816/1000\n",
      "363/363 - 0s - loss: 0.5719 - accuracy: 0.8075\n",
      "Epoch 817/1000\n",
      "363/363 - 0s - loss: 0.5719 - accuracy: 0.8071\n",
      "Epoch 818/1000\n",
      "363/363 - 0s - loss: 0.5830 - accuracy: 0.8075\n",
      "Epoch 819/1000\n",
      "363/363 - 0s - loss: 0.5598 - accuracy: 0.8102\n",
      "Epoch 820/1000\n",
      "363/363 - 0s - loss: 0.5604 - accuracy: 0.8100\n",
      "Epoch 821/1000\n",
      "363/363 - 0s - loss: 0.5611 - accuracy: 0.8145\n",
      "Epoch 822/1000\n",
      "363/363 - 0s - loss: 0.5539 - accuracy: 0.8111\n",
      "Epoch 823/1000\n",
      "363/363 - 0s - loss: 0.5657 - accuracy: 0.8134\n",
      "Epoch 824/1000\n",
      "363/363 - 0s - loss: 0.5697 - accuracy: 0.8086\n",
      "Epoch 825/1000\n",
      "363/363 - 0s - loss: 0.5665 - accuracy: 0.8077\n",
      "Epoch 826/1000\n",
      "363/363 - 0s - loss: 0.5648 - accuracy: 0.8118\n",
      "Epoch 827/1000\n",
      "363/363 - 0s - loss: 0.5680 - accuracy: 0.8108\n",
      "Epoch 828/1000\n",
      "363/363 - 0s - loss: 0.5523 - accuracy: 0.8136\n",
      "Epoch 829/1000\n",
      "363/363 - 0s - loss: 0.5725 - accuracy: 0.8093\n",
      "Epoch 830/1000\n",
      "363/363 - 0s - loss: 0.5730 - accuracy: 0.8085\n",
      "Epoch 831/1000\n",
      "363/363 - 0s - loss: 0.5500 - accuracy: 0.8168\n",
      "Epoch 832/1000\n",
      "363/363 - 0s - loss: 0.5686 - accuracy: 0.8124\n",
      "Epoch 833/1000\n",
      "363/363 - 0s - loss: 0.5615 - accuracy: 0.8119\n",
      "Epoch 834/1000\n",
      "363/363 - 0s - loss: 0.5766 - accuracy: 0.8071\n",
      "Epoch 835/1000\n",
      "363/363 - 0s - loss: 0.5679 - accuracy: 0.8096\n",
      "Epoch 836/1000\n",
      "363/363 - 0s - loss: 0.5671 - accuracy: 0.8069\n",
      "Epoch 837/1000\n",
      "363/363 - 0s - loss: 0.5591 - accuracy: 0.8127\n",
      "Epoch 838/1000\n",
      "363/363 - 0s - loss: 0.5467 - accuracy: 0.8161\n",
      "Epoch 839/1000\n",
      "363/363 - 0s - loss: 0.5601 - accuracy: 0.8104\n",
      "Epoch 840/1000\n",
      "363/363 - 0s - loss: 0.5539 - accuracy: 0.8129\n",
      "Epoch 841/1000\n",
      "363/363 - 0s - loss: 0.5658 - accuracy: 0.8068\n",
      "Epoch 842/1000\n",
      "363/363 - 0s - loss: 0.5564 - accuracy: 0.8143\n",
      "Epoch 843/1000\n",
      "363/363 - 0s - loss: 0.5568 - accuracy: 0.8119\n",
      "Epoch 844/1000\n",
      "363/363 - 0s - loss: 0.5703 - accuracy: 0.8120\n",
      "Epoch 845/1000\n",
      "363/363 - 0s - loss: 0.5643 - accuracy: 0.8078\n",
      "Epoch 846/1000\n",
      "363/363 - 0s - loss: 0.5692 - accuracy: 0.8112\n",
      "Epoch 847/1000\n",
      "363/363 - 0s - loss: 0.5527 - accuracy: 0.8155\n",
      "Epoch 848/1000\n",
      "363/363 - 0s - loss: 0.5593 - accuracy: 0.8108\n",
      "Epoch 849/1000\n",
      "363/363 - 0s - loss: 0.5749 - accuracy: 0.8070\n",
      "Epoch 850/1000\n",
      "363/363 - 0s - loss: 0.5662 - accuracy: 0.8079\n",
      "Epoch 851/1000\n",
      "363/363 - 0s - loss: 0.5508 - accuracy: 0.8131\n",
      "Epoch 852/1000\n",
      "363/363 - 0s - loss: 0.5454 - accuracy: 0.8172\n",
      "Epoch 853/1000\n",
      "363/363 - 0s - loss: 0.5637 - accuracy: 0.8109\n",
      "Epoch 854/1000\n",
      "363/363 - 0s - loss: 0.5480 - accuracy: 0.8154\n",
      "Epoch 855/1000\n",
      "363/363 - 0s - loss: 0.5719 - accuracy: 0.8112\n",
      "Epoch 856/1000\n",
      "363/363 - 0s - loss: 0.5641 - accuracy: 0.8101\n",
      "Epoch 857/1000\n",
      "363/363 - 0s - loss: 0.5700 - accuracy: 0.8093\n",
      "Epoch 858/1000\n",
      "363/363 - 0s - loss: 0.5582 - accuracy: 0.8146\n",
      "Epoch 859/1000\n",
      "363/363 - 0s - loss: 0.5566 - accuracy: 0.8156\n",
      "Epoch 860/1000\n",
      "363/363 - 0s - loss: 0.5693 - accuracy: 0.8115\n",
      "Epoch 861/1000\n",
      "363/363 - 0s - loss: 0.5702 - accuracy: 0.8115\n",
      "Epoch 862/1000\n",
      "363/363 - 0s - loss: 0.5543 - accuracy: 0.8145\n",
      "Epoch 863/1000\n",
      "363/363 - 0s - loss: 0.5748 - accuracy: 0.8084\n",
      "Epoch 864/1000\n",
      "363/363 - 0s - loss: 0.5605 - accuracy: 0.8120\n",
      "Epoch 865/1000\n",
      "363/363 - 0s - loss: 0.5470 - accuracy: 0.8131\n",
      "Epoch 866/1000\n",
      "363/363 - 0s - loss: 0.5540 - accuracy: 0.8121\n",
      "Epoch 867/1000\n",
      "363/363 - 0s - loss: 0.5652 - accuracy: 0.8089\n",
      "Epoch 868/1000\n",
      "363/363 - 0s - loss: 0.5614 - accuracy: 0.8127\n",
      "Epoch 869/1000\n",
      "363/363 - 0s - loss: 0.5573 - accuracy: 0.8139\n",
      "Epoch 870/1000\n",
      "363/363 - 0s - loss: 0.5513 - accuracy: 0.8142\n",
      "Epoch 871/1000\n",
      "363/363 - 0s - loss: 0.5757 - accuracy: 0.8104\n",
      "Epoch 872/1000\n",
      "363/363 - 0s - loss: 0.5672 - accuracy: 0.8086\n",
      "Epoch 873/1000\n",
      "363/363 - 0s - loss: 0.5657 - accuracy: 0.8123\n",
      "Epoch 874/1000\n",
      "363/363 - 0s - loss: 0.5494 - accuracy: 0.8130\n",
      "Epoch 875/1000\n",
      "363/363 - 0s - loss: 0.5641 - accuracy: 0.8124\n",
      "Epoch 876/1000\n",
      "363/363 - 0s - loss: 0.5672 - accuracy: 0.8094\n",
      "Epoch 877/1000\n",
      "363/363 - 0s - loss: 0.5553 - accuracy: 0.8152\n",
      "Epoch 878/1000\n",
      "363/363 - 0s - loss: 0.5494 - accuracy: 0.8166\n",
      "Epoch 879/1000\n",
      "363/363 - 0s - loss: 0.5613 - accuracy: 0.8104\n",
      "Epoch 880/1000\n",
      "363/363 - 0s - loss: 0.5730 - accuracy: 0.8053\n",
      "Epoch 881/1000\n",
      "363/363 - 0s - loss: 0.5707 - accuracy: 0.8079\n",
      "Epoch 882/1000\n",
      "363/363 - 0s - loss: 0.5490 - accuracy: 0.8176\n",
      "Epoch 883/1000\n",
      "363/363 - 0s - loss: 0.5525 - accuracy: 0.8120\n",
      "Epoch 884/1000\n",
      "363/363 - 0s - loss: 0.5553 - accuracy: 0.8133\n",
      "Epoch 885/1000\n",
      "363/363 - 0s - loss: 0.5616 - accuracy: 0.8127\n",
      "Epoch 886/1000\n",
      "363/363 - 0s - loss: 0.5810 - accuracy: 0.8071\n",
      "Epoch 887/1000\n",
      "363/363 - 0s - loss: 0.5605 - accuracy: 0.8127\n",
      "Epoch 888/1000\n",
      "363/363 - 0s - loss: 0.5493 - accuracy: 0.8163\n",
      "Epoch 889/1000\n",
      "363/363 - 0s - loss: 0.5400 - accuracy: 0.8157\n",
      "Epoch 890/1000\n",
      "363/363 - 0s - loss: 0.5552 - accuracy: 0.8134\n",
      "Epoch 891/1000\n",
      "363/363 - 0s - loss: 0.5642 - accuracy: 0.8117\n",
      "Epoch 892/1000\n",
      "363/363 - 0s - loss: 0.5526 - accuracy: 0.8146\n",
      "Epoch 893/1000\n",
      "363/363 - 0s - loss: 0.5515 - accuracy: 0.8121\n",
      "Epoch 894/1000\n",
      "363/363 - 0s - loss: 0.5637 - accuracy: 0.8106\n",
      "Epoch 895/1000\n",
      "363/363 - 0s - loss: 0.5557 - accuracy: 0.8139\n",
      "Epoch 896/1000\n",
      "363/363 - 0s - loss: 0.5451 - accuracy: 0.8167\n",
      "Epoch 897/1000\n",
      "363/363 - 0s - loss: 0.5586 - accuracy: 0.8151\n",
      "Epoch 898/1000\n",
      "363/363 - 0s - loss: 0.5817 - accuracy: 0.8053\n",
      "Epoch 899/1000\n",
      "363/363 - 0s - loss: 0.5503 - accuracy: 0.8160\n",
      "Epoch 900/1000\n",
      "363/363 - 0s - loss: 0.5478 - accuracy: 0.8157\n",
      "Epoch 901/1000\n",
      "363/363 - 0s - loss: 0.5571 - accuracy: 0.8143\n",
      "Epoch 902/1000\n",
      "363/363 - 0s - loss: 0.5733 - accuracy: 0.8043\n",
      "Epoch 903/1000\n",
      "363/363 - 0s - loss: 0.5656 - accuracy: 0.8071\n",
      "Epoch 904/1000\n",
      "363/363 - 0s - loss: 0.5666 - accuracy: 0.8110\n",
      "Epoch 905/1000\n",
      "363/363 - 0s - loss: 0.5411 - accuracy: 0.8165\n",
      "Epoch 906/1000\n",
      "363/363 - 0s - loss: 0.5431 - accuracy: 0.8193\n",
      "Epoch 907/1000\n",
      "363/363 - 0s - loss: 0.5617 - accuracy: 0.8118\n",
      "Epoch 908/1000\n",
      "363/363 - 0s - loss: 0.5561 - accuracy: 0.8158\n",
      "Epoch 909/1000\n",
      "363/363 - 0s - loss: 0.5438 - accuracy: 0.8161\n",
      "Epoch 910/1000\n",
      "363/363 - 0s - loss: 0.5639 - accuracy: 0.8082\n",
      "Epoch 911/1000\n",
      "363/363 - 0s - loss: 0.5468 - accuracy: 0.8150\n",
      "Epoch 912/1000\n",
      "363/363 - 0s - loss: 0.5585 - accuracy: 0.8130\n",
      "Epoch 913/1000\n",
      "363/363 - 0s - loss: 0.5645 - accuracy: 0.8080\n",
      "Epoch 914/1000\n",
      "363/363 - 0s - loss: 0.5591 - accuracy: 0.8128\n",
      "Epoch 915/1000\n",
      "363/363 - 0s - loss: 0.5531 - accuracy: 0.8128\n",
      "Epoch 916/1000\n",
      "363/363 - 0s - loss: 0.5668 - accuracy: 0.8094\n",
      "Epoch 917/1000\n",
      "363/363 - 0s - loss: 0.5559 - accuracy: 0.8127\n",
      "Epoch 918/1000\n",
      "363/363 - 0s - loss: 0.5483 - accuracy: 0.8134\n",
      "Epoch 919/1000\n",
      "363/363 - 0s - loss: 0.5426 - accuracy: 0.8162\n",
      "Epoch 920/1000\n",
      "363/363 - 0s - loss: 0.5541 - accuracy: 0.8147\n",
      "Epoch 921/1000\n",
      "363/363 - 0s - loss: 0.5712 - accuracy: 0.8059\n",
      "Epoch 922/1000\n",
      "363/363 - 0s - loss: 0.5621 - accuracy: 0.8141\n",
      "Epoch 923/1000\n",
      "363/363 - 0s - loss: 0.5535 - accuracy: 0.8160\n",
      "Epoch 924/1000\n",
      "363/363 - 0s - loss: 0.5483 - accuracy: 0.8162\n",
      "Epoch 925/1000\n",
      "363/363 - 0s - loss: 0.5516 - accuracy: 0.8179\n",
      "Epoch 926/1000\n",
      "363/363 - 0s - loss: 0.5573 - accuracy: 0.8124\n",
      "Epoch 927/1000\n",
      "363/363 - 0s - loss: 0.5572 - accuracy: 0.8153\n",
      "Epoch 928/1000\n",
      "363/363 - 0s - loss: 0.5524 - accuracy: 0.8152\n",
      "Epoch 929/1000\n",
      "363/363 - 0s - loss: 0.5756 - accuracy: 0.8073\n",
      "Epoch 930/1000\n",
      "363/363 - 0s - loss: 0.5541 - accuracy: 0.8144\n",
      "Epoch 931/1000\n",
      "363/363 - 0s - loss: 0.5385 - accuracy: 0.8205\n",
      "Epoch 932/1000\n",
      "363/363 - 0s - loss: 0.5485 - accuracy: 0.8186\n",
      "Epoch 933/1000\n",
      "363/363 - 0s - loss: 0.5798 - accuracy: 0.8096\n",
      "Epoch 934/1000\n",
      "363/363 - 0s - loss: 0.5591 - accuracy: 0.8186\n",
      "Epoch 935/1000\n",
      "363/363 - 0s - loss: 0.5661 - accuracy: 0.8136\n",
      "Epoch 936/1000\n",
      "363/363 - 0s - loss: 0.5542 - accuracy: 0.8171\n",
      "Epoch 937/1000\n",
      "363/363 - 0s - loss: 0.5542 - accuracy: 0.8139\n",
      "Epoch 938/1000\n",
      "363/363 - 0s - loss: 0.5665 - accuracy: 0.8114\n",
      "Epoch 939/1000\n",
      "363/363 - 0s - loss: 0.5462 - accuracy: 0.8152\n",
      "Epoch 940/1000\n",
      "363/363 - 0s - loss: 0.5517 - accuracy: 0.8146\n",
      "Epoch 941/1000\n",
      "363/363 - 0s - loss: 0.5456 - accuracy: 0.8174\n",
      "Epoch 942/1000\n",
      "363/363 - 0s - loss: 0.5481 - accuracy: 0.8164\n",
      "Epoch 943/1000\n",
      "363/363 - 0s - loss: 0.5615 - accuracy: 0.8122\n",
      "Epoch 944/1000\n",
      "363/363 - 0s - loss: 0.5492 - accuracy: 0.8175\n",
      "Epoch 945/1000\n",
      "363/363 - 0s - loss: 0.5425 - accuracy: 0.8141\n",
      "Epoch 946/1000\n",
      "363/363 - 0s - loss: 0.5399 - accuracy: 0.8168\n",
      "Epoch 947/1000\n",
      "363/363 - 0s - loss: 0.5398 - accuracy: 0.8168\n",
      "Epoch 948/1000\n",
      "363/363 - 0s - loss: 0.5628 - accuracy: 0.8099\n",
      "Epoch 949/1000\n",
      "363/363 - 0s - loss: 0.5374 - accuracy: 0.8187\n",
      "Epoch 950/1000\n",
      "363/363 - 0s - loss: 0.5591 - accuracy: 0.8127\n",
      "Epoch 951/1000\n",
      "363/363 - 0s - loss: 0.5493 - accuracy: 0.8172\n",
      "Epoch 952/1000\n",
      "363/363 - 0s - loss: 0.5466 - accuracy: 0.8162\n",
      "Epoch 953/1000\n",
      "363/363 - 0s - loss: 0.5526 - accuracy: 0.8106\n",
      "Epoch 954/1000\n",
      "363/363 - 0s - loss: 0.5616 - accuracy: 0.8093\n",
      "Epoch 955/1000\n",
      "363/363 - 0s - loss: 0.5584 - accuracy: 0.8120\n",
      "Epoch 956/1000\n",
      "363/363 - 0s - loss: 0.5468 - accuracy: 0.8159\n",
      "Epoch 957/1000\n",
      "363/363 - 0s - loss: 0.5498 - accuracy: 0.8156\n",
      "Epoch 958/1000\n",
      "363/363 - 0s - loss: 0.5539 - accuracy: 0.8139\n",
      "Epoch 959/1000\n",
      "363/363 - 0s - loss: 0.5583 - accuracy: 0.8153\n",
      "Epoch 960/1000\n",
      "363/363 - 0s - loss: 0.5488 - accuracy: 0.8170\n",
      "Epoch 961/1000\n",
      "363/363 - 0s - loss: 0.5505 - accuracy: 0.8153\n",
      "Epoch 962/1000\n",
      "363/363 - 0s - loss: 0.5547 - accuracy: 0.8148\n",
      "Epoch 963/1000\n",
      "363/363 - 0s - loss: 0.5444 - accuracy: 0.8165\n",
      "Epoch 964/1000\n",
      "363/363 - 0s - loss: 0.5530 - accuracy: 0.8136\n",
      "Epoch 965/1000\n",
      "363/363 - 0s - loss: 0.5578 - accuracy: 0.8142\n",
      "Epoch 966/1000\n",
      "363/363 - 0s - loss: 0.5587 - accuracy: 0.8109\n",
      "Epoch 967/1000\n",
      "363/363 - 0s - loss: 0.5340 - accuracy: 0.8185\n",
      "Epoch 968/1000\n",
      "363/363 - 0s - loss: 0.5493 - accuracy: 0.8140\n",
      "Epoch 969/1000\n",
      "363/363 - 0s - loss: 0.5466 - accuracy: 0.8172\n",
      "Epoch 970/1000\n",
      "363/363 - 0s - loss: 0.5458 - accuracy: 0.8173\n",
      "Epoch 971/1000\n",
      "363/363 - 0s - loss: 0.5359 - accuracy: 0.8197\n",
      "Epoch 972/1000\n",
      "363/363 - 0s - loss: 0.5469 - accuracy: 0.8185\n",
      "Epoch 973/1000\n",
      "363/363 - 0s - loss: 0.5644 - accuracy: 0.8123\n",
      "Epoch 974/1000\n",
      "363/363 - 0s - loss: 0.5480 - accuracy: 0.8154\n",
      "Epoch 975/1000\n",
      "363/363 - 0s - loss: 0.5378 - accuracy: 0.8200\n",
      "Epoch 976/1000\n",
      "363/363 - 0s - loss: 0.5474 - accuracy: 0.8163\n",
      "Epoch 977/1000\n",
      "363/363 - 0s - loss: 0.5466 - accuracy: 0.8185\n",
      "Epoch 978/1000\n",
      "363/363 - 0s - loss: 0.5426 - accuracy: 0.8204\n",
      "Epoch 979/1000\n",
      "363/363 - 0s - loss: 0.5430 - accuracy: 0.8155\n",
      "Epoch 980/1000\n",
      "363/363 - 0s - loss: 0.5337 - accuracy: 0.8210\n",
      "Epoch 981/1000\n",
      "363/363 - 0s - loss: 0.5424 - accuracy: 0.8143\n",
      "Epoch 982/1000\n",
      "363/363 - 0s - loss: 0.5678 - accuracy: 0.8079\n",
      "Epoch 983/1000\n",
      "363/363 - 0s - loss: 0.5335 - accuracy: 0.8215\n",
      "Epoch 984/1000\n",
      "363/363 - 0s - loss: 0.5386 - accuracy: 0.8170\n",
      "Epoch 985/1000\n",
      "363/363 - 0s - loss: 0.5529 - accuracy: 0.8163\n",
      "Epoch 986/1000\n",
      "363/363 - 0s - loss: 0.5440 - accuracy: 0.8157\n",
      "Epoch 987/1000\n",
      "363/363 - 0s - loss: 0.5543 - accuracy: 0.8157\n",
      "Epoch 988/1000\n",
      "363/363 - 0s - loss: 0.5460 - accuracy: 0.8190\n",
      "Epoch 989/1000\n",
      "363/363 - 0s - loss: 0.5525 - accuracy: 0.8144\n",
      "Epoch 990/1000\n",
      "363/363 - 0s - loss: 0.5434 - accuracy: 0.8144\n",
      "Epoch 991/1000\n",
      "363/363 - 0s - loss: 0.5523 - accuracy: 0.8158\n",
      "Epoch 992/1000\n",
      "363/363 - 0s - loss: 0.5604 - accuracy: 0.8133\n",
      "Epoch 993/1000\n",
      "363/363 - 0s - loss: 0.5411 - accuracy: 0.8167\n",
      "Epoch 994/1000\n",
      "363/363 - 0s - loss: 0.5386 - accuracy: 0.8206\n",
      "Epoch 995/1000\n",
      "363/363 - 0s - loss: 0.5522 - accuracy: 0.8172\n",
      "Epoch 996/1000\n",
      "363/363 - 0s - loss: 0.5490 - accuracy: 0.8150\n",
      "Epoch 997/1000\n",
      "363/363 - 0s - loss: 0.5421 - accuracy: 0.8199\n",
      "Epoch 998/1000\n",
      "363/363 - 0s - loss: 0.5516 - accuracy: 0.8154\n",
      "Epoch 999/1000\n",
      "363/363 - 0s - loss: 0.5647 - accuracy: 0.8099\n",
      "Epoch 1000/1000\n",
      "363/363 - 0s - loss: 0.5530 - accuracy: 0.8129\n"
     ]
    }
   ],
   "source": [
    "## Compile and train the deep learning model\n",
    "fire_cause_model_v1.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "modelHistory_v1 = fire_cause_model_v1.fit(\n",
    "    X_train,\n",
    "    y_train_categorical,\n",
    "    epochs=NoOfRuns,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT MODEL ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,4))\n",
    "\n",
    "ax[0].plot(modelHistory_v1.history['loss'])\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "\n",
    "ax[1].plot(modelHistory_v1.history['accuracy'])\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 - 0s - loss: 1.9030 - accuracy: 0.6668\n",
      "Loss: 1.9029875993728638, Accuracy: 0.6668388247489929\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = fire_cause_model_v1.evaluate(X_test, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [[7.35844587e-05 6.73302591e-01 8.66867310e-07 ... 1.02117576e-06\n",
      "  3.02136641e-07 1.29856080e-14]\n",
      " [6.24579457e-07 2.51035144e-05 4.93140294e-12 ... 1.93791316e-09\n",
      "  7.56815721e-11 1.31831569e-22]\n",
      " [9.47224660e-11 1.39018502e-02 1.15985745e-11 ... 3.44555387e-25\n",
      "  8.64706695e-10 8.91181940e-34]\n",
      " ...\n",
      " [2.05772537e-07 8.66089482e-03 2.14922391e-09 ... 3.86087231e-06\n",
      "  4.46821505e-04 1.88410418e-23]\n",
      " [2.47729186e-04 4.72087832e-03 4.01448697e-09 ... 3.96922178e-06\n",
      "  2.71207397e-03 5.04158372e-15]\n",
      " [3.66232347e-14 3.41046997e-03 7.43260400e-15 ... 1.37042398e-19\n",
      "  5.54338736e-12 1.41215247e-34]]\n",
      "Predicted class: 4046\n"
     ]
    }
   ],
   "source": [
    "### Making Predictions with new data\n",
    "# new_data = X_scaler.transform(np.array([[-1.2, 0.3, 0.4]]))\n",
    "new_data = X_test\n",
    "\n",
    "print(f\"Model output: {fire_cause_model_v1.predict(new_data)}\")\n",
    "print(f\"Predicted class: {np.argmax(fire_cause_model_v1.predict(new_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions_v1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>P(0) model1</th>\n",
       "      <th>P(100) model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.67330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00284</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>0.00107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.00181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64255</td>\n",
       "      <td>0.04976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.96196</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>0.28336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.02203</td>\n",
       "      <td>0.00228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99752</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96821</td>\n",
       "      <td>0.01552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00940</td>\n",
       "      <td>0.01418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46530</td>\n",
       "      <td>0.00183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.03018</td>\n",
       "      <td>0.22674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00719</td>\n",
       "      <td>0.06690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.07123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00405</td>\n",
       "      <td>0.13843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00598</td>\n",
       "      <td>0.02403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.07490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.07916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00230</td>\n",
       "      <td>0.01753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.13771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.01158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03064</td>\n",
       "      <td>0.00541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions_v1  Actual  P(0) model1  P(100) model1\n",
       "0                1       4      0.00007        0.67330\n",
       "1                6       6      0.00000        0.00003\n",
       "2                6       6      0.00000        0.01390\n",
       "3                6       6      0.00000        0.00425\n",
       "4                7       4      0.00000        0.00000\n",
       "5                6       6      0.00284        0.00000\n",
       "6                6       6      0.00000        0.02912\n",
       "7                6       6      0.00000        0.00004\n",
       "8                6       6      0.00398        0.00107\n",
       "9                6       6      0.00014        0.00181\n",
       "10               0       0      0.64255        0.04976\n",
       "11               0       7      0.96196        0.00000\n",
       "12               7       8      0.00000        0.03364\n",
       "13               6       6      0.00000        0.03313\n",
       "14               6       6      0.00000        0.02463\n",
       "15               6       6      0.00000        0.00073\n",
       "16               6       6      0.00000        0.00195\n",
       "17               6       6      0.00000        0.00821\n",
       "18               6       4      0.00285        0.28336\n",
       "19               6       6      0.00000        0.01330\n",
       "20               6       6      0.02203        0.00228\n",
       "21               0       6      0.99752        0.00072\n",
       "22               6       5      0.00007        0.00598\n",
       "23               8       3      0.00000        0.00017\n",
       "24               6       6      0.00000        0.10829\n",
       "25               0       0      0.96821        0.01552\n",
       "26               6       6      0.00940        0.01418\n",
       "27               0       4      0.46530        0.00183\n",
       "28               6       6      0.00000        0.00010\n",
       "29               6       4      0.03018        0.22674\n",
       "30               6       6      0.00004        0.00001\n",
       "31               6       1      0.00719        0.06690\n",
       "32               6       6      0.00036        0.07123\n",
       "33               3       7      0.00405        0.13843\n",
       "34               6       6      0.00000        0.00000\n",
       "35               6       6      0.00000        0.00132\n",
       "36               6       6      0.00598        0.02403\n",
       "37               6       6      0.00001        0.07490\n",
       "38               6       6      0.00018        0.07916\n",
       "39               6       6      0.00000        0.00994\n",
       "40               6       6      0.00167        0.00438\n",
       "41               6       6      0.00001        0.01544\n",
       "42               6       6      0.00000        0.01505\n",
       "43               6       6      0.00000        0.00006\n",
       "44               6       1      0.00230        0.01753\n",
       "45               6       6      0.00000        0.00034\n",
       "46               6       6      0.00060        0.13771\n",
       "47               6       4      0.00290        0.01158\n",
       "48               6       6      0.00000        0.00406\n",
       "49               6       6      0.03064        0.00541"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### View prediction probabilities\n",
    "predictions_v1 = np.argmax(fire_cause_model_v1.predict(X_test), axis=1)\n",
    "probs_v1 = fire_cause_model_v1.predict(X_test)\n",
    "\n",
    "# Change the shape of y\n",
    "old_y_test = y_test\n",
    "new_y_test = np.array(old_y_test)\n",
    "y_test = new_y_test.reshape(-1, 1) \n",
    "y_test\n",
    "y_test_df = y_test.ravel()\n",
    "y_test_df\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Predictions_v1\": predictions_v1,\n",
    "    \"Actual\": y_test_df, \n",
    "    \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "    \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "    })\n",
    "\n",
    "pred_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle weakref objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-955-4c77e784e631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NN_fireCauseModel.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfire_cause_model_v1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle weakref objects"
     ]
    }
   ],
   "source": [
    "# SAVING MODEL\n",
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import pickle\n",
    "\n",
    "with open('NN_fireCauseModel.pkl','wb') as f:\n",
    "    pickle.dump(fire_cause_model_v1, f)\n",
    "\n",
    "\n",
    "import joblib\n",
    "filename = 'NN_fireCauseModel.sav'\n",
    "joblib.dump(fire_cause_model_v1, filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
